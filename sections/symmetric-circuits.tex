\documentclass[../paper.tex]{subfiles}
%\usepackage{../mymacros}
\begin{document}
% Note: include circuits in background

% AD: re-wrote the introductory paragraphs to be a bit more substantive.

A Boolean circuit $C$ computing a function from $\{0,1\}^n$ to $\{0,1\}$ is
usually described as a directed acyclic graph, with each gate $g$ that has $m$
incoming edges labelled with a Boolean function $f_g : \{0,1\}^m \rightarrow
\{0,1\}$ from a basis $\mathbb{B}$ and exactly $n$ input gates of $C$ are
labelled by variables. If the function $f_g$ can be arbitrary, then the circuit
$C$ must impose an order on the gates that provide the inputs to $g$. When we
say that $C$ is a directed acyclic graph, without further ordering the nodes, we
implicitly assume that the functions in the basis $\mathbb{B}$ are
\emph{symmetric}. That is to say $f_g$ is invariant under all permutations of
its $m$ inputs. This unstated assumption is pervasive in circuit complexity. In
particular, the standard Boolean basis of $\AND$, $\OR$ and $\NOT$ gates as well as bases
with majority or threshold gates only contain symmetric functions.

We are interested in Boolean circuits that compute queries on structures, such
as graphs. In the case of (undirected, loop-free) graphs on $n$ vertices, such a
circuit might compute a function from $\{0,1\}^{n \choose 2}$ to $\{0,1\}$. In
this case, the function computed by the circuit is not necessarily invariant
under all permutations of the inputs, but it is invariant under all permutations
of the $n \choose 2$ inputs induced by permutations of $[n]$. We are especially
concerned with \emph{symmetric} circuits, that is those where the permutations
of $[n]$ extend to automorphisms of the circuit. Note that this use of the word
``symmetric'' is distinct to that its use when applied to Boolean functions. For
such circuits, Anderson and Dawar~\cite{AndersonD17} consider $\PT$-uniform
circuits in the standard Boolean basis as well one with majority gates. It is a
consequence of their results that the latter are strictly more powerful than the
former. In particular, they are shown to be equivalent to the logic $\FPC$. In
contrast, we show, in this section, that adding any further symmetric functions
to the basis does not allow us to extend the power of $\PT$-uniform symmetric
circuits beyond that of $\FPC$.

As our aim is a circuit characterisation of $\FPR$, whose expressive power is
strictly greater than that of $\FPC$, we need to consider gates corresponding to
non-symmetric Boolean functions. In particular, we consider \emph{rank} gates
whose inputs are a matrix and whose result is invariant under row and column
permutations. To lead up to this, we first develop a general framework of
structured Boolean functions. These are functions whose inputs naturally encode
$\tau$-structures and where the output is invariant under the natural symmetries
of such structures. The\emph{matrix-invariant} functions are a natural
partiruclar case. We therefore define symmetric circuits in a general form where
gates can be labelled by \emph{isomorphism-invariant} structured functions.

Ultimately, our aim is replicate the results Anderson and
Dawar~\cite{AndersonD17} in this more general setting. A difficulty we face is
that the proof methods in that paper heavily rely on the assumption that the
Boolean functions computed by individual gates are symmetric functions. We
address this difficulty in the next section.

% Boolean circuits have long acted as an alternative model from which to study
% algorithmic complexity. A circuit is evaluated for some input binary sequence
% by recursively evaluating each gate in the circuit, starting from the input
% gates. Suppose then we in the process of evaluating the circuit $C$ and are at
% the stage of evaluating the gate $g$. We take the input sequence formed from
% the evaluations of the gates input to $g$ and applying the element of the
% basis that labels $g$ to that sequence. It follows that in order to evaluate
% $g$ we need to suppose some order on the evaluations of the input gates. In
% many cases this order is simply induced by an assumed order on the whole of
% the circuit; an assumption common in most parts of complexity theory, where
% the encoding of structures for computation induces such orders, but
% problematic in finite model theory.

% Circuit models have also been studied in finite model theory, often as a means
% for characterising the expressive power of logics. In particular, research has
% focused on symmetric circuits defined over bases of symmetric Boolean
% functions (see \cite{}). The fact that the basis consist of only symmetric
% functions is a crucial requirement, ensuring that the evaluation of a gate
% does not depend on an external order. However, in this paper we will need to
% consider circuits with gates that compute rank, a function that is not
% symmetric.

% In this section we extend this circuit model so as to allow for the inclusion
% of non-symmetric functions in the basis. We allow each gate $g$ to index its
% input gate in accordance with the basis element labeling $g$. We introduce the
% notion of a \emph{structured function}, a Boolean function whose input is
% indexed in accordance with a many-sorted vocabulary $\tau$. The input vector
% to a structured function can then be thought of as encoding a
% $\tau$-structure. In particular, we consider structured functions that compute
% properties of $\tau$-structures, which we call \emph{isomorphism-invariant}
% structured functions. We then define what it means for a circuit over a basis
% of isomorphism-invariant structured functions to be symmetric. This
% generalises the notion of a symmetric circuit. We also show that there are
% limitations on the power of symmetric circuits over bases of symmetric
% functions, justifying the importance of this generalisation.

% We incorporate this labelling in the circuit model by including for each gate
% $g$ labelled by a structured function $$an indexing on its children that
% matches the index for the function that labels $g$. We allow these circuits to
% be defined over bases of structured functions with this more general symmetry
% condition

% In order then to include a gate computing rank in our symmetric circuit model
% we need to rec We are interested in circuit with gates that can compute rank
% and so, since rank is not a symmetric function, we develop a symmetric circuit
% model capable of incorporating non-symmetric functions in its basis. Moreover,
% we note that

% In particular, we are interested in Boolean functions that compute rank, i.e.
% functions that take in a binary matrix and compute the rank of that matrix
% over some prime field and compare the result with some threshold. But clearly
% this rank function is not symmetric. Furthermore, its evaluation depends on
% how the input set is labelled to form a matrix.

% In this section we develop the

% allowing us to develop natural symmetry conditions on the functions in terms
% of symmetry conditions on the structure. This indexing allows us to generalise
% the notion of a symmetric function by relativising the symmetry condition in
% accord with the structure on the input string. Incorporating this indexing
% into the circuit and



% ore recently, they have played a role in finite model theory, with many
% authors (e.g. ) studying circuit models that take in some representation of a
% finite algebraic structure and which obey certain natural symmetry conditions.
% However, there are some subtleties in the definition and evaluation of
% circuits which must be considered carefully and have important implications
% for the notion of a symmetric circuit studied in this paper. Let $C$ be a
% Boolean circuit $g$ be an internal gate labelled by some function $f_g:
% \{0,1\}^{A} \rightarrow \{0,1\}$, for some index set $A$ with $\vert A \vert =
% \vert H_g \vert$. Formally, evaluating $g$ requires a (usually bijective)
% indexing function $f_i: A \mapsto H_g$, which organises the inputs of $g$ into
% an appropriate sequence. The evaluation of $g$ is then given by $C[\vec{x}](g)
% = f_g (a \mapsto C[\vec{x}](f_i(a)))$. As such the evaluation of a gate in a
% circuit may depend on how the inputs to the gate are indexed.

% In most contexts in complexity theory, circuits may be taken to be implicitly
% ordered objects and so this indexing function can be defined as taking the
% $i$th element of $A$ to the $i$th element of $H_g$. However, in general this
% renders the evaluation of a circuit for a given input a property both of the
% circuit and an arbitrary order. In order to address this problem this problem
% many authors only define circuits over Boolean bases of symmetric functions
% (e.g. the standard basis or the majority basis). In this case the evaluation
% of a gate is independent of the choice of indexing function.

% However, in this paper we require gates labelled by Boolean rank functions,
% i.e. a function that takes in a Boolean sequence indexed by `row' and `column'
% sets, outputs 1 iff that matrix, when interpreted as having entries in
% $\mathbb{F}_p$, has rank at least $r$. These rank functions clearly depend on
% how the input sequence is labelled, and so are not symmetric. However, it is
% worth noting that while such rank functions may be symmetric, they are
% symmetric in the weaker sense of being constant under permutations on the rows
% and columns of the input matrix.

% Motivated by the desire to study circuits with gates that compute rank, We
% develop a general framework for circuits that allows gates to be labelled by
% Boolean functions of the form $F: \{0,1\}^{X} \rightarrow \{0, 1\}$, where the
% labelling $X$ is the universe of a many-sorted structure over some vocabulary
% $\tau$. The Moreover, we generalise the notion of a circuit for structures
% (see Anderson and Dawar \cite{AndersonD17}), incorporate an appropriate
% labelling for the inputs of each gate and allowing for a Boolean basis
% including non-symmetric functions. Furthermore, the vocabulary $\tau$ will
% allow us to impose natural symmetry conditions on $F$, and so allowing us to
% develop a useful notion of a symmetric circuit.

% We also prove that no family symmetric functions defined over a basis of
% symmetric functions can improve on the expressive power of the circuit model
% of Anderson and Dawar \cite{AndersonD17}. Together with the main theorem of
% this paper this implies that these more general symmetric circuits are
% strictly more powerful

% consider the problem of explicitly labelling the input of the function both so
% that the semantics of the function can be reasonably defined and so as to
% ensure that appropriate symmetry conditions on the function can be enforced.


% labelled by functions that are not symmetric, we need to think explicitly
% about how the input is to be labelled and how that structure should be
% mirrored in the circuit definition. In particular, we should like to consider
% functions which invariant under some action and so choose labellings which
% appropriately reflect the required symmetry conditions of the function.

% In this section we first discuss how to structure the input to a Boolean
% function appropriately and how symmetries on that input structure induce
% useful symmetries on the function.

\subsection{Structured Functions and Symmetry}
Let $X$ be a finite set and $F: \{0,1\}^{X} \rightarrow \{0,1\}$. We call $X$
the \emph{index} of $F$, and denote it by $\ind(F)$. We are often interested in
classes of functions characterised by certain symmetry conditions. Perhaps the
simplest example is the class of symmetric functions, i.e.\ those functions
invariant under the action of the symmetric group on their index. However, in
many cases this symmetry condition may be too strong, or otherwise
inappropriate. For example, suppose $X$ consists of all two element subsets of
some set $V$. We may think of $X$ as containing all potential edges in a graph,
and the input sequence $ \vec{x} \in \{0,1\}^X$ as encoding a graph. In this
case we might require instead that $F$ be invariant under the action of $\sym_V$
on $\vec{x}$. This condition guarantees that $F$ determines a graph property,
and we call such a function \emph{graph-invariant}. Another example of interest,
especially in this paper, is the case where $X := A \times B$, where $A$ and $B$
are non-empty sets, and we think of $\vec{x} \in \{0,1\}^X$ as encoding an
(unordered) matrix. It is natural then to consider the case where $F$ is
invariant under the action of $\sym_A \times \sym_B$, and we say such a function
is \emph{matrix-invariant}. In this subsection we develop a general framework
for dealing with functions that take in structures.

% AD - rewrote the paragraph to reduce the use of subscripts and superscripts.
Let $\tau = (R, S, \nu)$ be a many-sorted vocabulary. Let $D := \biguplus_{s \in
  S} D_{s} = \{(s,d) : d \in D_s\}$, be a disjoint union of non-empty sets,
indexed by $S$. For $R_i \in R$ let $R^D_i$ denote the trivial relation over the
many-sorted universe $D$, i.e.\ $R^D_i := D_{a_1} \times \ldots \times
D_{a_{r}}$, where $\nu(R_i) = (a_1, \ldots , a_{r)})$. There is an obvious
interpretation of $\tau$ over $D$ given by assigning each sort symbol in $\tau$
in the obvious manner and each relation symbol in $\tau$ to the trivial relation
over $D$. We call this \emph{the structure defined by $(\tau, D)$}, and denote
it by $\str(\tau, D)$.

The idea is to use the tuples in the relations of this structure as an index
set, and with the automorphisms of this structure defining a group action. Let
the \emph{index defined by the pair $(\tau, D)$} be the set $\biguplus_{R_i\in
  R} R^{D}_i$. We often use this set to index the input to a Boolean function,
as such we abuse notation and denote the index defined by $(\tau, D)$ by
$\ind(\tau, D)$, and call $\tau$ the vocabulary and $D$ the universe of
$\ind(\tau, D)$.

% GW: move sorted permutations into the background section
For the remainder of this subsection we fix a vocabulary $\tau$ and a
many-sorted set $D := \biguplus_{s \in S} D_{s}$, and let $X := \ind (\tau, D)$
and $G \leq \sym_{X}$. There is an obvious action of $G$ on $X$. There is also
an obvious action of the automorphism group $\str(\tau, D)$ on $X$ (with
permutations in $\str(\tau, D)$ acting element-wise on tuples in $X$). We denote
this group by $\aut(\tau, D)$, and identify it with the subgroup of $\sym_X$
that acts equivalently on $X$.

We can extend the action of $G$ on $X$ to an action on the set of functions of
the form $f: X \rightarrow H$, for any set $H$, defined by $\sigma \cdot f(x) :=
f(\sigma \cdot x)$ for all $x \in X$, $\sigma \in G$.

% and let $\sortsym_D := \prod_{s \in S} \sym_{D_{s}}$. We call the elements of
% $\sortsym_D$ \emph{sorted permutations}. Note that $\sortsym(D)$ can be
% identified with a subgroup of $\sym_X$.


% If $H$ is surjective, we say that \emph{$f$ indexes $H$ by $X$} or \emph{$f$
% indexes $H$ by $\mathcal{D}$}.

We say that two functions $f: \ind(\tau, D) \rightarrow H$ and $g: \ind(\tau',
D') \rightarrow H$ are \emph{isomorphism-equivalent} if there exists an
isomorphism $\pi :\str(\tau, D) \rightarrow \str(\tau', D')$ such that $f (x) =
g (\pi (x))$ for all $x \in \str(\tau, D)$. It is easy to see that
isomorphism-equivalence is an equivalence relation.

We are often interested in the case where $X = \ind(\tau, D) = \ind(\tau', D')$.
We say that $f, g X \rightarrow H$ are \emph{$G$-equivalent} if there exists
$\sigma \in G$ such that $f = \sigma \cdot g$. We note that in this case $f$ and
$g$ are \emph{isomorphism-equivalent} if, and only if, they are $\aut(\tau,
G)$-equivalent.

In this paper we will often let the co-domain $H$ be the binary symbols
$\{0,1\}$, and so consider functions of the form $f : X \rightarrow \{0,1\}$. In
this case we may think of $f$ as defining for each relation $R^D_i$ a subset of
that relation, and thus determining a $\tau$-structure over the universe $D$. We
note that two functions $f, g: X \rightarrow \{0,1\}$ are isomorphism-equivalent
if, and only if, the two $\tau$-structures they determine are isomorphic.

We call a function of the form $F:\{0,1\}^{X} \rightarrow \{0,1\}$ a
\emph{$(\tau, D)$-structured function}, or just a \emph{structured function}
when there is no need to emphasise the particular vocabulary. We note that
$\ind(F) = \ind(\tau, D)$, justifying our choice of notation. We let \emph{the
  vocabulary of $F$} and \emph{the universe of $F$} denote $\tau$ and $D$
respectively.

% It is easy to see that if $\mathcal{C}_A$ is the category with objects given
% by $\tau$-structures over $A$ and morphisms by the action of $G$, and
% $\mathcal{C}_X$ is the category of subsets of $X^{\tau}_A$ with morphisms
% similarly given by the action of $G$, then these two categories are
% equivalent. More informally, the subsets of $X^{\tau}_A$ encode the
% $\tau$-structures over $A$. This relationship is bijective and the action of
% $G$ factors through this bijection.

% \begin{remark}
%   Is the categorical language unnecessary? It seemed the quickest way of
%   saying what I wanted to say formally.
% \end{remark}

% \begin{remark}
%   In the above section (and just below) we talk about the action of
%   $\sym_{A_{s_1}} \times \ldots \times \sym_{A_{s_p}}$ on elements of
%   $X^\tau_A$ and structured functions. In the proof of the support theorem,
%   when defining a definable matrix for converting circuits into formulas, and
%   later on in this section, it is useful to speak more generally and instead
%   look at bijections from $A_1, \ldots A_{s_p}$ to $B_1, \ldots, B_{s_p}$,
%   thus allowing us to map between $X^\tau_A$ and $X^\tau_B$ and so between the
%   associated structured functions. I've added this in later on in the section,
%   but I still need to incorporate it into the original definition (it's a more
%   general notion in a sense, and so I think it should be incorporated). I'll
%   wait for feedback before doing this as I'm not sure this formulation will
%   survive.
% \end{remark}

Structured functions give us a general framework for indexing the input sequence
to a Boolean function and associating with that function an appropriate symmetry
condition, or notion of equivalence. Let $F$ be a $(\tau, D)$-structured
function. We say $F$ is \emph{$G$-invariant} if it is constant on $G$-equivalent
input vectors, i.e. for all $G$-equivalent $\vec{x}, \vec{y} \in \{0,1\}^{X}$,
$F(\vec{x}) = F(\vec{y})$. We say $F$ is \emph{isomorphism-invariant} if it is
$\aut(\tau, D)$-invariant. Note that a structured function with vocabulary
$\tau$ is isomorphism-invariant if, and only if, it decides a property of
$\tau$-structures.

At the beginning of this subsection we defined three Boolean functions with
differently indexed inputs and corresponding symmetry conditions. We now look at
how these functions might be thought of as structured functions, and how the
symmetry conditions we discussed are naturally reproduced. Suppose $\tau$ is
single-sorted and consists of a single unary relation. Then any structured
function $F$ with vocabulary $\tau$ is isomorphism-invariant if, and only if, it
is symmetric. If instead the vocabulary of $F$ is the graph vocabulary, then $F$
is isomorphism-invariant if, and only if, $F$ decides a property of directed
graphs. Lastly, if the vocabulary of $F$ has just two sorts $(s_1, s_2)$ and one
binary relation with type $(s_1, s_2)$, then $F$ is isomorphism-invariant if,
and only if, it is matrix-invariant.

In each case a natural choice of the structure indexes the input to the
structured function appropriately and produces the appropriate symmetry
condition. It is worth mentioning that the graph-invariant case is not strictly
reproduced above, as the structured functions are rather defined over directed
graphs.

From the above observations, we may think of symmetric functions as
isomorphism-invariant structured functions over the single-sorted vocabulary
with a single unary relation. We can similarly think of matrix-invariant
functions as isomorphism-invariant structured functions over the appropriate
vocabulary. More formally, if the vocabulary of $F$ consists of $p$ sort symbols
$s_1, \ldots , s_p$ and only one relation symbol with type $(s_1, \ldots, s_p)$
and $F$ is isomorphism-invariant, then we say $F$ is \emph{sort-invariant}. If
$p = 2$ and $F$ is sort-invariant then we say that $F$ is
\emph{matrix-invariant}.

In keeping with convention for Boolean functions, and for introducing simplicity
without a loss of generality, we assume that the universe of any structured
function is always a disjoint union of initial segments of the natural numbers,
i.e.\ if $F$ is structured function with universe $D_{s_1} \uplus \ldots \uplus
D_{s_p}$, then for all $s \in \{s_1 , \ldots , s_p\}$ there exists $d_s \in
\mathbb{N}$ such that $D_{s} = [d_s]$. We also assume that every $(\tau,
D)$-structured function has the property that every $a \in D$ appears in at
least one element of $\ind(\tau, D)$.


% Let $F$ be a $(\tau, A)$-structured function with $\tau = (\{R\}, \{1\},
% \nu)$, where $R$ is a binary relation. Let $G \leq \sym_A$ such that for any
% $v, w \in A$ We say $F$ is \emph{graph-symmetric} if $F$ is $(\tau, A)$simple
% and matrix-symmetric.

% If $\tau$ is single-sorted we call $F$ \emph{simple} and if it consists of a
% single unary relation, we call $F$ \emph{unary-relational}.



% We briefly introduce notions of equivalence useful for comparing functions.
% \begin{definition}
%   Let $\tau = (R, S, \nu)$ be a many-sorted signature and let $A = A_1 \times
%   \ldots A_s$ and $B = B_1 \times \ldots \times B_s$ be a product of non-empty
%   sets. A \emph{sorted bijection} between $A$ and $B$ is a function bijections
%   $f: A \rightarrow B$ such that $f (A_i) = B_i$ for all $i \in S$. There is
%   an obvious action of $f$ that maps $X^\tau_A$ to $X^\tau_B$ and
%   $\{0,1\}^{X^\tau_A}$ to $\{0,1\}^{X^\tau_B}$.

%   Let $L: X^\tau_A \rightarrow H$ and $L': X^\tau_B \rightarrow H$ be two
%   functions for some finite set $H$. We say that $L \sim L'$, or \emph{$L$ is
%   equivalent to $L'$}, if there is a sorted bijection $f: A \rightarrow B$
%   such that for all $x \in X^\tau_A$, $L(x) = L'(f (x))$.

%   Let $F$ be a $(\tau, A)$-structured function and $G$ be a $(\tau,
%   B)$-structured function. Then we say that $F \sim G$, or \emph{$F$ is
%   equivalent to $G$}, if there is a sorted bijection $f: A rightarrow B$ such
%   that for all $\vec{i} \in \{0,1\}^{X^\tau_A}$, $F (\vec{i}) =
%   G(f(\vec{i}))$.
% \end{definition}

% \begin{remark}
%   There is an obvious connection between $\tau$-symmetric functions and
%   generalised quantifiers (or closed classes of structures). Should I include
%   details about this connection? I also feel a lot of dirtiness might be
%   avoidable if we instead recast everything in terms of generalised
%   quantifiers. For one, generalised quantifiers give a natural way of defining
%   a Boolean function for each input universe.
% \end{remark}

\subsection{Symmetric Circuits}
% We define a circuit over a basis of structured functions that are not
% necessarily symmetric. As such, the circuit must include for each gate $g$ an
% index on its children corresponding to the index of the function labelling
% $g$.
In this section we extend the circuit definitions of Anderson and Dawar
\cite{AndersonD17}, introducing a circuit for structures that incorporates an
indexing for each gate in accordance with the Boolean function labelling that
gate. This allows us to define (and evaluate) circuits with gates labelled by
non-symmetric functions.

% Having developed the notion of a function that accepts input structured in
% accordance with some vocabulary, we now develop a circuit model which
% incorporates this structure on the inputs of a gate. We use this general
% framework to define the notion of a matrix-symmetric circuit, a circuit with
% gates labelled by matrix-symmetric Boolean functions, and finally we develop
% the notion of a matrix-symmetric circuit with rank.

% Importantly, many natural functions of interest are matrix symmetric. For
% example, the function that computes the rank of the matrix over
% $\mathbb{F}_2$. or a thresholded rank function, for example the rank of the
% matrix over $\mathbb{F}_p$ being larger then $r$, for some particular $(p, r)
% \in \mathbb{N}$.


We now define a \emph{$(\mathbb{B}, \tau)$-circuit} . This is a circuit that
computes a function on structures in the relational vocabulary $\tau$ and where
the gates are labelled by elements of the basis $\mathbb{B}$. Each element of
the basis is a $(\tau,D)$-structured function for some $\tau$ and $D$. Note
that, in the interests of keeping our definitions from getting excessively
complicated, we do not consider circuits computing functions over multi-sorted
vocabularies.

\begin{definition}[Circuits on Structures]
  Let $\mathbb{B}$ be a basis and $\tau$ be a relational vocabulary, we define a
  \emph{$(\mathbb{B}, \tau)$-circuit} $C_n$ computing a $q$-ary query $Q$ as a
  structure $\langle G, \Omega, \Sigma, \Lambda, L \rangle$.
  \begin{itemize}
    \setlength\itemsep{0mm}
  \item $G$ is called the set of gates of $C_n$ and $\vert C_n \vert := \vert G
    \vert$.
  \item $\Omega$ is an injective function from $[n]^q$ to $G$. The gates in the
    image of $\Omega$ are called the output gates. When $q = 0$, $\Omega$ is a
    constant function mapping to a single output gate.
  \item $\Sigma$ is a function from $G$ to $\mathbb{B} \uplus \tau \uplus
    \{0,1\} $ such that $\vert \Sigma^{-1} (0) \vert \leq 1$ and $\vert
    \Sigma^{-1} (1) \vert \leq 1$. Those gates mapped to $\tau \uplus \{0,1\}$
    are called input gates, with those mapped to $\tau$ called relational gates
    and those mapped $\{0,1\}$ called constant gates. Those gates mapped to
    $\mathbb{B}$ are called internal gates.
  \item $\Lambda$ is a sequence of injective functions $(\Lambda_{R_i})_{R_i \in
      R}$ such that $\Lambda_{R_i}$ maps each relational gate $g$ with $\Sigma
    (g) = R_i$ to the tuple $\Lambda_{R_i} (g) \in [n]^{r}$. When no ambiguity
    arises we write $\Lambda (g)$ for $\Lambda_{R_i} (g)$.
  \item $L$ associates with each internal gate $g$ a function $L(g):
    \ind(\Sigma(g)) \rightarrow G$ such that if we define a relation $W
    \subseteq G^{2}$ by $W(h_1,h_2)$ iff $h_2$ is an internal gate and $h_1$ is
    in the image of $L(h_2)$, then $(G, W)$ is a directed acyclic graph.
  \end{itemize}
\end{definition}

% \begin{definition}[Circuits on Structures]
%   Let $\mathbb{B}$ be a basis of structured functions and $\tau := (R, \{s_1,
%   \ldots, s_p\}, \nu)$ be a many-sorted vocabulary and let $\vec{n} :=
%   (n_{s_1}, \ldots , n_{s_p}) \in \mathbb{N}^{S}$, we define a
%   \emph{$(\mathbb{B}, \tau)$-circuit} $C_{\vec{n}}$ computing a $q$-ary query
%   $Q$ of type $(s^Q_{1}, \ldots , s^Q_{q})$ is a structure $\langle G, W,
%   \Omega, \Sigma, \Lambda, L\rangle$.
%   \begin{itemize}
%     \setlength\itemsep{0mm}
%   \item $G$ is called the set of gates of $C_{\vec{n}}$ and $\vert C_{\vec{n}}
%     \vert := \vert G \vert$.
%   \item $W \subseteq G \times G$, where $W$ is called the wires of the
%     circuit. $(G,W)$ must be a directed acyclic graph. For $g \in G$ we $H_g
%     := \{ h \in G: W(h,g)\}$ be the set of children of $g$.
%   \item $\Omega$ is an injective function from $[n_{i_1}] \times \ldots \times
%     [n_{i_q}]$ to $G$. The gates in the image of $\Omega$ are called the
%     output gates. When $q = 0$, $\Omega$ is a constant function mapping to a
%     single output gate.
%   \item $\Sigma$ is a function from $G$ to $\mathbb{B} \uplus \tau \uplus
%     \{0,1\} $ which maps input gates to $\tau \uplus \{0,1\}$ and where $\vert
%     \Sigma^{-1} (0) \vert \leq 1$ $\vert \Sigma^{-1} (1) \vert \leq 1$ and the
%     internal gates get mapped into $\mathbb{B}$. Gates mapped to $R$ are
%     called relational gates and gates mapped to 1 or 0 are called constant
%     gates.
%   \item $\Lambda$ is a sequence of injective functions $(\Lambda_{R'})_{R' \in
%     R}$ where for each $R' \in R$ with arity $r$ and type $(s^{R'}_{1},
%     \ldots, s^{R'}_{r})$, $\Lambda_{R'}$ maps each relational gate $g$ with
%     $R' = \Sigma (g)$ to the tuple $\Lambda_{R'} (g) \in [n_{s^{R'}_1}] \times
%     \ldots \times [n_{S^{R'}_r}]$. When no ambiguity arises we write $\Lambda
%     (g)$ for $\Lambda_{R'} (g)$.
%   \item $L$ maps to each internal gate a labelling on its children. Let $g$ be
%     an internal gate. We have that $L(g)$ is a surjection from $\ind (\Sigma
%     (g))$ to $H_g$. We call $L(g)$ the \emph{child-labelling} for $g$.
%   \end{itemize}
% \end{definition}

Let $C_n = \langle G, \Omega, \Sigma, \Lambda, L \rangle$ be a $(\mathbb{B},
\rho)$-circuit. The $n$ is used to indicates that $C_n$ accepts structures of
size $n$. For a gate $g \in C_n$, we define the \emph{index} of $g$, denoted by
$\ind(g)$, as $\ind(\Sigma(g))$. We define the relation $W \subseteq G^2$ by
$W(h,g)$ if, and only if, $h \in \range(L(g))$. For each $g \in G$ we let
$W(\cdot, g) := \{h \in G : W(h,g)\}$ and $W(g, \cdot) := \{h \in G : W(g,h)\}$.
We call the elements of $W(\cdot, g)$ the \emph{children} of $g$ and the
elements of $W(g, \cdot)$ the \emph{parents} of $g$. We also abbreviate $W(g,
\cdot)$ by $H_g$.

We let the vocabulary and universe of $g$ be the vocabulary and universe of
$\Sigma(g)$, respectively, and denote the vocabulary of $g$ by $\vocab{g}$ and
the universe by $\universe{g}$. We also let $\aut(g) := \aut(\tau, D)$ and
$\str(g) := \str(\tau, D)$.

% It is worth noting that in general computing the syntactic equivalence
% relation in polynomial time may not be possible. In fact, given two bipartite
% graphs it is possible to construct (in time polynomial in the size of the
% graphs) a circuit with gates labelled by matrix-symmetric functions such that
% two specified gates are syntacticly equivalent if,and only if, the two
% bipartite graphs are isomorphic. Since there is a polynomial time reduction
% from the graph isomorphism problem to the graph isomorphism problem on
% bipartite graphs, it follows that there is a polynomial time reduction from
% the graph isomorphism to the problem of computing syntactic equivalence. We
% formalise this result in the following proposition, and give the explicit
% construction referenced.

% \begin{prop}
%   There is a a polynomial time reduction from Graph Isomorphism to the problem
%   of deciding if two specified gates in a matrix-circuit are syntacticly
%   equivalent.
% \end{prop}
% \begin{proof}
% \end{proof}

% In contrast, in the restricted case where the gates of the circuit are
% labelled only by symmetric Boolean functions then the syntactic equivalence
% relation can be computed in polynomial time.

% \begin{prop}
%   Let $C_n$ be a circuit with symmetric gates. Then the problem of syntactic
%   equivalence relation on the gates of $C_n$ can be computed in polynomial
%   time.
% \end{prop}
% \begin{proof}
% \end{proof}

Let $\tau$ be a relational vocabulary, $\mathcal{A}$ a $\tau$-structure over an
$n$-element universe $U$ and $\gamma \in [n]^{\underline{U}}$. Let $\gamma
\mathcal{A}$ be the structure on universe $[n]$ formed by mapping $U$ in
accordance with $\gamma$. The evaluation of a $(\mathbb{B}, \tau)$-circuit $C_n$
computing a $q$-ary query $Q$ proceeds by recursively evaluating the gates in
the circuit. The evaluation of the gate $g$ for the bijection $\gamma$ and input
$\mathcal{A}$ is denoted by $C[\gamma \mathcal{A}](g)$, and is given as follows
\begin{enumerate}
  \setlength\itemsep{0mm}
\item If $g$ is a constant gate then it evaluates to the bit given by
  $\Sigma(g)$.
\item If $g$ is a relational gate then $g$ evaluates to true iff $\gamma
  \mathcal{A} \models \Sigma(g)(\Lambda (g))$.
\item If $g$ is an internal gate such that $\Sigma (g)$ let $L^{\gamma}_g:
  \ind(g) \rightarrow \{0,1\}$ be defined by $L^{\gamma}_g(x) = C[\gamma
  \mathcal{A}](L(g)(x))$, for all $x \in \ind(g)$. Then $g$ evaluates to true
  iff $\Sigma(g) (L^{\gamma}_g) = 1$.
\end{enumerate}
We say that $C_n$ defines the $q$-ary query $Q \subseteq U^q$ under $\gamma$
where $\vec{a} \in Q$ if, and only if, $C_n[\gamma \mathcal{A}](\Omega (\gamma
\vec{a})) = 1$.

% The circuit $C_n$ The following definition is an important circuit property
% introduced by Anderson and Dawar \cite{AndersonD17}. We introduce it for the
% sake of comparison.

The following circuit condition is from Anderson and Dawar \cite{AndersonD17}.

\begin{definition}[Invariant Circuit]
  Let $C_n$ be a $(\mathbb{B}, \tau)$-circuit, computing some $q$-ary query. We
  say $C_n$ is \emph{invariant} if for every $\tau$-structure $\mathcal{A}$ of
  size $n$, $\vec{a} \in U^{q}$, and $\gamma_1, \gamma_2: [n]^{\underline{U}}$
  we have that $C[\gamma_1 \mathcal{A}](\Omega (\gamma_1 \vec{a})) = C[\gamma_2
  \mathcal{A}](\Omega (\gamma_2 \vec{a}))$.
\end{definition}

In other words $C_n$ is invariant if the evaluation of the circuit on any
$n$-element structure $\mathcal{A}$ does not depend on the particular map
$\gamma$ that takes the universe of the structure to $[n]$. In general, the
evaluation of a circuit depends on the presentation of the structure (i.e.\ the
bijection $\gamma$). If a family of $(\mathcal{B}, \tau)$-circuits $\mathcal{C}$
is invariant it follows that the query computed is a $q$-query on
$\tau$-structures. Thus if $q = 0$ then $\mathcal{C}$ computes a property of
$\tau$-structures. The following lemma allows us to recast this notion in terms
of the language developed in this paper.

\begin{lem}
  Let $C_n$ be a $(\mathbb{B}, \tau)$-circuit. The function computed by $C_n$ is
  $\tau$-invariant if, and only if, $C_n$ is an invariant circuit.
\end{lem}
% AD - does this require a few lines of proof? GW - To be added. I have not done
% this yet.

% \begin{definition}[Automorphism]
%   let $C = \langle G, \Omega, \Sigma, \Lambda, L\rangle$ be a
%   $(\mathbb{B},\tau)$-circuit computing a $q$-ary query on structures of size
%   $n$, and where $\mathbb{B}$ is a basis of isomorphism-invariant structured
%   functions. Let $\sigma \in \sym_n$ and $\pi: G \rightarrow G$ be a bijection
%   such that
%   \begin{itemize}
%     \setlength\itemsep{0mm}
%   \item for all output tuples $x \in [n]^q$, $\pi \Omega (x) = \Omega (\sigma
%     x)$,
%   \item for all gates $g \in G$, let $\Sigma (g) = \Sigma (\pi g)$,
%   \item for each relational gate $g \in G$, $\sigma \Lambda (g) = \Lambda (\pi
%     g)$, and
%   \item For each pair of gates $g, h \in G$ $W(h,g)$ iff $W(\pi h, \pi g)$ and
%     for each internal gate $g$ we have that $L(\pi g)$ and $ \pi \cdot L(g)$
%     are isomorphism-equivalent.
%   \end{itemize}
%   We call $\pi$ an \emph{automorphism} of $C$, and we say that $\sigma$
%   \emph{extends to an automorphism} $\pi$. The group of automorphisms of $C$
%   is called $\aut (C)$.
% \end{definition}

% It can be shown that $P$-uniform families of invariant circuits over the
% standard basis can decide exactly those languages in $\PT$\cite{}. In this
% paper, we are instead interested in circuits with broader symmetry properties.
% We first define the notion of automorphism for circuits.

We now define the notion of an automorphism of circuit.

\begin{definition}[Automorphism]
  let $C = \langle G, \Omega, \Sigma, \Lambda, L\rangle$ be a
  $(\mathbb{B},\tau)$-circuit computing a $q$-ary query on structures of size
  $n$, and where $\mathbb{B}$ is a basis of isomorphism-invariant structured
  functions. Let $\sigma \in \sym_n$ and $\pi: G \rightarrow G$ be a bijection
  such that
  \begin{itemize}
    \setlength\itemsep{0mm}
  \item for all output tuples $x \in [n]^q$, $\pi \Omega (x) = \Omega (\sigma
    x)$,
  \item for all gates $g \in G$, let $\Sigma (g) = \Sigma (\pi g)$,
  \item for each relational gate $g \in G$, $\sigma \Lambda (g) = \Lambda (\pi
    g)$, and
  \item For each pair of gates $g, h \in G$ $W(h,g)$ if and only if $W(\pi h,
    \pi g)$ and for each internal gate $g$ we have that $L(\pi g)$ and $ \pi
    \cdot L(g)$ are isomorphism-equivalent.
  \end{itemize}
  We call $\pi$ an \emph{automorphism} of $C$, and we say that $\sigma$
  \emph{extends to an automorphism} $\pi$. The group of automorphisms of $C$ is
  called $\aut (C)$.
\end{definition}

We are particularly interested in circuits that have the property that every
permutation in $\sym_n$ extends to an automorphism of the circuit.

\begin{definition}[Symmetry]
  A circuit $C$ on structures of size $n$ is called \emph{symmetric} if every
  $\sigma \in \sym_n$ extends to an automorphism on $C$.
\end{definition}

It follows that for any symmetric circuit $C_n$ there is a homomorphism $h$ that
maps $\sym_n$ to $\aut(C_n)$, taking any $\sigma \in \sym_n$ to an automorphism
that extends it. Suppose $C_n$ contains no relational gates of non-zero arity.
In that case $C_n$ computes a constant function. As such, in this paper we
always assume a circuit contains at least one relational gate with non-zero
arity. There there exists a relational gate in $C_n$ with some element of $[n]$
appearing in the tuple labelling that gate. By symmetry it follows that all
elements of $[n]$ appear in tuples labelling relational gates in $C_n$. Thus no
two distinct elements of $\sym_n$ agree on all input gates, and so the
homomorphism $h$ is injective.

If this homomorphism is also surjective then we have that each element of
$\sigma$ extends uniquely to an automorphism of the circuit. Since many of the
technical tools developed in this paper require that circuits have this
property, we restrict our attention to classes of circuits that have
\emph{unique extensions}.

\begin{definition}
  We say that a circuit $C_n$ has \emph{unique extensions} if for every $\sigma
  \in \sym_n$ there is at most one $\pi_{\sigma} \in \aut(C_n)$ such that
  $\pi_{\sigma}$ extends $\sigma$.
\end{definition}

Anderson and Dawar~\cite{AndersonD17} introduce the notion of a \emph{rigid}
circuit, and show that, for circuits defined over a basis of symmetric functions
there is a polynomial-time algorithm that takes as input a symmetric circuit and
outputs an equivalent rigid symmetric circuit. They also show that rigid
circuits have unique extensions, allowing them to conclude that $P$-uniform
families of symmetric circuits over bases of symmetric functions may be assumed
to be rigid (and hence have unique extensions) without a loss of generality.

While we establish an approximately analogous argument, unfortunately, for the
general $(\mathbb{B}, \tau)$-circuit, establishing an exactly analogous
condition is a non-trivial problem. We discuss this problem in more detail in
Section \label{sec:transparency-and-unique-extensions}.

We now introduce the notion of a circuit with \emph{unique labels}, and show
that if a circuit has unique labels then it has has unique extensions. Before we
do so, we define the \emph{syntactic equivalence} relation on the gates of a
circuit.

% In order to prove this result, Anderson and Dawar introduce the notion of a
% \emph{rigid} circuit, proving that symmetric circuits may be

% However, it is not obvious that it is possible to generalise this result. We
% show in Proposition \ref{}, that for the general $(\mathbb{B}, \tau)$-circuit,
% the problem of deciding if a given circuit has unique extensions is at least
% as hard as the graph isomorphism problem. As such, we instead define a the
% notion of a circuit having \emph{unique labels} and show that if a circuit has
% unique labels then we may assume it has unique extensions. We then explicitly
% restrict ourselves to circuits with unique labels.

% When analysing circuits we are often interested in identifying families of
% gates that We are interested not just in the case where the labelling function
% $L(g)$ is an injection but when there are no two gates in its image that are
% in some broader sense the same. Of course we cannot efficiently decide if two
% gates in a circuit compute the same function (unless SAT is in $\P$). We may,
% however, consider a weaker relation on gates -- a syntactic condition which
% encodes the idea that the circuits underneath two gates are in some sense the
% same. We define this notion formally below. Before we do we define what it
% means for two functions to be isomorphism-equivalent up to an equivalence
% relation.

% We will often be interested in the case where two functions are
% isomorphism-equivalent up to syntactic equivalence. We define this notion (for
% an arbitrary equivalence relation) below.

\begin{definition}
  Let $\tau$ be a many-sorted vocabulary and $D$ be a $\tau$-sorted set. Let X
  be a set and $\sim$ be an equivalence relation defined on $X$. Let $Y, Z
  \subset X$. We say two functions $f : \ind(\tau,D) \rightarrow X$ and $g :
  \ind(\tau, D) \rightarrow Y$ are \emph{isomorphism-equivalent up to $\sim$} if
  $Y/{\sim} = X/{\sim}$ and $f/{\sim}$ is isomorphism-equivalent to $g/{\sim}$.
\end{definition}

\begin{definition}
  Let $C_n$ be a $(\mathbb{B}, \tau)$-circuit such that $C_n = \langle G, W,
  \Omega, \Sigma, \Lambda, L\rangle$. We recursively define the equivalence
  relation \emph{syntactic equivalence}, which we denote using the symbol
  `$\equiv$', on $G$ as follows. We say $g \equiv h$ if (i) $\Sigma(g) =
  \Sigma(h)$, (ii) if $g$ and $h$ are constant gates then they are equal, (iii)
  if $g$ and $h$ are relational gates then $\Lambda(g) = \Lambda(h)$, (iv) if
  $g$ and $h$ are internal gates then the functions $L(g)$ and $L(h)$ are
  isomorphism-equivalent up to syntactic equivalence, and (v) if $g$ and $h$ are
  output gates then $\Omega^{-1}(g) = \Omega^{-1}(h)$.
\end{definition}

It is easy to show that determining if two gates in a given circuit compute the
same function is $NP$-complete. The syntactic-equivalence relation defines a
weaker relation between gates, instead identifying gates that have `hereditary
similar' circuits defining them. It is easy to show that, for a circuit $C_n$,
if $\sigma \in \sym_n$ and $\pi, \pi' \in \aut(C_n)$ extend $\sigma$, then for
every gate $g$ in $C_n$, $\pi (g)$ and $\pi'(g)$ are syntactically equivalent.

We now introduce the \emph{unique labels} condition.

\begin{definition}
  Let $C_n$ be a circuit and $g$ be a gate in $C_n$. We say $g$ has
  \emph{injective labels} if $L(g)$ is an injection. We say $g$ has \emph{unique
    labels} if $L(g)$ has injective labels and no two gates in $\range(L(g))$
  are syntactically equivalent. We say $C_n$ has \emph{injective labels} (resp.
  \emph{unique labels}) if every gate in $C_n$ has injective labels (resp.
  unique labels). We say $C_n$ is \emph{transparent} if every non-symmetric gate
  in $C_n$ has unique labels.
\end{definition}

Let $C_n$ be a circuit and $W_t$ be the transitive closure of the $W$ relation
on $C_n$. We note that a circuit $C_n$ may have an internal gate $g$ such that
for every output gate $g'$, $\neg W_t(g, g')$ (i.e. there is no path from $g$ to
any output gate). We call such a gate \emph{redundant}, as their inclusion in
the circuit can not possibly have any bearing on the function computed by the
circuit. It can be shown that given a circuit $C_n$ with redundant gates we may
construct a new circuit $C_n'$ by simply removing the redundant gates. Moreover,
this process preserves important circuit properties and can be done efficiently.
We state and prove this formally in Lemma \ref{lem:redudant-gates}.

% \begin{definition}
%   Let $C_n = \langle G, \Omega, \Sigma, \Lambda, L \rangle$ be a circuit
%   computing a $q$-ary query. We say a gate $g \in G$ is \emph{redundant} if
%   there is no $\vec{a} \in [n]^q$ such that $W_t(g, \Omega (\vec{a}))$.
% \end{definition}

% We note that the definition of a circuit allows for the inclusion of gates
% that are never used when evaluating the circuit. That is, for a circuit $C_n$
% let $W_t$ be the transitive closure of $W$. It may be the case that there
% exists a gate $h$ in $C_n$ such that there is no output gate $g$ with $W_t(h,
% g)$.

\begin{lem}
  There exists an algorithm that takes as input a $(\mathbb{B}, \tau)$-circuit
  $C_n = \langle G, \Omega, \Sigma, \Lambda, L \rangle$ computing a $q$-ary
  query and outputs a $(\mathbb{B}, \tau)$-circuit $C_n'$ such that (i) every
  gate in $C_n$ is in $C_n'$, (ii) $C_n$ and $C_n'$ compute the same query,
  (iii) no gate in $C_n'$ is redundant, (iv) if $C_n$ is symmetric then $C_n'$
  is symmetric, (v) if $C_n$ has unique labels then $C_n'$ has unique labels,
  and (vi) if $C_n$ is transparent then $C_n'$ is transparent. This algorithm
  runs in time polynomial in the size of the input circuit.
  \label{lem:redudant-gates}
\end{lem}
\begin{proof}
  We construct the sub-circuit $C_n'$ of $C_n$ by removing all redundant gates
  in $C_n$. Since $W_t$, the transitive closure of $W$, can be computed in time
  polynomial in the size of the circuit, this construction can be completed in
  time polynomial in the size of $C_n$.

  Conditions (i), (ii), (iii), (v) and (vi) follow obviously for $C_n'$. Suppose
  $C_n$ is symmetric and let $\sigma \in \sym_n$. Let $\pi$ be an automorphism
  of $C_n$ extending $\sigma$. Let $g$ be a gate in $C_n'$. Then there exists
  $\vec{a} \in [n]^q$ such that $W_t(g, \Omega(\vec{a}))$ in $C_n$. It can be
  shown that $W_t (\pi(g), \Omega(\sigma(\vec{a})))$. Thus $\pi (g)$ is in
  $C_n'$, and so restricting $\pi$ to the gates of $C_n'$ is an automorphism of
  $C_n'$ extending $\sigma$. It follows that $C_n'$ is symmetric.
\end{proof}

Given Lemma \ref{lem:redudant-gates}, we may assume, without a loss of
generality, that a circuit has no redundant gates. In this paper we make this
assumption of every circuit unless stated otherwise.

We now show that unique labels are sufficient for unique extensions.

\begin{prop}
  Let $C_n := \langle G, \Omega, \Sigma, \Lambda, L\rangle$ be a $\mathbb{B},
  \tau)$-circuit. If $C_n$ has unique labels then $C_n$ has unique extensions.
  \label{prop:unique-labels-unique-extensions}
\end{prop}
% \begin{prop}
%   Let $C_n := \langle G, \Omega, \Sigma, \Lambda, L\rangle$ be an injective
%   $(\mathbb{B}, \tau)$-circuit. Then $C_n$ has unique labels if, and only if,
%   $C_n$ has unique extensions.
% \end{prop}
\begin{proof}
  Suppose $C_n$ has unique labels. Let $\pi_{\sigma}, \pi_{\sigma}' \in
  \aut(C_n)$ be automorphisms extending $\sigma \in \sym_n$. We now prove that
  $\pi_\sigma = \pi_{\sigma}'$. It is sufficient to show that $\pi :=
  \pi_{\sigma}'\pi^{-1}_\sigma$ is the trivial automorphism on the circuit. It
  is easy to see that $\pi$ extends the trivial permutation $e \in \sym_n$. Thus
  $\pi$ acts trivially on input gates and output gates in the circuit, as $\pi$
  acts as $e$ on relational gates and for any output gate $g$ there exists
  $\vec{a} \in [n]^q$ such that $\pi (g) = \pi (\Omega(\vec{a})) = \Omega(e \dot
  \vec{a}) = \Omega(\vec{a}) = g$.

  It can be shown by induction that, since $\pi$ extends the trivial
  permutation, for all gates $g \in G$, $\pi(g)$ is syntactically equivalent to
  $g$. Let $W_t$ be the transitive closure of the relation $W$ on $C_n$. Let $g
  \in G$ and suppose $\pi (g) = g$. Then $\pi H_{g} = H_g$ and, since $g$ has
  unique labels, it follows that $\pi$ acts trivially on $H_g$ (i.e. for all $h
  \in H_{g}$, $\pi(h) = h$). It follows by induction that for all $h \in G$ if
  $W_t(h, g)$ then $\pi (h) = h$. Since the circuit contains no redundant gates,
  it follows that $G = \bigcup_{\vec{a} \in [n]^q} \{g \in G : W_t (g,
  \Omega(\vec{a}))\}$. Thus, since $\pi$ acts trivially on output gates, we have
  that for all $g \in G$, $\pi (g) = g$. The result follows.
    
  % Suppose $C_n$ does have not have unique labels. For every such gate $g \in
  % G$ let $D(g)$ be the distance from $g$ to the set of output gates. From the
  % hypothesis there exists $g \in G$ such that $h, h' \in H_g$ and $h \equiv
  % h'$. Let $g$ the gate in the circuit without unique labels and with minimal
  % $D(g)$. Then

  % to the set of output gates Order the set of all such gates by their distance
  % to the set of output gates, and let $g$ be the minimal gate in this set.


  % such that it is of minimal distance to the set of output gates. Let $e \in
  % \sym_n$ be the trivial permutation and $\pi \in \aut(C_n)$ be the unique
  % extension of $e$. We have that $\pi (g) = g$, as if $\pi (g) \neq g$
\end{proof}

We also show that a transparent circuit can be converted into an equivalent
circuit with unique labels in time polynomial in the size of the circuit. Since
we are working with $P$-uniform families of transparent circuits, this fact
allows us to assume, without a loss of generality, that transparent circuits
have unique labels. We prove this formally in Proposition
\ref{prop:transparent-unique}.

% \begin{definition}
%   We say that a circuit $C_n$ is \emph{rigid} if every equivalence class of
%   gates under the syntactic equivalence relation is a singleton.
% \end{definition}
% \

% We prove in Proposition~\ref{} that there is a polynomial time algorithm that
% takes in a symmetric circuit with unique labels and outputs an equivalent
% rigid circuit. It is worth noting that the requirement that the circuit have
% unique labels is very important (see Section \ref{} for a detailed discussion
% of this point). Since we are interested in $P$-uniform families of circuits,
% this result allows us to assume the rigidity of a circuit without a loss of
% generality. Moreover, as we will show in Proposition \ref{}, if a circuit is
% rigid then every $\sigma \in \sym_n$ has exactly one an extension to an
% automorphism of $C_n$, and so the above defined homomorphism mapping $\sym_n$
% to $\aut(C_n)$ is an isomorphism. Since we may assume rigidity without a loss
% of generality this property may also be assumed without a loss of generality.
% As such we abuse notation and let $\sigma \in \sym_n$ also denote the induced
% automorphism of the circuit.

% \begin{definition}[Rigidity]
%   Let $C_n$ be a $(\mathbb{B}, \tau)$-circuit, where $C_n = \langle G, W,
%   \Omega, \Sigma, \Lambda, L\rangle$. Say that $C_n$ is \emph{rigid} if there
%   are no distinct internal gates $g, g' \in G$ such that $\Sigma(g) = \Sigma
%   (g')$, $\Omega^{-1}(g) = \Omega^{-1}(g')$, $H_g = H_{g'}$, and $L(g')$ and
%   $L(g)$ are isomorphism-equivalent.
% \end{definition}

% Let $\MB$ be the set of all structured functions that are symmetric or
% matrix-invariant.

In many contexts, circuits are defined over a basis of symbols, usually the
usual logical symbols $\land, \neg, \lor$ and perhaps $\maj$ (for majority).
When evaluating a circuit, a gate labelled by a particular symbol is evaluated
using a Boolean function appropriate to the particular symbol. We have instead
defined a basis to be a set of Boolean functions. However, when reasoning about
circuits or dealing with them as inputs to algorithms we often want to identify
a function in the basis with a particular symbol. We now formally define a few
natural bases used in this paper, assigning to each function in these bases an
appropriate symbol.

Let $a \in \nats$, let $\land[a] : \{0,1\}^{[a]} \rightarrow \{0,1\}$ be the
structured function computing the $\AND$ operation on $a$ inputs. Let $\lor[a] :
\{0,1\}^{[a]} \rightarrow \{0,1\}$ be the structured function computing the
$\OR$ operation on $a$ inputs. Let $\maj [a] : \{0,1\}^{[a]} \rightarrow
\{0,1\}$ be the structured function computing the the majority function on $a$
inputs. We abuse notation and let $\neg : \{0,1\} \rightarrow \{0,1\}$ also
denote the structured function computing negation on a single input. In each
case we use the name of the function above as a symbol denoting that function.

Let the \emph{standard basis} $\BS$ be the basis containing $\neg$ and all
functions $\land[a]$ and $\lor[a]$ for every $a \in \nats$. Let the
\emph{majority basis }$\BM := \BS \cup \{\maj[a] : a \in \nats\}$. We say a
basis $\BB$ is \emph{symmetric} if every function in $\mathbb{B}$ is a symmetric
Boolean function.

Let $a, b, r, p \in \nats$, with $p$ prime. Let $\rank^r_p[a,b] : \{0,1\}^{[a]
  \times [b]} \rightarrow \{0,1\}$ be a matrix-invariant structured with
universe $[a] \uplus [b]$, such that $\rank^r_p[a,b](M) = 1$ if, and only if,
the matrix $M \in \{0,1\}^{[a] \times [b]}$ has rank at most $r$ when its
entries are understood as elements of the finite field $\mathbb{F}_p$. We again
identify the function $\rank^{r}_p[a,b]$ with the symbol $\rank^{r}_p[a,b]$.

Let the \emph{\rank basis} $\RB := \BM \cup \{\rank^{r}_p[a,b] : a, b, r, p \in
\nats, \text{ $p$ prime}\}$. We say a basis $\BB$ is \emph{matrix-symmetric} if
every function in $\BB$ is symmetric or matrix-symmetric.

% Let $C_n$ be a $(\mathbb{B}, \tau)$-circuit and let $g$ be a gate in $C_n$. We
% say $g$ is an \emph{\AND-gate} if $g$ is an internal gate labelled a function
% of the . We say $g$ is a a \emph{majority gate}

Let $C_n = \langle G, \Omega, \Sigma, \Lambda, L \rangle$ be a $(\mathbb{B},
\tau)$-circuit and let $g \in G$. We say a gate $g \in G$ is a \emph{symmetric
  gate} if $\Sigma(g)$ is a symmetric function. We say a gate $g \in G$ is a
\emph{matrix-symmetric gate} if $\Sigma(g)$ is a matrix-symmetric structured
function. We say that $g$ is an \emph{$\AND$ gate} if $\Sigma(g) := \land [a]$
for some $a \in \nats$. Similarly we define \emph{$\OR$- gates}, \emph{$\NOT$
  gates}, \emph{$MAJ$ gates} and \emph{$\rank$ gates}.

We say $C_n$ is a \emph{circuit with symmetric gates} if every gate in $C_n$ is
symmetric. We say $C_n$ is a \emph{matrix-circuit} if every gate in $C_n$ is
matrix-symmetric or symmetric. We say $C_n$ is a \emph{rank-circuit} if $C_n$ is
a matrix-circuit and every non-symmetric gate is a $\rank$ gate.

% \begin{definition}
%   Let $C_n = \langle G, \Omega, \Simga, \Lambda, L \rangle$ be a $(\mathbb{B},
%   \tau)$-circuit. Let $g \in $ Let $\mathbb{B} \subseteq \MB$. We call a
%   symmetric $(\mathbb{B}, \tau)$-circuit with unique labels a \emph{symmetric
%   matrix-circuit}.
% \end{definition}

% \begin{definition}
%   Let $\mathbb{B} \subseteq \MB$. We call a symmetric $(\mathbb{B}_\rank,
%   \tau)$-circuit with unique labels a \emph{symmetric rank-circuit}.
% \end{definition}

% The natural restriction to consider on families of circuits is uniformity.

% \begin{definition}
%   Let $(C_n)_{n \in \mathbb{N}}$ be a family of Boolean circuits. We say that
%   $(C_n)_{n \in \mathbb{N}}$ is \emph{$P$-uniform} if the mapping $n \mapsto
%   C_n$ is computable in polynomial time.
% \end{definition}
We are now ready to state the main theorem of this paper.

\begin{thm}[Main Theorem]
  A graph property is decidable by a $P$-uniform family of transparent symmetric
  rank-circuits if, and only if, it is definable by an $\FPR$ sentence.
\end{thm}



% Anderson and Dawar use the above proposition (or, rather, an analogous
% relation) in order to


% an automorphism of a circuit $C_n$ from the elements to $\aut(C_n)$. In the
% following sections this fact

% It is worth noting that in general computing the syntactic equivalence
% relation in polynomial time may not be possible. In fact, given two bipartite
% graphs it is possible to construct (in time polynomial in the size of the
% graphs) a circuit with gates labelled by matrix-symmetric functions such that
% two specified gates are syntacticly equivalent if,and only if, the two
% bipartite graphs are isomorphic. Since there is a polynomial time reduction
% from the graph isomorphism problem to the graph isomorphism problem on
% bipartite graphs, it follows that there is a polynomial time reduction from
% the graph isomorphism to the problem of computing syntactic equivalence. We
% formalise this result in the following proposition, and give the explicit
% construction referenced.

\subsection{Limitations of Symmetric Bases}
In this section we show that any family of symmetric circuits over an arbitrary
basis of symmetric functions can be transformed in polynomial time into a family
of symmetric circuits that decide the same language but are defined over the
basis $\mathbb{B}_\maj$. In other words, it makes no difference to the
expressive power of such circuits whether we include \emph{all} symmetric
functions in the basis or just $\mathbb{B}_\maj$. It follows that in order to
construct $P$-uniform families of symmetric circuits that define queires not in
$\FPC$, we need to consider bases with non-symmetric functions.

% Recall from Anderson and Dawar \cite{AndersonD17} we have that
% $\mathbb{B}_{\std} = \{ \neg , \wedge , \lor \}$ and $\mathbb{B}_\maj = \{
% \maj \} \cup \mathbb{B}_{\std}$.

Let $F : \{0,1\}^n\rightarrow \{0,1\}$ be a symmetric Boolean function. Recall
that the output of $F$ is entirely determined by the number of $1$s in its
input. Let $c_{F} \subseteq [n]$ be the set of all $m \leq n$ such that for all
$\vec{x} \in \{ 0,1 \}^n$ with $m$ $1$s we have $F (\vec{x}) = 1$. Clearly any
symmetric function $F$ is entirely determined by $c_{F}$. As such, $F$ may be
encoded by a tuple $f \in \{0,1\}^{n}$, where $f (i) = 1 $ iff $i \in c_{F}$. We
assume this encoding below.
 
\begin{prop}
  \label{prop:fuctions-maj}
  There is a deterministic algorithm that outputs for each symmetric function
  $F: \{0,1\}^n \rightarrow \{0,1\}$ (encoded as a binary $n$-tuple as above) a
  symmetric circuit $C$ defined over the basis $\mathbb{B}_\maj$ that computes
  $F$. Moreover, this function is computable in time polynomial in $n$ and the
  circuit $C$ has depth at most $5$, width at most $2n+2$ and size at most $5n +
  3$.
\end{prop}

\begin{proof}
  We have $c_{F}$ from the input. We now define $C$. We define the set of gates
  and wires of $C$ layer by layer as follows. The first layer consists of just
  the $n$ input gates labelled by the variables $x_1, \ldots , x_n$. The second
  layer consists of two `majority' gates for each $a \in c_{F}$, which we denote
  by $\maj_a$ and $\maj^{\neg}_a$. For each $a \in c_{F}$ there is one wire from
  each of $x_1, \ldots , x_n$ to $\maj_a$ and $\maj^{\neg}_a$. For all $a \geq
  \frac{n}{2}$, there are $2a - n$ wires from $0$ to $\maj_a$ and $2a - n + 2$
  wires from $0$ to $\maj^{\neg}_a$. For all $a < \frac{n}{2}$ there are $n -
  2a$ wires from $1$ to $\maj_a$ and $n - 2a - 2$ wires from $1$ to
  $maj^{\neg}_a$. The third layer consists of one `not' gate for each $a \in
  c_{F}$, which we denote by $\neg_a$. For each $a \in c_{F}$ there is a wire
  from $\maj^\neg_a$ to $\neg_a$. The fourth layer consists of one `and' gate
  for each $a \in c_{F}$, which we denote by $\countgate_a$. For each $a \in
  c_{F}$ there is a wire from each of $\maj_a$ and $\neg_a$ to $\countgate_a$.
  The fifth layer consists of just a single `or' gate, designated as the output
  gate, and for each $a \in c_{F}$ there is a wire from $\countgate_a$ to the
  output gate.

  We summarise the circuit up to the fourth layer as follows:
  \[
    \countgate_a = \begin{cases} \land ( \maj ( x_1, \ldots, x_n, \underbrace
      {0, \ldots, 0}_{2a - n} ), \neg ( \maj (x_1, \ldots , x_n, \underbrace{0,
        \ldots,
        0}_{2a - n + 2} ) )) &  a \geq \frac{n}{2} \\
      \land ( \maj ( x_1, \ldots, x_n, \underbrace {1, \ldots, 1}_{n - 2a} ),
      \neg ( \maj ( x_1, \ldots , x_n, \underbrace{1, \ldots, 1}_{n - 2a -2} )
      )) & a < \frac{n}{2}.
    \end{cases}
  \]
  We note that for an input vector $\vec{x}$, $count_a$ evaluates to 1 if, and
  only if, the number of 1's in $\vec{x}$ equals $a$. Thus we have that $C$
  evaluates to 1 if, and only if, there exists $a \in c_{F}$ such that the
  number of $1$'s in $\vec{x}$ equals $a$ if, and only if, $F (\vec{x}) = 1$.
  Moreover, it is easy to see that $C$ is symmetric and the algorithm defined
  runs in time polynomial in $n$.
  % AD - perhaps include a brief argument for why C is symmetric?

  Furthermore, notice that the first layer contains $n$ gates and the second
  layer contains at most $2 \vert c_{F} \vert \leq 2n$ gates. The third and
  fourth layer each contain at most $n$ gates. As such $C$ has size at most $n +
  2n + 2n + 1 + 2 = 5n +3$ (the additional 2 is for the constant gates). The
  width of $C$ is at most $2n + 2$, and the depth is at most $5$.
\end{proof}

\begin{thm}
  Let $\mathbb{B}$ be a basis of symmetric functions and let $(C_n)_{n \in
    \mathbb{N}}$ be a family of symmetric circuits defined over the basis
  $\mathbb{B}$. Then there exists a family of symmetric circuits $(C_n')_{n \in
    \mathbb{N}}$ defined over $\mathbb{B}_\maj$ that decides the same language.
  Moreover, the map $C_n \mapsto C_n'$ is polynomial-time computable and for
  each $n \in \nats$, $\vert C_n' \vert \leq (5 \cdot \vert C_n \vert + 3) \cdot
  \vert C_n \vert$.
\end{thm}

\begin{proof}
  From $C_n$ we construct $C_n'$ as follows. For each gate $g \in C_n$ labelled
  by a member of $\mathbb{B}$ we have a symmetric circuit $C_g$ from
  Proposition~\ref{prop:function-maj} that computes the same function as $g$.
  Then let $C_n'$ be as $C_n$ but with each gate $g \in C_n$ replaced by $C_g$.
  It is easy to see that $C_n'$ is symmetric. We also have that each gate $g$
  must have at most $\vert C_n \vert$ inputs, and so the size of $C_g$ is
  bounded by $5 \vert C_n \vert + 3$. Thus the size of $C_n'$ is bounded by
  $(5f(n)+3) f(n)$. This algorithm clearly runs in polynomial-time.
\end{proof}

This result gives us that for any family of circuits over an arbitrary basis of
symmetric functions we can construct another symmetric circuit family computing
the same function over the majority basis without a blowup in size. Moreover, we
also have that if the first family was uniform the second family will be as
well. As such, we cannot extend the power of the $P$-uniform symmetric circuits
families studied by Anderson and Dawar \cite{AndersonD17} by simply considering
alternative bases of symmetric functions, thus motivating the generalisation
developed in the previous subsection to non-symmetric functions.
\end{document}

