\documentclass[../paper.tex]{subfiles}
\begin{document}
In this section we construct for every query computable by a $P$-uniform family
of transparent symmetric rank-circuits a corresponding $\FPR$ formula. In the
first subsection we show that for a rank gate in the circuit, the rank of that
gate depends only on which elements of the input structure are assigned to the
support of $g$. We then construct for $g$ and an assignment to the support of
$g$ a matrix $M$ which has the same rank as the matrix defined at that gate. In
the second subsection we implement the construction of this matrix in $\FPC$,
and hence produce a formula for evaluating a rank gate in $\FPR$. This formula,
together with the Immerman-Vardi theorem and the work of Anderson and Dawar
\cite{AndersonD17}, allows us to both define and evaluate a $P$-uniform family
of circuits in $\FPR$, completing the result.

\subsection {Evaluating Circuits}
In this section let $\mathcal{C} = (C_n)_{n \in \mathbb{N}}$ be a family of
polynomial-size symmetric matrix-circuits with unique labels that compute a
$q$-ary query, and let $n_0$ be the constant in the hypothesis of the Support
Theorem. We also fix a structure $\mathcal{A}$ of size $n$ over the universe $U$
and an internal gate $g$ in the circuit $C_n$. In this subsection we show how to
evaluate $g$ in $\FPR$ for a given assignment to its support.

If $g$ is a symmetric gate then the results of Anderson and
Dawar~\cite{AndersonD17} will suffice for evaluating $g$. As such, we assume
that $g$ is a matrix-symmetric gate, and we let $A \times B := \ind(g)$.

Recall that in order to evaluate the gate $g$ we need to consider a bijection
$\gamma \in [n]^{\underline{U}}$, with the evaluation of $g$ given by
$C_n[\gamma \mathcal{A}](g)$. In this subsection we show that the evaluation of
$g$ depends only what $\gamma$ maps to $\consp(g)$. This result allows us to
characterise all those bijections for which $g$ evaluates to true using only
using only constant-size-domain injections in $U^{\consp(g)}$. In the next
subsection we use this succinct encoding, along with the fixed-point operator,
to evaluate the entire circuit.
 
It will often be important that two assignments to a support be
\emph{compatible} with one another in the sense that there is an injection over
the union of their domains which agrees with each assignment on their respective
domains. We formalise this in the following definition.

\begin{definition}
  Let $f \in Y^{\underline{X}}$ and $g : Z^{\underline{W}}$. We say that $f$ is
  \emph{compatible} with $g$, and we write $f \sim g$, if for all $a \in X \cap
  W$, $f(a) = g(a)$ and for all $a \in X \setminus W$ and $b \in W \setminus X$,
  $f(a) \neq g(b)$.
\end{definition}

It is also useful to have some notation for combining two compatible functions.
Let $f : X \rightarrow Y$ and $p: X' \rightarrow Y'$ be compatible injections.
Define the combination $(f | p): X \cup X' \rightarrow Y \cup Y'$ by
\begin{align*}
  (f \vert p) (x) =
  \begin{cases}
    f (x) & x \in X \\
    p (x) & x \in Y.
  \end{cases}
\end{align*}

We also introduce some notation for the case where $f: X \rightarrow Y$ is an
injection and $g: X \rightarrow Z$ be a function. Then we let $g_f : \range(f)
\rightarrow Z$ be defined by for all $a \in \range(Y)$, $g_f(a) := g \circ
f^{-1}(a)$.

Given an assignment $\gamma \in [n]^{\underline{U}}$, we can evaluate the child
gates of $g$, forming the matrix $L^{\gamma} : A \times B \rightarrow \{0,1\}$
defined by $L^{\gamma} (a,b) := C[\gamma \mathcal{A}](L(g)(a,b))$ for $(a,b) \in
A \times B$. We may then evaluate $g$ by taking $L^{\gamma}$ as the input to the
Boolean function labelling $g$. In the following Lemma we show that for any
$\gamma_1, \gamma_2 \in [n]^{\underline{U}}$ that agree on the support of $g$,
$L^{\gamma_1}$ is isomorphism-equivalent to $L^{\gamma_2}$. Since $g$ is matrix
symmetric, we may conclude that the evaluation of $g$ for $\gamma$ depends only
on the assignment to the support of $g$ (i.e. on what $\gamma$ maps to
$\consp(g)$).

\begin{lem}
  Let $g$ be a matrix-symmetric gate in $C_n$. Let $\eta \in
  U^{\underline{\consp(g)}}$ and $\gamma_1, \gamma_2 \in [n]^{\underline{U}}$
  such that $\gamma^{-1}_1 \sim \eta$ and $\eta \sim \gamma^{-1}_2$. Then
  $L^{\gamma_1}$ and $L^{\gamma_2}$ are isomorphism-equivalent.
  \label{lem:support-determines-evaluation}
\end{lem}

\begin{proof}
  We have that there exists a unique $\pi \in \sym_n$ such that $\pi \gamma_1 =
  \gamma_2$. Moreover, since $\gamma^{-1}_1$ and $\gamma^{-1}_2$ are both
  consistent with $\eta$, it follows that $\pi$ must fix $\consp(g)$ point-wise.
  Thus $L(g)$ is isomorphism-equivalent to $\pi L(g)$, and so there exists
  $(\sigma, \lambda) \in \sym_A \times \sym_B$ such that $\pi L(g) = L(g)
  (\sigma, \lambda)$.

  We then have that,
  \begin{align*}
    L^{\gamma_1} (a,b) &= C_n[\gamma_1 \mathcal{A}](L(g)(a,b))\\
                       & = C_n[\pi \gamma_1 \mathcal{A}][\pi L(g)(a,b)] \\
                       & = C_n[\gamma_2 \mathcal{A}][L(g)((\sigma, \lambda)(a,b))]\\
                       & = L^{\gamma_2} ((\sigma, \lambda) (a,b)),
  \end{align*}
  and it follows that $L^{\gamma_1} \sim L^{\gamma_2}$.
\end{proof}

For each gate $h \in C_n$ we associate with it a set $\Gamma_h$ consisting of
all those bijections which cause $h$ to evaluate to true, i.e. $\Gamma_h:=
\{\gamma \in [n]^{\underline{U}} : C[\gamma \mathcal{A}](h) = 1 \}$. Lemma
\ref{lem:supports-determine-evaluation} gives us that the membership of $\gamma$
in $\Gamma_h$ is entirely determined by what $\gamma$ maps to $\consp(h)$. As
such, we also associate with $h$ a set $\EV_h \subseteq
U^{\underline{\consp(g)}}$ consisting of all assignments to the support of $h$
for which $h$ evaluates to true, i.e. $\EV_h := \{ \eta:
U^{\underline{\consp(g)}} : \exists \gamma \in \Gamma_h \wedge \eta \sim
\gamma^{-1})\}$, and note that $\Gamma_h$ is entirely determined by $\EV_h$. The
important point to note is that each $\eta \in \EV_h$ is defined on a
constant-size domain, and as such $\EV_h$ gives us a succinct way of encoding
$\Gamma_h$.

We aim to show that we can recursively construct $\EV_g$. In particular, we show
that for any $\eta \in U^{\underline{sp(g)}}$, there is an $\FPR$-definable
matrix $M$ such that for any $\gamma \in [n]^{\underline{U}}$ with $\gamma^{-1}
\sim \eta$, $M$ is isomorphism-equivalent to $L^{\gamma}$. This result allows us
to decide the membership of $\eta$ in $\EV_g$, where $g$ is a $\rank^r_p$ gate,
by first defining $M$ for $\eta$, computing the rank of $M$ over the field of
characteristic $p$, and then checking if this result is less than or equal to
$r$.

For a gate $h \in H_g$, let $A_h := \{\vec{x} \in U^{\underline{\consp(h)}} :
\eta \sim \vec{x}\}$ be the set of assignment to the support of $h$ that are
compatible with $\eta$, our chosen assignment to the support of $g$. We should
also like to consider similar sets of assignments for other objects in the
circuit which may be permuted and which are relevant to $g$. More generally, let
$X$ be a set on which the left group action of $\sym_n$ is defined and let $s
\in X$. We let $A_s = \{\vec{x} \in U^{\underline{\consp(s)}} : \eta \sim
\vec{x}\}$. We will be particularly interested in the case where $X$ is the set
of `rows' or `columns' (i.e. $A$ or $B$) of the matrix indexing the inputs of
$g$.

Let $s \in X$ and $\vec{x}, \vec{x}' \in A_s$ and we say that $\vec{x}$ and
$\vec{x}'$ are \emph{mutually stable} if there exists $\sigma \in \stab(s) \cap
\spstab{g}$ such that $\vec{x} = \vec{x}' \cdot \sigma$. Note that mutual
stability is an equivalence relation on $A_s$, and we denote the equivalence of
two vectors $\vec{x}, \vec{x}' \in A_s$ by $\vec{x} \equiv_s \vec{x}'$.

\begin{lem}
  Let $X$ be a set on which the left group action of $\sym_n$ is defined, and
  let $\gamma: U \rightarrow [n]$ be a bijection such that $\gamma^{-1} \sim
  \eta$. Let $s \in X$ and let $\sigma, \sigma' \in \stab(\consp(g))$. Then
  $\sigma(s) = \sigma' (s)$ if, and only if, $\sigma \equiv_s \sigma'$.
  \label{lem:functions-well-defined}
\end{lem}

\begin{proof}
  (removed, to be included later)
  % Suppose $\sigma(s) = \sigma'(s)$. Take $x := \sigma(s)$. So then
  % $\gamma^{-1}(\sigma(s))$
\end{proof}

We now define a matrix. We begin by defining the index sets for the matrix.

Let $R^{\min} = \{\min (\orb(\row(h))) : h \in H_g\}$ and $C^{\min} = \{ \min
(\orb (\column(h))) : h \in H_g\}$, and let
\begin{align*}
  I = \{(i, \vec{x}): i \in R^{\min}, \vec{x} \in A_i\},
\end{align*}
and
\begin{align*}
  J = \{(j, \vec{y}): j \in C^{\min}, \vec{y} \in A_j\}.
\end{align*}

From Lemma \ref{lem:permutation-row-column} we have for any $(i, \vec{x}) \in I$
and $(j, \vec{y}) \in J$, corresponding vectors and permutations $\vec{r}$,
$\vec{c}$, $\sigma_r$ and $\sigma_c$. Let $h := L(g)(\sigma_r(i), \sigma_c
(j))$. We define the matrix $M : I \times J \rightarrow \{0,1\}$ by

\begin{align*}
  M((i , \vec{x}), (j, \vec{y})) := (\vec{x}_{\vec{r}} \vert \vec{y}_{\vec{c}}) \in EV_h.
\end{align*}

% Let $I /{\sim} = \{(i, [\vec{x}]): i \in R^{\min}, [\vec{x}] \in
% A_i/{\sim_i}\},$ and $J/{\sim} = \{(j, [\vec{y}]): j \in C^{\min}, [\vec{y}]
% \in A_j/{\sim_j}\}$. Let the matrix $M_{~} : I /{\sim} \times J / {\sim}
% rightarrow \{0,1\}$ be the function defined by $M_{~} ((i, [\vec{x}]) (j,
% [\vec{y}])) = M(((i, \vec{x}), (j, \vec{y})))$. Lemma
% \ref{lem:matrix-quot-well-defined} gives us that this function is
% well-defined.

% It remains to show that $M_{~} \sim L^{\gamma}$ for some $\gamma: U
% \rightarrow [n]$.

Let $X$ be a set on which the left action of $\sym_n$ is defined, and let $x \in
X$. Let $f \in U^{\underline{\consp(x)}}$ and $\gamma\in [n]^{\underline{U}}$,
then we let $\Pi^{\gamma}_{f} \in \spstab{g}$ be any permutation in $\sym_n$
such that $\Pi^{\gamma}_f (a) = \gamma (f(a))$ for all $a \in \consp(x)$. Note
that from Lemma \ref{lem:support_determine_action}, $\Pi^{\gamma}_f(x)$ is
well-defined independently of the particular choice of permutation.

Let $\alpha^{\gamma}: I \rightarrow A$ and $\beta^{\gamma}: J \rightarrow B$ be
defined by $\alpha^{\gamma} (i, \vec{x}) = \Pi^{\gamma}_{\vec{x}}(i)$ and
$\beta^{\gamma} (j, \vec{y}) = \Pi^{\gamma}_{\vec{y}}(j)$, respectively. It can
be shown that these functions are surjective.

\begin{lem} 
  For any bijection $\gamma : U \rightarrow [n]$ both $\alpha^{\gamma}$ and
  $\beta^{\gamma}$ are surjective.
  \label{lem:alpha-beta-surjective}
\end{lem}
\begin{proof}
  We show that $\alpha^{\gamma}$ is surjective, with the same result for
  $\beta^{\gamma}$ following similarly. Let $q \in A$ and let $i = \min
  (\orb_{\spstab{g}} (q))$. Then there exists $\sigma \in \spstab{g}$ such that
  $\sigma (i) = q$. Let $\vec{x} := \gamma^{-1} \sigma \vec{\consp}(i)$. Notice
  that for $a \in \consp(i)$ we have that $\vec{x}(a) = \gamma^{-1} (\sigma
  (a))$, and since $\gamma^{-1} \sigma \sim \eta$, it follows that $\vec{x} \in
  A_i$.

  For $a \in \consp(i)$ we have $\Pi^{\gamma}_{\vec{x}} (a) = \gamma
  (\vec{x}(a)) = \gamma \gamma^{-1} \sigma (a) = \sigma (a)$. From Lemma
  \ref{lem:support-determine-action} it follows that $\alpha(i, \vec{x}) = q$.
\end{proof}

% Note that $\alpha^{\gamma}$ and $\beta^{\gamma}$ can be lifted to functions on
% $I /{\sim}$ and $J /{\sim}$ respectively. Lemma
% \ref{lem:functions-well-defined} gives us that these liftings are
% well-defined.

% We now show that $\alpha^{\gamma}$ and $\beta^{\gamma}$ witness the fact that
% $M_{~}$ and $L^{\gamma}$ are isomorphism-equivalent. We first show that
% $\alpha^{\gamma}$ and $\beta^{\gamma}$ are surjective.

% \begin{remark}
%   I am still in the process of rewriting this section (and figuring out how to
%   restructure it) so as to include this quotienting operation. The remainder
%   of this section should still be looked at, but I have yet to integrate the
%   quotenting operation. I would also like to talk with you about this step.
% \end{remark}

We now prove a number of important technical lemmas that will ultimately allow
us to to prove that the matrix $M$ (quotiented by some appropriate equivalence
relation) is isomorphism-equivalent to $L^{\gamma}$. The following useful Lemma
allows us to factor a permutation through $\alpha$ and $\beta$.

\begin{lem}
  \label{lem:alpha-and-gamma}
  Let $(i,\vec{x}) \in I$ and $(j, \vec{y}) \in J$. Let $\gamma: U \rightarrow
  [n]$ be a bijection such that $\gamma^{-1} \sim \eta$ and $\pi \in spstab{g}$.
  Then $\pi \alpha^{\gamma}(i, \vec{x}) = \alpha^{\pi \gamma}(i, \vec{x})$ and
  $\pi \beta^{\gamma}(j, \vec{y}) = \beta^{\pi \gamma}(j, \vec{y})$.
\end{lem}
\begin{proof}
  We have that $\pi \alpha^{\gamma}(i, \vec{x}) = \pi \Pi^{\gamma}_{\vec{x}}(i)$
  and $(\pi \Pi^{\gamma}_{\vec{x}}(\vec{\consp}(i)) = \pi \cdot \gamma (\vec{x})
  = \Pi^{\pi \gamma}_{\vec{x}}(\vec{\consp}(i))$. Since $\Pi^{\gamma}_{\vec{x}}$
  and $\Pi^{\pi \gamma}_{\vec{x}}$ are in $\spstab{g}$, it follows from Lemma
  \ref{lem:support-determines-action}, that $\pi \alpha^{\gamma}(i, \vec{x}) =
  \pi \Pi^{\gamma}_{\vec{x}} (i) = \Pi^{\pi \gamma}_{\vec{x}}(i) = \alpha^{\pi
    \gamma}(i, \vec{x})$. Similarly, $\pi \beta^{\gamma}(j, \vec{y}) =
  \beta^{\pi \gamma} (j, \vec{y})$.
\end{proof}

The following result applies Lemma \ref{lem:alpha-and-gamma} to the evaluation
of gates in the circuit.

\begin{lem}
  \label{lem:alpha-ind-gamma}
  Let $(i,\vec{x}) \in I$ and $(j, \vec{y}) \in J$. Let $\gamma_1, \gamma_2: U
  \rightarrow [n]$ be bijections such that $\gamma^{-1}_1 \sim \eta$ and
  $\gamma^{-1}_2 \sim \eta$. Let $\mathcal{A}$ be a structure. Then
  $C_n[\gamma_1 \mathcal{A}] (L(\alpha^{\gamma_1}(i, \vec{x}),
  \beta^{\gamma_1}(j, \vec{y}))) = C_n[\gamma_2 \mathcal{A}]
  (L(\alpha^{\gamma_2}(i, \vec{x}), \beta^{\gamma_2}(j, \vec{y})))$.
\end{lem}
\begin{proof}
  We note that there exists $\pi \in \sym_n$ such that $\gamma_1 = \pi
  \gamma_2$. Moreover, since $\gamma^{-1}_1$ and $\gamma^{-1}_2$ are both
  consistent with $\eta$, it follows that $\pi \in \spstab{g}$. We then have
  that
  \begin{align*}
    C_n[\gamma_1 \mathcal{A}](L(\alpha^{\gamma_1}(i, \vec{x}), \beta^{\gamma_1}(j,
    \vec{y})) &= C_n[\pi \gamma_1 \mathcal{A}](\pi L(\alpha^{\gamma_1}(i, \vec{x}),
                \beta^{\gamma_1}(j, \vec{y})) \\
              &= C_n[\pi \gamma_1 \mathcal{A}](L(\pi
                \alpha^{\gamma_1}(i, \vec{x}), \pi \beta^{\gamma_1}(j, \vec{y}))\\
              &= C_n[\pi
                \gamma_1 \mathcal{A}](L(\alpha^{\pi \gamma_1}(i, \vec{x}), \pi \beta^{\pi
                \gamma_1}(j, \vec{y})\\
              &= C_n[\gamma_2 \mathcal] (L(\alpha^{\gamma_2}(i,
                \vec{x}), \beta^{\gamma_2}(j, \vec{y})))\\
  \end{align*}The third equality follows from Lemma \ref{lem:alpha-and-gamma}.
\end{proof}

The following result shows that, for a given $(i, \vec{x}) \in I$ and $(j,
\vec{y}) \in J$ we may define a gate $h \in H_g$ and a bijection $\gamma' \in
[n]^{\underline{U}}$, such that $(\gamma')^{-1} \sim \eta$, and
$\alpha^{\gamma'}(i, \vec{x})$ and $\beta^{\gamma'}(j, \vec{y})$ define the row
and column of $h$.

\begin{lem}
  \label{lem:defining-h-from-IJ}
  Let $(i, \vec{x}) \in I$ and $(j, \vec{y}) \in J$. From Lemma
  \ref{lem:permutation-row-column} we have $\vec{r}$, $\vec{c}$, $\sigma_r$ and
  $\sigma_c$. Let $h = L(g) (\sigma_r (i), \sigma_c (j))$. Let $\gamma' :=
  (\Pi^{\gamma}_{(\vec{x}_{\vec{r}} \vert \vec{y}_{\vec{c}})})^{-1} \gamma$.
  Then $\alpha^{\gamma'} (i, \vec{x}) = \row (h)$ and $\beta^{\gamma'}
  (i,\vec{y}) = \column(h)$.
\end{lem}
\begin{proof}
  We prove the result for $\alpha$. The $\beta$ case follows similarly. We have
  from Lemma \ref{lem:support-determines-action} that it is sufficient to show
  that for all $a \in \consp(i)$, $\alpha^{\gamma'}(i, \vec{x}) =
  \Pi^{\gamma'}_{\vec{x}} (a) = \sigma_r (a)$. Let $a \in \consp(i)$. We have
  that $\Pi^{\gamma'}_{\vec{x}} (a) = (\Pi^{\gamma}_{(\vec{x}_{\vec{r}} \vert
    \vec{y}_{\vec{c}})})^{-1} \gamma (\vec{x} (a))$ and $\gamma (\vec{x}(a)) =
  \gamma (\vec{x} (\sigma^{-1}_r(\sigma_r(a)))) = \gamma (\vec{x} (\vec{r}^{-1}
  (\sigma_r(a)))) = \Pi^{\gamma}_{(\vec{x}_{\vec{r}} \vert
    \vec{y}_{\vec{c}})}(\sigma_r(a))$. It follows that
  $\Pi^{\gamma'}_{\vec{x}}(a) = \sigma_r(a)$, as required.
\end{proof}

The following result shows that we may check if an assignment to a gate $h$
makes $h$ evaluate to true by analysing certain gates in the orbit of $h$.

\begin{lem}
  Let $\gamma\in [n]^{\underline{U}}$ and $h \in C_n$. Then $\nu \in \EV_h$ if,
  and only if, $C_n[\gamma \mathcal{A}](\Pi^{\gamma}_\nu (h)) = 1$.
  \label{lem:translate-EV-circuits}
\end{lem}
\begin{proof}
  We have that $C_n[\gamma \mathcal{A}](\Pi^{\gamma}_\nu(h))$ if, and only if,
  $C_n[(\Pi^{\gamma}_{\nu})^{-1}\gamma \mathcal{A}] (h)$. Then, by the
  definition of $\EV_h$, $\nu \in \EV_h$ if, and only if, there exists $\gamma'
  \in [n]^{\underline{U}}$ such that $C_n[\gamma' \mathcal{A}](h) = 1$ and $\nu
  = \gamma\restriction{\consp(h)}$.
\end{proof}

We combine the above lemmas in order to show that $\alpha^{\gamma}$ and
$\beta^{\gamma}$ together defines a surjective homomorphism from the matrix $M$
to $L^{\gamma}$.

\begin{thm}
  Let $\gamma\in [n]^{\underline{U}}$ be such that $\eta \sim \gamma^{-1}$ and
  let $(i, \vec{x})\in I$ and $(j, \vec{y})\in J$. It follows that $M((i,
  \vec{x}), (j, \vec{y})) = L^{\gamma}(\alpha^{\gamma}(i, \vec{x}),
  \beta^{\gamma}(j, \vec{y})$.
  \label{lem:ML-equal-elements}
\end{thm}
\begin{proof}
  From Lemma \ref{lem:permutation-row-column} we have $\vec{r}$, $\vec{c}$,
  $\sigma_r$ and $\sigma_c$. Let $\gamma' = (\Pi^{\gamma}_{(\vec{x}_{\vec{r}}
    \vert \vec{y}_{\vec{c}})})^{-1} \gamma$. Let $h = L(g)(\sigma_r(i),
  \sigma_c(j))$. Then
  \begin{align*}
    M((i, \vec{x}), (j, \vec{y}))
    &= (\vec{x}_{\vec{r}} \vert \vec{y}_{\vec{c}}) \in \EV_h \\
    &= C_n[\gamma \mathcal{A}] (\Pi^{\gamma}_{(\vec{x}_{\vec{r}} \vert \vec{y}_{\vec{c}})} (h)) \\
    &= C_n[\gamma' \mathcal{A}] (h) \\
    &= C_n[\gamma' \mathcal{A}](L(\row(h), \column (h)))\\
    &= C_n[\gamma' \mathcal{A}](L(\alpha^{\gamma'}(i, \vec{x}), \beta^{\gamma'}(j, \vec{y})))\\
    &= C_n[\gamma \mathcal{A}](L(\alpha^{\gamma}(i, \vec{x}), \beta^{\gamma}(j, \vec{y}))y)\\
    &= L^{\gamma}(\alpha^{\gamma}(i, \vec{x}), \beta^{\gamma}(j, \vec{y}))
  \end{align*}
  The second equality follows from Lemma \ref{lem:translate-EV-circuits}. The
  fifth equality follows from Lemma \ref{lem:defining-h-from-IJ}. The sixth
  equality follows from Lemma \ref{lem:alpha-ind-gamma}.
\end{proof}

We will now define a new matrix $M_{\equiv}$, formed by quotienting the row and
column sets using the mutual equivalence relation. We will then show that
$\alpha^{\gamma}$ and $\beta^{\gamma}$, lifted to act on equivalence classes,
now define the required isomorphism.

Let $I_{\equiv} = \{(i, [\vec{x})]_{\equiv_i}) : (i, \vec{x}) \in I\}$ and
$J_\equiv = \{(j, [\vec{y}]_{\equiv_j}) : (j, \vec{y})\}$. Let $M_{\equiv} :
I_{\equiv} \times J_{\equiv} \rightarrow \{0,1\}$ be defined by $M_\equiv ((i,
[\vec{x}]_\equiv), (j, [\vec{y}]_\equiv)) := M((i,\vec{x}), (j, \vec{y}))$.

We show in Lemma \ref{lem:matrix-quot-well-defined} that this matrix is
well-defined. We show in Lemma \ref{alpha-beta-mutal equivalence} that
$\alpha^{\gamma}$ and $\beta^{\gamma}$ are constant on mutual equivalence
classes, and as such may be lifted to act on equivalence classes. We combine
these results to prove the existence of the required isomorphism.

\begin{lem}
  Let $X$ be a set on which the left group action of $\sym_n$ is defined, and
  let $\sigma, \sigma' \in \stab(\consp(g))$. We have that $\sigma(s) = \sigma'
  (s)$ if, and only if, $\sigma \equiv_s \sigma'$.
  \label{lem:functions-mutual-equivalence}
\end{lem}
\begin{proof}
  Suppose $\sigma(s) = \sigma'(s)$. Then let $\pi = (\sigma')^{-1} \cdot
  \sigma$. Then clearly $\pi \in \stab(s) \cap \spstab(g)$ and $\sigma = \sigma'
  \pi$.

  Suppose $\sigma \equiv_s \sigma'$. Then let $\pi = (\sigma')^{-1} \cdot
  \sigma$. From mutual stability $\pi \in \stab (s)$ and so $(\sigma')^{-1}\cdot
  \sigma (s) = \pi (s) = s$. The result follows.
\end{proof}

\begin{lem}
  Let $((i, \vec{x}), (j, \vec{y})), ((i, \vec{x}'), (j, \vec{y}')) \in I \times
  J$ and let $\gamma \in [n]^{\underline{U}}$. If $\vec{x} \equiv_i \vec{x}'$
  then $\alpha^{\gamma}(i, \vec{x}) = \alpha^{\gamma}(i, \vec{x}')$ and if
  $\vec{y} \equiv_j \vec{y}'$ then $\beta^{\gamma}(j, \vec{y}) =
  \beta^{\gamma}(j, \vec{y}')$.
  \label{lem:alpha-beta-mutal-equivalence}
\end{lem}
\begin{proof}
  From mutual equivalence there exists $\sigma \in \stab(i)$ such that $\vec{x}'
  = \vec{x} \cdot {\sigma}\restriction_{\consp(i)}$. Notice that
  $\alpha^{\gamma}(i, \vec{x})$ stabilises $\consp(g)$. Then for $a \in
  \consp(i)$, $\Pi^{\gamma}_{\vec{x}} (\sigma (a)) = \gamma (\vec{x}(\sigma
  (a))) = \gamma (\vec{x}'(a)) = \Pi^{\gamma}_{\vec{x}'}(a)$. It follows from
  Lemma \ref{lem:functions-mutual-equivalence} that $\alpha^{\gamma}(i,\vec{x})
  = \Pi^{\gamma}_{\vec{x}} (i) = \Pi^{\gamma}_{\vec{x}'} = \alpha^{\gamma}(i,
  \vec{x}')$. The result follows similarly for $\beta$.
\end{proof}

% \begin{proof}
%   From mutual equivalence there exists $\sigma_1 \in \stab(i) \cap \spstab{g}$
%   and $\sigma_2 \in \stab{j} \cap \spstab{g}$ such that $\vec{x}' = \vec{x}
%   \cdot \sigma_1\restriction{\consp(i)}$ and $\vec{y}' = \vec{y} \cdot
%   \sigma_2\restriction{\consp(j)}$. Notice that $\alpha^{\gamma}(i, \vec{x})$
%   and $\beta^{\gamma}(j, \vec{y})$ both stabilise $\consp(g)$. Then for $a \in
%   \consp(i)$, $\Pi^{\gamma}_{\vec{x}} (\sigma_1 (a)) = \gamma
%   (\vec{x}(\sigma_1 (a))) = \gamma (\vec{x}'(a)) =
%   \Pi^{\gamma}_{\vec{x}'}(a)$. It follows from Lemma
%   \ref{lem:functions-mutual-equivalence} that $\alpha^{\gamma}(i,\vec{x}) =
%   \Pi^{\gamma}_{\vec{x}} (i) = \Pi^{\gamma}_{\vec{x}'}(i)$. The result follows
%   similarly for $\beta$.
% \end{proof}

\begin{lem}
  Let $((i, \vec{x}), (j, \vec{y})), ((i, \vec{x}'), (j, \vec{y}')) \in I \times
  J$ be such that $\vec{x} \equiv_i \vec{x}'$ and $\vec{y} \equiv_j \vec{y}'$,
  then $M(((i, \vec{x}), (j, \vec{y}))) = M((i, \vec{x}'), (j, \vec{y}'))$.
  \label{lem:matrix-quot-well-defined}
\end{lem}
\begin{proof}
  \begin{align*}
    M((i, \vec{x}),(j, \vec{y})) &= L^{\gamma}(\alpha^{\gamma}(i, \vec{x}), \beta^{\gamma}(j, \vec{y}) \\
                                 &= L^{\gamma}(\alpha^{\gamma}(i, \vec{x}'), \beta^{\gamma}(j, \vec{y}'))\\
                                 &= M((i, \vec{x}'), (j, \vec{y}'))
  \end{align*}
  The second equality follows from Lemma \ref{lem:alpha-beta-mutal-equivalence}.
\end{proof}

We now prove the existence of the required isomorphism.

\begin{thm}
  Let $\gamma \in [n]^{\underline{U}}$ such that $\gamma^{-1} \sim \eta$. Then
  $L^{\gamma}$ is isomorphism-equivalent to $M_{\equiv}$.
  \label{thm:LM-equivalence}
\end{thm}
\begin{proof}
  Let $(i, [\vec{x}]) \in I_\equiv$ and $(j, [\vec{y}]) \in J_\equiv$. Then,
  from Lemmas \ref{lem:matrix-quot-well-defined} and
  \ref{lem:ML-equal-elements}, we have that $M_\equiv ((i, [\vec{x}]), (j,
  [\vec{y}])) = M ((i, \vec{x}), (j, \vec{y}))= = L^{\gamma}(\alpha^{\gamma}(i,
  \vec{x}), \beta^{\gamma}(j, \vec{y}))$.

  Moreover, from Lemma \ref{lem:alpha-beta-mutal-equivalence} we can lift
  $\alpha^\gamma$ to $I_\equiv$ and $\beta^{\gamma}$ to $J_\equiv$. It remains
  to show that $\alpha^\gamma$ and $\beta^{\gamma}$, thought of as functions to
  $I_\equiv$ and $J_\equiv$, are bijections. We prove the result for
  $\alpha^{\gamma}$, with the proof for $\beta^\gamma$ following similarly.

  We first note that the lifting of $\alpha^{\gamma}$ to $I_\equiv$ is
  surjective as, using Lemma \ref{lem:alpha-beta-surjective}, both the unlifted
  function $\alpha^{\gamma}$ and the lifting function (i.e. the quotient map
  from $I$ to $I_\equiv$) are surjective.

  Suppose $\alpha^{\gamma}((i, [\vec{x}])) = \alpha^{\gamma}((i', [\vec{x}']))$,
  and so $\Pi^{\gamma}_{\vec{x}}(i) = \Pi^{\gamma}_{\vec{x}'}(i')$. But then $i$
  and $i'$ are in the same orbit and thus, from the definition of $I$, $i = i'$.
  Thus $\Pi^{\gamma}_{\vec{x}}(i) = \Pi^{\gamma}_{\vec{x}'}(i)$, and so from
  Lemma \ref{lem:functions-mutual-equivalence} there exists $\sigma \in \stab(i)
  \cap \spstab{g}$ such that for all $a \in \consp(i)$ we have that
  $\Pi^{\gamma}_{\vec{x}}(a) = \Pi^{\gamma}_{\vec{x}'} (\sigma (a))$. But then
  $\Pi^{\gamma}_{\vec{x}}(a) = \gamma (\vec{x}(a)) =
  \Pi^{\gamma}_{\vec{x}'}(\sigma (a)) = \gamma (\vec{x}' (\sigma (a))$ and,
  since $\gamma$ is a bijection, it follows that $\vec{x}(a) = \vec{x}' \sigma
  (a)$. Thus $\vec{x} \equiv_i \vec{x}'$, and the lifting of $\alpha^{\gamma}$
  to $I_{\equiv}$ is an injection. The result follows.
\end{proof}

Let $(i,\vec{x}), (i, \vec{x}') \in I$ be such that $\vec{x} \equiv \vec{x}'$.
From Lemma \ref{lem:matrix-quot-well-defined} it follows that for all $(j,
\vec{y}) \in J$, $M((i, \vec{x}), (j, \vec{y})) = M((i, \vec{x}'), (j,
\vec{y}))$, and any two rows indexed by elements of the same equivalence class
are equal. It follows that $\rank (M) = \rank (M_{\equiv}) = \rank
(L^{\gamma})$.

% \begin{lem}
%   Let $\gamma \in [n]^{\underline{U}}$ such that $\gamma^{-1} \sim \eta$. Then
%   $\rk_p (M) = \rk_p (L^{\gamma})$.
% \end{lem}
% \begin{proof}
%   We show that $\rk(M) = \rk (M_\equiv)$, and the result will follow from
%   Theorem \ref{thm:LM-equivalence}.
% \end{proof}

% Let $((i, \vec{x}), (j, \vec{y})), ((i, \vec{x}'), (j, \vec{y}')) \in I \times
% J$ be such that $\vec{x} \equiv_i \vec{x}'$.
% \begin{lem}

% \end{lem}


% \begin{thm}
%   Let $\gamma\in [n]^{\underline{U}}$, $M$ is row-column equivalent to
%   $L^{\gamma}$. This equivalence is witnessed by $\alpha^{\gamma}$ and
%   $\beta^{\gamma}$.
% \end{thm}
% \begin{proof}
%   We have that $\alpha^{\gamma}$ and $\beta^{\gamma}$ are surjective. Let
%   $\gamma' = (\Pi^{\gamma}_{(\vec{x}_{\vec{r}} \vert \vec{y}_{\vec{c}})})^{-1}
%   \gamma$.

%   \begin{align*}
%     M((i, \vec{x}), (j, \vec{y}))
%     &= (\vec{x}_{\vec{r}} \vert \vec{y}_{\vec{c}}) \in \EV_h \\
%     &= C_n[\gamma \mathcal{A}] (\Pi^{\gamma}_{(\vec{x}_{\vec{r}} \vert \vec{y}_{\vec{c}})} (h)) \\
%     &= C_n[\gamma' \mathcal{A}] (h) \\
%     &= C_n[\gamma' \mathcal{A}](L(\row(h), \column (h)))\\
%     &= C_n[\gamma' \mathcal{A}](L(\alpha^{\gamma'}(i, \vec{x}), \beta^{\gamma'}(j, \vec{y})))\\
%     &= C_n[\gamma \mathcal{A}](L(\alpha^{\gamma}(i, \vec{x}), \beta^{\gamma}(j, \vec{y}))y)\\
%     &= L^{\gamma}(\alpha^{\gamma}(i, \vec{x}), \beta^{\gamma}(j, \vec{y}))
%   \end{align*}
%   The second equality follows from Lemma \ref{lem:translate_EV_circuits}. The
%   fifth equality follows from Lemma \ref{lem:defining_h_from_IJ}. The sixth
%   equality follows from Lemma \ref{lem:alpha_ind_gamma}.
% \end{proof}

% \begin{remark}
%   In fact, the above still requires injectivity. This still needs to be
%   integrated.
% \end{remark}


% \subsection{FPR Formulas}

% \begin{lem}
%   Let $(i, \vec{x}) \in I$ and $(j, \vec{y}) \in J$. Let $h \in H$ such that
%   $\row (h) \in \orb_r (i)$, $\column (h) \in \orb_c(j)$, and $\type(h) =
%   \type(\vec{x}, \vec{y})$. Let $\gamma: U \rightarrow [n]$ be a bijection and
%   $\mathcal{A}$ a structure. Then $C_n[\gamma
%   \mathcal{A}](\Pi^{\gamma}_{\vec{x} \vert \vec{y}} (h)) = C_n[\gamma
%   \mathcal{A}](L(\alpha^{\gamma}(i, \vec{x}), \beta^{\gamma}(j, \vec{y})))$.
% \end{lem}
% \begin{proof}
%   Let $\gamma' = (\Pi^{\gamma}_{\vec{x} \vert \vec{y}})^{-1} \gamma$. First we
%   show that $h = L(\alpha^{\gamma'}(i, \vec{x}), \beta^{\gamma'}(j,
%   \vec{y}))$. Notice that $\Pi^{\gamma'}_{\vec{x}}(\vec{r}_i) =
%   \gamma'(\vec{x}) = (\Pi^{\gamma}_{\vec{x} \vert \vec{y}})^{-1} \gamma
%   (\vec{x}) = \vec{r}_h$. But $\row(h) \in \orb_r(i)$ and so there exists
%   $\vec{x}' \in A^r_i$ such that $\Pi^{\gamma'}_{vec{x}'}(i) = \row{h}$ From
%   Lemma \ref{lem:support_determine_action} it follows that $\row (h) =
%   \Pi^{\gamma'}_{\vec{x}}(i) = \alpha^{\gamma'}(i, \vec{x})$. Similarly, we
%   can show that $\column(h) = \beta^{\gamma'}(j, \vec{y})$. It follows that $h
%   = L(\alpha^{\gamma'}(i, \vec{x}), \beta^{\gamma'}(j, \vec{y}))$, and so
%   \begin{align*}
%     C_n[\gamma \mathcal{A}](\Pi^{\gamma}_{\vec{x}
%     \vert \vec{y}} (h))
%     &= C_n[\gamma' \mathcal{A}](h)\\
%     &= C_n[\gamma' \mathcal{A}](L(\alpha^{\gamma'}(i, \vec{x}), \beta^{\gamma'}(j, \vec{y})))\\
%     &= C_n[\gamma \mathcal{A}](L(\alpha^{\gamma}(i, \vec{x}), \beta^{\gamma}(j, \vec{y}))).
%   \end{align*}
%   The final equality follows from Lemma \ref{lem:alpha_ind_gamma}.
% \end{proof}


% \chapter{New Stuff}
% Let $x,y \subset U$ such that $\vert x \vert = \vert y \vert = k \in
% \mathbb{N}$. Let $\vec{x}: [k] \rightarrow x$ and $\vec{y}: [k] \rightarrow y$
% be bijections.

% We need to define $r, c \subset [n]$ such that $\vert r \vert = \vert c \vert
% = k$ and there exists bijections $\vec {r}: [k] \rightarrow r$ and $\vec{c}:
% [k] \rightarrow c$.

% Let $u_1 , \ldots , u_{2k}$ be the first $2k$ elements of $[n] \setminus
% \SP(g)$ in order. Then let
% \[r = \eta^{-1} (x \cap \eta (\SP(g))) \cup \{u_{\vec{x}^{-1}(a)}: a \in x
%   \setminus \alpha (\SP (g))\} \] and
% \[s = \eta^{-1} (y \cap \eta (\SP(g))) \cup (x \cap y) \cup \{ u_{k +
%   \vec{x}^{-1}(a)} : a \in y \setminus (x \cup \alpha (\SP (g))) \}). \]
% Define
% \[
%   \vec{r} (a) =
%   \begin{cases}
%     \eta^{-1} (\vec{x} (a)) & a \in \vec{x}^{-1} (x \cap \eta (\SP(g))) \\
%     u_{a} & a \in \vec{x}^{-1} (x \setminus \eta(\SP(g)),
%   \end{cases}
% \]
% and

% \[
%   \vec{c} (a) =
%   \begin{cases}
%     \eta^{-1} (\vec{y} (a)) & a \in \vec{y}^{-1}(y \cap \eta (\SP (g))) \\
%     \vec{r} (a) & a \in \vec{y}^{-1} (x \cap y \setminus \eta (\SP (g))) \\
%     u_{k+a} & \text{otherwise}.
%   \end{cases}
% \]

% \begin{lem}
%   $x_r \sim \eta$ and $x_c \sim \eta$
% \end{lem}

% \begin{lem}
%   $\SP(g) \cap \SP(i) = \SP(g) \cap r$ and $\SP (g) \cap SP (j) = \SP (g) \cap
%   c$.
% \end{lem}

% Let $(\vec{x}, \vec{y})_{\vec{r}, \vec{c}}: r \cup c \rightarrow U$ be defined
% by
% \[
%   (\vec{x}, \vec{y})_{\vec{r}, \vec{c}}(a) =
%   \begin{cases}
%     \vec{x}(\vec{r}^{-1}(a)) & a \in r \\
%     \vec{y}(\vec{c}^{-1}(a)) & a \in c
%   \end{cases}
% \]

% This function is well defined.

% % \begin{lem}
% %   Let $r, c \subset U$ and let $r_1, r_2 : [k_1] \rightarrow r$ and $c_1, c_2 :
% %   [k_2] \rightarrow c$ then $\type(\vec{r}_1, \vec{c}_1) = \type (\vec{r}_2 ,
% %   \vec{c}_2)$.
% % \end{lem}

% \begin{lem}
%   $(\vec{x}_{\vec{r}} \vert \vec{y}_{\vec{y}}) \sim \eta$
% \end{lem}

% \begin{lem}
%   There exists $\sigma_1, \sigma_2 \in \spstab{g}$ such that $\sigma_1 \cdot
%   \vec{\consp(i)} = \vec{r}$ and $\sigma_2 \cdot \vec{\consp(j)} = \vec{c}$.
% \end{lem}

% \begin{lem}
%   Let $(i, \vec{x}) \in I$ and $j, \vec{y} \in J$. Let $\vec{r}$ and $\vec{c}$
%   be described as above. Let $\sigma_1$ and $\sigma_2$ be as from Lemma
%   \ref{}. Let $h = L(g) (\sigma_1 (i), \sigma_2 (j))$. Then $\alpha^{\gamma'}
%   (i, \vec{x}) = \row (h)$ and $\beta^{\gamma'} (i,\vec{y}) = \column(h)$.
% \end{lem}
% \begin{proof}
%   $\alpha^{\gamma'}(i, \vec{x}) = \Pi^{\gamma'}_{\vec{x}} (i)$. It is
%   sufficient to show that for all $a \in sp(g)$, $\Pi^{\gamma}_{\vec{x}} (a) =
%   \sigma_1 (a)$. Note that $\Pi^{\gamma'}_{\vec{x}_i} (a) =
%   (\Pi^{\gamma}_{(\vec{x}, \vec{y})_{\vec{r}, \vec{c}}})^{-1} \gamma
%   (\vec{x}_i (a))$, and if $b = \sigma_1 (a)$ we have that $\gamma (\vec{x}_i
%   (a)) = \gamma (\vec{x} (\vec{\consp}(i)^{-1} (a))) = \gamma (\vec{x}
%   (\vec{\consp}(i)^{-1} (\sigma^{-1}_1 b))) = \gamma (\vec{x} ((\sigma_1 \cdot
%   \vec{\consp}(i))^{-1} (b))) = \gamma (\vec{x} (\vec{r}^{-1}(b))) =
%   \Pi^{\gamma}_{(\vec{x}, \vec{y})_{\vec{r}, \vec{c}}}(b)$. So
%   $\Pi^{\gamma'}_{\vec{x}} (a) = b = \sigma_1 (a)$. Similarly for
%   $\beta^{\gamma'}$.
% \end{proof}

% \begin{lem}
%   Let $(i, \vec{x}) \in I$ and $(j, \vec{y}) \in J$. There exists $h \in H$
%   such that $h$ has type $(\vec{x}, \vec{y})$ and for any bijection $\gamma: U
%   \rightarrow [n]$ and structure $\mathcal{A}$ then $C_n[\gamma \mathcal{A}]
%   (\Pi^{\gamma}_{(\vec{x} \vert \vec{y})_{h}}) = C_n [\gamma
%   \mathcal{A}](L(\alpha^{\gamma}(i, \vec{x}), \beta^{\gamma}(j, \vec{y})))$.
% \end{lem}

% \begin{lem}
%   Let $h \in H$ and $\vec{z} \in A_h$ and $\Pi^{\delta}_h$ be a permutation
%   such that $\Pi^{\delta}_{\vec{z}}(a) = \delta(\vec{z}(a))$ for all $a \in
%   \sp(h)$. Then $C_n[\gamma \mathcal{A}](\Pi^{delta}_{\vec{z}} (h))$ iff
%   $\vec{z} \in \EV_h$.
% \end{lem}

% \begin{thm}
%   The matrix $M$ is equivalent to $L$.
% \end{thm}

\subsection{Translating to Formulas of FPR}
\label{sec:translating-formulas-to-FPR}
Let $\mathcal{C}:= (C_n)_{n \in \mathbb{N}}$ be a $P$-uniform family of
symmetric rank circuits. In this section we define a formula $Q$ in $\FPR$ such
that for any $\tau$-structure $\mathcal{A}$ over the universe $U$ with $\vert U
\vert = n$, the $q$-ary query defined by $C_n$ on input $\mathcal{A}$ is defined
by $Q$ when interpreted in $\mathcal{A}$.

Since $\mathcal{C}$ is P-uniform, it follows from the Immerman-Vardi theorem and
Lemma \ref{} that there is an $\FP(\leq)$ interpretation defining a rigid
symmetric circuit with bijective labeling equivalent to $C_n$ when interpreted
in the structure $\langle n, \leq \rangle$. We abuse notation and also call this
circuit $C_n$. Let this interpretation be denoted by $\Phi := (\phi_G,
\phi_\omega, (\phi_s)_{ s \in \mathbb{B} \cup \tau \cup \{0,1\}},
(\phi_{\Lambda_R})_{R \in \tau}, \phi_L)$, where $\mathbb{B}$ consists of the
symbols $\land$, $\lor$, $\maj$, $\rank$ and $\nand$. Let $t$ be the artity of
this interpretation. It follows that the domain of this interpretation is a
subset of $[n]^t$. We identify the tuples in $[n]^t$ with elements of the
initial segment of the natural numbers $[n^t]$. In this way $\phi_g$ has one
free number variable and defines the set of gates $G \subseteq [n^t]$ (rather
than $G$ as a subset of $[n]^t$). Similarly we have that $\phi_s (\mu)$ holds
if, and only if, $\mu$ is assigned to a gate of type $s$, and $\phi_L (\mu,
\vec{\kappa}, \nu)$ holds if, and only if, $L$ at the gate $\mu$ maps the tuple
$\vec{\kappa}$ to the gate $\nu$. Moreover, it follows from the Immerman-Vardi
theorem that there exists a formula $\FA{rank-type}(\mu, \kappa , \pi)$ such
that, for a structure $\mathcal{A}$, $\mathcal{A} \models \FA{rank-type}[g, r,
p]$ if, and only if, $g$ is a rank gate with prime $p$ and threshold $r$. We
note that the bound on the domain is definable as a closed number term $\FA{m}
:= (x\# (x = x))*t$. We have from the support theorem that there are constants
$n_0$ and $k$ such that for all $n \geq n_0$ the support of each gate has size
at most $k$. Note that for each $n \leq n_0$, $C_n$ can be evaluated by an
$\FPC$ formula with simply quantifies over all of the possible bijections from
the universe of $\mathcal{A}$ to $[n]$ (since there are at most constantly many
such bijections). As such we suppose $n \geq n_0$ in the rest of this
subsection.

We will recursively construct $\EV_g$ for each gate $g$ in the circuit. While we
have that the canonical support of $g$ has size at most $k$, it may not be equal
to $k$. As such, if $\vert \consp(g) \vert = \ell$, we define

\begin{align*}
  \overline{\EV}_g = \{ (a_1, \ldots , a_k) \in [n]^k : (a_1 , \ldots , a_\ell ) \in \EV_g \text{ and } i \neq j \implies a_i \neq a_j \}.
\end{align*}

In this subsection we use $\mu$ and $\nu$ to denote number variables that index
gates. We use $\epsilon$ and $\delta$ to denote variables that index elements of
the universe of a gate. We use $\kappa$ and $\pi$ to denote number variables. We
use $x, y, z, \ldots$ to denote vertex variables and $U, V, \ldots$ to denote
relation variables. We use $a, b, c , \ldots$ to denote elements of the vertex
sort. When a vector of values or variables is used without reference to size, it
is usually taken to be a $k$-tuple.

We seek to define a relation $V \subseteq [n^t] \times U^k$ by $V(g, \vec{a})$
if, and only if, $\vec{a} \in \overline {\EV}_g$. Our aim is to define a set of
formulas $\theta_s (\mu, \vec{x})$, where $s \in \mathbb{B} \cup \tau \cup
\{0,1\}$, which evaluate the gate indexed by $\mu$ for the assignment to its
support given by $\vec{x}$ if it is a gate labelled by the symbol $s$. Each of
these formulas are written in terms of $V$, the relation variable we are
inductively defining.

We will define the $\FPR$ formula $\theta_\rank (\mu, \vec{x})$. The other
formulas have already been defined by Anderson and Dawar \cite{AndersonD17} and
so this will suffice. In order to do this we first define a formula $\psi_M$
that defines the matrix $M$ from the previous subsection. We then use the rank
operator to compute the rank of the given matrix. In order to define $\psi_M$
and $\theta_\rank$ succinctly we first define a number of useful $\FPC$
formulas.

We define the closed number term $\FA{s} := x\# (x = x)$, which defines the size
of the structure. The following two formulas take in a gate $g$ and an element
of the universe of $g$ and check if that element is in the first or second sort
(i.e. of it is a row or a column).

\begin{align*}
  \FA{row} (\mu, \delta) := & \exists \nu, \epsilon \leq \FA{m} \, (\Phi_L (\mu, \delta , \epsilon, \nu))\\
  \FA{col} (\mu, \epsilon) := & \exists \nu, \delta \leq \FA{m} \, (\Phi_L (\mu, \delta , \epsilon, \nu))
\end{align*}

From Lemma \ref{}, and invoking Immerman-Vardi theorem, we have an $\FPC$
formula $\FA{orb}(\mu, \delta, \epsilon)$ such that $\mathcal{A} \models
\FA{orb}[g,i, i']$ if, and only if, $i$ and $i'$ are in the universe of $g$ and
are in the same orbit. The following formula allows us to define the minimal
element of an orbit

\begin{align*}
  \FA{min-orb} (\mu, \delta) := \forall \epsilon \leq \FA{m} \, (\FA{orb} (\mu, \delta, \epsilon) \implies \delta \leq \epsilon).
\end{align*}

% We define an $\FPC$ formula $\FA{agree}_s (\vec{s}_1, \vec{s}_1, \vec{x},
% \vec{y})$ such that for $\mathcal{A}$, $\mathcal{A}^{\leq} \models
% \FA{agree}_s[\vec{r}, \vec{c}, \vec{a}, \vec{b}]$ if, and only if,
% $\vec{a}_{\vec{r}} \sim \vec{b}_{\vec{c}}$.

From Anderson and Dawar \cite{AndersonD17} there is an $\FPC$ formula
$\FA{supp}$ such that $\mathcal{A} \models \FA{supp} [g, u]$ if, and only if,
$\mathcal{A} \models \phi_G [g]$ and $u$ is in $\consp(g)$. They use this
formula to inductively define a set of formula $\FA{supp}_i$ for each $i \in
\nats$ such that $\mathcal{A} \models \FA{supp}_i[g, u]$ if, and only if, $u$ is
the $i$th element of $\consp(g)$.

Similarly, we can define $\FA{supp}^r$ such that $\mathcal{A} \models
\FA{supp}^r[g, a, u]$ if, and only if, $\mathcal{A} \models \phi_G [g] \land
\FA{row}[g, a]$ and $u$ is in $\consp_g(u)$, and $\FA{supp}^c$ such that
$\mathcal{A} \models \FA{supp}^c[g, a, u]$ if, and only if, $\mathcal{A} \models
\phi_G [g] \land \FA{col}[g, a]$ and $u$ is in $\consp_g(u)$. Again we can
define the formulas $\FA{supp}^r_i$ and $\FA{supp}^c_i$ for each $i \in \nats$
which hold if, and only if, the element given is in fact the $i$th element of
the row and column support respectively.

From Anderson and Dawar \cite{AndersonD17} we have an $\FPC$ formula
$\FA{agree}(\mu, \nu, \vec{x}, \vec{y})$ such that $\mathcal{A} \models
\FA{agree}[g, h, \vec{a}, \vec{b}]$ if, and only if, $\vec{a}_g' \sim
\vec{b}_h'$, where $\vec{a}_g'$ and $\vec{b}_h'$ are the the restrictions of the
$k$-tuples $\vec{a}_g$ and $\vec{b}_h$ to the sizes of $\consp(g)$ and
$\consp(h)$ respectively. We can similarly define define $\FA{agree}_1 (\mu,,
\nu, \delta , \vec{x}, \vec{y}, \vec{z})$ (where $\vec{z}$ is a tuple of size
$2k$) such that $\mathcal{A} \models \FA{agree}_1 [g, h, i, \vec{a}, \vec{b},
\vec{c}]$ if, and only if, $\vec{b}_h' \sim \vec{c}_i'$, $\vec{a}_g' \sim
\vec{b}_h'$ and $\vec{c}_i' \sim \vec{a}_g'$, and where $\vec{a}_g'$,
$\vec{b}_h'$ and $\vec{b}_i'$ are the the restrictions of the tuples
$\vec{a}_g$, $\vec{b}_h'$ and $\vec{c}_i'$ to the sizes of $\consp(g)$,
$\consp(h)$ and $\consp_g(i)$ respectively

It is easy to see that the construction of the vector $\vec{c}$ from Equation
\ref{} is expressible in $\FPC$. Thus we assert that there exists an $\FPC$
formula $\FA{move} (\mu, \delta, \epsilon, \vec{y}, \vec{x}, \vec{y}, \vec{z},
\vec{w})$ such that $\mathcal{A} \models \FA{move} [g, i, j, \vec{a}, \vec{b},
\vec{d}, \vec{c}']$ if, and only if, $\mathcal{A} \models \phi_G [g] \land
\FA{row}_g[g,i] \land \FA{col}[g, j]$ and the vector $\vec{c}$ defined in the
previous section is equal to the restriction of $\vec{c}'$ to the length of
$\vec{c}$.

From Lemma \ref{} and invoking the Immerman-Vardi theorem, there is an $\FPC$
formula $\FA{map}^c$ such that $\mathcal{A} \models \FA{map}^c[g, j, j',
\vec{c}]$ if, and only if, $\mathcal{A} \models \phi_G [g] \land \FA{col}[g, j]
\land \FA{col}[g, j']$ and such that for all $\sigma \in \sym_n$ if $\sigma
(\vec{\consp}_g(j)) = \vec{c}$ then $\sigma (j) = j'$.

% Similarly we can define $\FA{agree}_1 (\mu, \delta , \vec{x}, \vec{y})$ such
% that $\mathcal{A}^leq \models \FA{agree}_1 [g, i, \vec{a}, \vec{b}]$ if, and
% only if, $\alpha \sim \beta$, where $\alpha \in U^{\underline{\consp(g)}}$ and
% $\beta \in U^{\underline {\consp_g(i)}}$ are the restrictions of $\vec{a}$ and
% $\vec{b}$ to the length of $\consp(g)$ and $\consp_g(i)$ respectively. Lastly
% we can define $\FA{agree}_2 (\mu, \delta, \epsilon , \vec{x}, \vec{y})$ such
% that $\mathcal{A}^\leq \models \FA{agree}_2 [g, i,j ,\vec{a}, \vec{b},
% \vec{c}]$ if, and only if, $\mathcal{A}^{\leq} \models \FA{agree}_1[g, i,
% \vec{a}, \vec{b}] \land \FA{agree}_1[g, j, \vec{a}, \vec{c}]$ and $\alpha \sim
% \beta$, where $\alpha \in U^{\underline{\consp_g(i)}}$ and $\beta \in
% U^{\underline {\consp_g(j)}}$ are the restrictions of $\vec{b}$ and $\vec{c}$
% to the length of $\consp_g(i)$ and $\consp_g(j)$ respectively.

We define the $\FPC$ formula $\FA{merge}$ that takes in two gates $g$ and $h$
(with $h \in H_g$) as well as assignments to the supports of $g$ and $h$ and the
row and column supports of $h$. It then checks if the assignment to the support
of $h$ is compatible with the given row and column supports of $h$.

% \begin{align*}
%     \FA{merge} (\mu, \nu, \vec{x}, \vec{y}, \vec{z}) := \exists u_1, u_2 \leq \FA{MAX} ( \phi_L (\mu, u_1, u_2, \nu) \land ( \bigwedge{1 \leq i < j \leq 2k}  \exists v \leq \FA{SIZE} ((\FA{supp}^r_j (\mu, u_1, v) \land \FA{supp}_i(\nu, v) \implies z_i = x_j) \land (\FA{supp}^c_j (\mu, u_2, v) \land \FA{supp}_i(\nu, v) \implies z_i = y_j))))
% \end{align*}

\begin{align*}
  \FA{merge} (\mu, \nu, \vec{x}, \vec{y}, \vec{w}_1, \vec{w}_2) := &\exists \delta, \epsilon \leq \FA{m} \, ( \phi_L (\mu, \delta, \epsilon, \nu) \\ & \land \FA{agree}_1 (\mu, \nu , \delta, \vec{x}, \vec{y}, \vec{w}_1) \land \\ & \FA{agree}_1 (\mu, \nu , \epsilon, \vec{x}, \vec{y}, \vec{w}_2))
\end{align*}

We are almost ready to define the matrix $M$ from the previous subsection. We
break this up into two formulas. The first checks that the input is within the
domain of the matrix and the second defines $M$ for the given row and column
indexes.

\begin{align*}
  \FA{check-dom}(\mu, \vec{x}, \delta, \vec{y}, \epsilon, \vec{z})  := & \FA{dom}_{\Phi_L} (\mu, \delta, \epsilon) 
                                                                         \land \FA{min-orb}(\delta, \vec{y}) \land \FA{min-orb} (\epsilon, \vec{z}) \\
                                                                       &\land \FA{agree}_1 (g, \delta , \vec{x}, \vec{y}) \land \FA{agree}_1 (g, \epsilon , \vec{x}, \vec{z})
\end{align*}

\begin{align*}
  \FA{find-eval} (\mu, \vec{x}, \delta, \vec{y}, \epsilon, \vec{z}) := & \exists \vec{s} \leq \FA{s} \, (\FA{move}(\mu, \delta, \epsilon, \vec{x}, \vec{y}, \vec{z}, \vec{s}) \\ & \land (\exists \epsilon' \leq \FA{m} \, (\FA{map}^c (\mu, \epsilon, \epsilon', \vec{s}) \land (\exists \nu \leq \FA{m} \, (\phi_L (\mu, \delta, \epsilon', \nu) \\ & \land (\exists \vec{m} \, (\FA{merge} (\mu, \nu, \vec{x}, \vec{m}, \vec{y}, \vec{z}) \land V(\nu, \vec{m}))))))))
\end{align*}

% There is an $\FP$ formula $\FA{merge}(\nu , \vec{s}, \vec{s}_2, \vec{x},
% \vec{y}, \vec{w})$ such that $\mathcal{A} \models \FA{merge} [\vec{r},
% \vec{c}, \vec{a}, \vec{b}, \vec{d}]$ if, and only if, $\mathcal{A}^{\leq}
% \models \FA{agree}_s[\vec{r}, \vec{c}, \vec{a}, \vec{b}]$ and $\vec{d}_{\vec{r
% \cup c}} = \vec{a}_{\vec{r}} | \vec{b}_{\vec{c}}$.

% We define the $\FPC$ formula $\FA{FIND}$ that takes in gates $g$ and $h \in
% H_g$ and
% \begin{align*}
% \FA{FIND}(\mu, \nu, \vec{s}, \vec{t}) := \exists a, b \leq \FA{MAX} (\phi_L(\mu, a, b, \nu) \land \bigwedge_{1 \leq i \leq 2k} \left( (\exists u \leq \FA{SIZE} (\FA{supp}_i (\mu, a, u) \implies s_i = u)) \and (\exists u \leq \FA{SIZE} (\FA{supp}_i (\mu, b, u) \implies t_i = u)) \right)
% \end{align*}
% From Lemma \ref{} and the Immerman-Vardi theorem there is a formula
% $\FA{FIND}$ such that $\mathcal{A} \models \FA{FIND} [g, h, \vec{r}, \vec{c}]$
% if, and only if, $h \in H_g$ and $\mathcal{A} \models \bigwedge_\FA{supp}^_r_i
% [h, \vec{r}, g] \land \FA{supp}^c [h, \vec{c}, g]$. We can then define
% $\FA{MIN-FIND} (\vec{s}_1, \vec{s}_2, \mu, \vec{x}, \nu) := \FA{FIND}
% (\vec{s}_1, \vec{s}_2, \mu, \vec{x}, \nu) \land (\forall \nu' (\FA{FIND}
% (\vec{s}_1, \vec{s}_2, \mu, \vec{x}, \nu') \implies \nu \leq \nu'))$.

% We now define a formula for checking if the input is in the domain of the
% matrix, i.e. are elements of the sets $I$ and $J$ defined in the previous
% section.
% \begin{align*}
%     \FA{check-dom}(\mu, \vec{x}, \delta, \vec{y}, \epsilon, \vec{z})  := & \FA{dom}_{\Phi_L} (\mu, \delta, \epsilon) 
%     \land \FA{min-orb}(\delta, \vec{y}) \land \FA{min-orb} (\epsilon, \vec{z}) \\
%     &\land \FA{agree}_1 (g, \delta , \vec{x}, \vec{y}) \land \FA{agree}_1 (g, \epsilon , \vec{x}, \vec{z}).
% %     \FA{merge} (\mu, \vec{x}, \nu, \vec{w}, \delta, \vec{y}, \epsilon,
% %     \vec{z}, \vec{w}) := & \FA{agree} (\mu, \nu, \vec{x}, \vec{w}) \land
% %     \FA{agree}_2 (\mu , \delta, \epsilon, \vec{x}, \vec{y}, \vec{z}) \\ &
% %     \land \FA{agree}_2 (\nu , \delta, \epsilon, \vec{w}, \vec{y}, \vec{z}),
% %     and \\ \\
% %     \FA{MIN-MERGE} (\mu, \vec{x}, \nu, \vec{w}, \delta, \vec{y}, \epsilon,
% %     \vec{z}, \vec{w}) := & \FA{merge} (\mu, \vec{x}, \nu, \vec{w}, \delta,
% %     \vec{y}, \epsilon, \vec{z}, \vec{w}) \\ & \land (\forall \nu'
% %     (\FA{merge} (\mu, \vec{x}, \nu', \vec{w}, \delta, \vec{y}, \epsilon,
% %     \vec{z}, \vec{w}) \implies \nu \leq nu'))
% \end{align*}.

% We now define a formula that takes in a gate $g$ and an assignment to its
% support as well as an encoding of $(i, \vec{b}) \in I$ and $(j, \vec{d})\in
% J$, and constructs the vector $\vec{c}$, as defined in the previous section,
% such that $\vec{b}_{\consp_g(i)} \sim \vec{d}_{\vec{c}}$. It then defines a
% gate $h \in H_g$ that has row support $\consp_g(i)$ and column support
% $\vec{c}$, before evaluating for $h$ for the assignment to the support
% $(\vec{b}_{\consp_g(i)} | \vec{d}_{\vec{c}})$.
% \begin{align*}
%     \FA{find-eval} (\mu, \vec{x}, \delta, \vec{y}, \epsilon, \vec{z}) := & \exists \vec{v} (\FA{move}(\delta, \vec{y}, \epsilon, \vec{z}, \mu, \vec{x}, \vec{v}) \\ & \land (\exists \vec{u} (\FA{supp}_r(\delta, \vec{u}, \mu) \land (\exists \nu (\FA{MIN-FIND}(\vec{u}, \vec{v}, \nu, \mu) \\ & \land (\exists \vec{w} (\FA{merge}(\nu, \vec{y}, \vec{z}, \vec{w}) \FA{agree}(\mu, \nu, \vec{x}, \vec{w}) \land V(\nu, \vec{w}))))))))
% \end{align*}

We are now ready to define the formula that defines the matrix $M$.

\begin{align*}
  \psi_M (\mu, \vec{x}, \delta, \vec{x}, \epsilon, \vec{y}) :=  \FA{check-dom}(\mu, \vec{x}, \delta, \vec{y}, \epsilon, \vec{z}) \land \FA{find-eval} (\mu, \vec{x}, \delta, \vec{y}, \epsilon, \vec{z})
\end{align*}

We now define the formula that evaluates a rank gate $g$.

\begin{align*}
  \theta_\rank (\mu, \vec{x}) := &\bigwedge_{1 \leq i < j \leq k} x_i \neq x_j \land (\exists p, k \leq \FA{m} \, (\FA{rank-type}(\mu. p, k) \\ &\land [\rank (\vec{y}\delta\leq \FA{m}, \vec{z}\epsilon\leq \FA{m}, p \leq \FA{M}). \psi_M] \leq k )))
\end{align*}

As mentioned above we have the formulas $\theta_0$, $\theta_1$, $\theta_\land$,
$\theta_\lor$, $\theta_\nand$, $\theta_\maj$ and $(\theta_R)_{R \in \tau}$ from
Anderson and Dawar \cite{AndersonD17}. The relation $V$ is then given as a fixed
point by the following formula.
\begin{align*}
  \theta (\mu, \vec{x}) := [\ifp_{V,\nu \vec{y}} \bigvee_{s \in \mathbb{B}' \uplus \tau \uplus \{0,1\}} (\phi_s(\mu) \land \theta_s (\nu, \vec{y} ] (\mu, \vec{x})
\end{align*}

The following $\FPR$ formula defines the $q$-ary query computed by the circuit
family $\mathcal{C}$ \cite{AndersonD17}.

\begin{align*}
  Q (z_1, \ldots z_q) := & \exists \vec{x} \exists \mu, \nu_1 , \ldots  \nu_q \eta_1 , \ldots , \nu_k \leq \FA{m} [\phi_\omega (\nu_1, \ldots \nu_q, \mu) \land \\
                         & \bigwedge_{1 \leq i \leq k} \FA{supp}_i (\mu, \eta_i) \wedge \forall \eta (\neg \FA{supp}_i (\mu, \eta))) \land \\
                         & \bigwedge_{1 \leq i \leq k} \bigwedge_{1 \leq j \leq q}((\FA{supp}_i (\mu, \eta_i) \land (x_i = z_j) \implies \nu_j = \eta_i) \land \\ &
                                                                                                                                                                    \bigwedge_{1 \leq j \leq q} \bigvee_{1 \leq i \leq k} (x_i = z_j \land \FA{supp}_i (\mu, \eta_i)]
\end{align*}

This completes the proof of our main theorem.





% We define the following formulas:
% \begin{align*}
%     \FA{check-dom}(\mu, \vec{x}, \delta, \vec{y}, \epsilon, \vec{z})  := & \FA{dom}_{\Phi_L} (\mu, \delta, \epsilon) 
%     \land \FA{min-orb}(\delta, \vec{y}) \land \FA{min-orb} (\epsilon, \vec{z}) \\
%     &\land \FA{agree}_1 (g, \delta , \vec{x}, \vec{y}) \land \FA{agree}_1 (g, \epsilon , \vec{x}, \vec{z}), \\ \\
%     %     \FA{merge} (\mu, \vec{x}, \nu, \vec{w}, \delta, \vec{y}, \epsilon,
%     %     \vec{z}, \vec{w}) := & \FA{agree} (\mu, \nu, \vec{x}, \vec{w}) \land
%     %     \FA{agree}_2 (\mu , \delta, \epsilon, \vec{x}, \vec{y}, \vec{z}) \\
%     %     & \land \FA{agree}_2 (\nu , \delta, \epsilon, \vec{w}, \vec{y},
%     %     \vec{z}), and \\ \\
%     %     \FA{MIN-MERGE} (\mu, \vec{x}, \nu, \vec{w}, \delta, \vec{y},
%     %     \epsilon, \vec{z}, \vec{w}) := & \FA{merge} (\mu, \vec{x}, \nu,
%     %     \vec{w}, \delta, \vec{y}, \epsilon, \vec{z}, \vec{w}) \\ & \land
%     %     (\forall \nu' (\FA{merge} (\mu, \vec{x}, \nu', \vec{w}, \delta,
%     %     \vec{y}, \epsilon, \vec{z}, \vec{w}) \implies \nu \leq nu'))
% \end{align*}.



% \theta_M (\delta , \vec{y}, \epsilon, \vec{z}, \mu, \vec{x})



\end{document}
