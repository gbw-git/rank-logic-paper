\documentclass[../paper.tex]{subfiles}
\begin{document}

In this section we develop the theory for defining a formula of FPR from a
family of $P$-uniform family of symmetric circuits with rank gates. We first
prove results on the generality of rigid circuits and circuits with bijective
labelings. Second, we prove that there are polynomial time algorithms for
determining canonical supports of gates. Third, we develop a FPR definable way
of evaluating a rank gate in the circuit. Finally, we complete the result by
explicitly defining an FPR formula corresponding to a given family of symmetric
circuits with rank gates.

We note that most of these results are for the more general case of symmetric
circuits with matrix-symmetric gates.

% \begin{remark}
%   Please ignore the first two sections (Rigid Circuits and Labelings and
%   Computing Supports), and go on to the third section. These subsections are
%   waiting until the second section of the paper (Symmetric Circuits) is complete
%   as the results in these subsections depend on definitions in that section.
% \end{remark}

\subsection{Rigid Circuits and Labelings}

In this section we prove important simplifying lemmas which allow for
assumptions of rigidity and bijective labels.

\begin{definition}
  We say that a circuit $C$ has bijective labels if for each gate $g$ in $C$,
  $L(g)$ is a bijection.
\end{definition}

\begin{lem}
  \label{lem:bij_labels}
  There is an algorithm that runs in polynomial time that takes in a circuit $C$
  and outputs a circuit with unique gates $C'$. Moreover, if $C$ was symmetric
  then $C'$ is symmetric. If $C$ is rigid then $C'$ is rigid.
\end{lem}

\begin{proof}
  Let $S = 2*\vert C \vert$. Recurse through the gates of $C$ topologically and
  let $h$ be the next gate topologically. If for all $g \in W(h, \cdot)$ we have
  that $L\vert (g)^{-1}(h) \vert = 1$ continue on to the next gate. If not add
  in a tower of $S$ $\land$ gates such that $h \rightarrow \land^h_1 \rightarrow
  \ldots \rightarrow \land^h_S$ (i.e. we have a tower of $\land$ gates with $h$
  as input to $\land^h_1$ and the output of each $\land^h_i$ connected to the
  input of each $\land^h_{i+1}$ for each $1 \leq i < S$). Now for each $g \in
  W(h, \cdot)$, if $L(g)^{-1}(h) = \{ s_0, \ldots, s_{r}\}$, for each $1 \leq i
  \leq r$ add in the wires $W(\land^h_i, g)$ and set $L(g)(s_{i}) = \land^h_i$.
  Now continue on to the next gate topologically and run the above algorithm.

  % First, notice that for a given gate $h$ and $k \in \mathbb{N}$, we can
  % define
  % a sub-circuit $h^k = 1 \and \cdots, 1 \and h$ (or rather a $k$-height tower
  % of
  % $k$ binary $\and$ gates with $h$ at the top and all other inputs set to
  % $1$).
  % We call $h$ the top of the sub-circuit $h^k$ and the bottom $and$ gate (the
  % output of the sub-circuit) the bottom gate. We may think of this as a
  % $k$-height copy of the gate $h$, in the sense that it has the same output as
  % $h$ and similar orbits. We now use different copies to distinguish gates
  % that
  % otherwise have the same labelling.

  % Let $h$ be the next gate topologically. Then let $r$ be maximal such that
  % $W(h,g)$ and $\omega_g^{-1}(h) = \{ s^g_1, s^g_2, \ldots, s^g_r \}$. Then
  % let
  % $k$ be the height of the highest tower with $h$ at the top and with it's
  % bottom connected to a gate in $W(h, \cdot)$. Then create a single
  % $k+r-1$-height tower by adding in the appropriate number of binary $\and$
  % gates below $h$.

  % For each $g \in W(h, \cdot)$ and for each $\omega_g^{-1}(h) = \{s^g_1,
  % s^g_2,\ldots , s^g_{r_g}\}$, set $L'(g)(s^g_1) = h$ each child starting with
  % the $and$-gate child to $h$ add in a wire from from the $i$th gate in the
  % tower to $g$ and set $L'(g)(s^g_{i+1}) = \and_i$, where $\and_i$ is the
  % $i$th
  % $\and$ gate in the tower starting with the $\and$ gate in the tower child to
  % $h$. There are enough gates in the tower as $r_g \leq r$.

  We call this updated circuit $C'$.
  
  Firstly, note that after running the above algorithm for each $g$ the
  labelling of $g$ will be a bijection. Moreover, it's easy to see that the
  output of each gate remains unchanged, and as such the output of the circuit
  is unchanged.

  Secondly, notice that the size of $C'$ is at most $2*\vert C \vert^2$, and
  note that the above algorithm runs in polynomial time.

  Now suppose that $C$ is symmetric. Let $\sigma$ be a permutation on the input
  universe and $\pi_C$ the induced automorphism on $C$. We now define $\pi$, the
  induced automorphism on $C'$. For each gate $g$ in $C'$, if $g$ is in $C$ then
  set $\pi(g) := pi_C(g)$. If $g$ is not in $C$ then $g$ must be some
  $\land^h_i$, for some $h$ in $C$. Then set $\pi(\land^h_i) :=
  \land^{\pi_C(h)}_i$. It is easy to see that $\pi$ is an automorphism, and
  $\pi$ extends $\sigma$.

  Suppose that $C$ is rigid. It is easy to see that $C'$ will be rigid as well.

\end{proof}


\begin{lem}
  There is an algorithm that runs in polynomial time that takes in a circuit $C$
  and outputs a circuit $C'$ such that $C'$ is rigid and has bijective labels.
  Moreover, if $C$ was symmetric it follows that $C'$ will be symmetric.
\end{lem}

\begin{proof}
  First run the algorithm from Lemma \ref{lem:bij_labels} on $C$, and call the
  output circuit $C$.
  
  Recurse through the gates of $C$ topologically. For each internal gate $g$,
  for all $g'$ in $C$ such that $g \neq g'$, $W(\cdot, g) = W(\cdot, g')$, $W(g,
  \cdot) = W(g', \cdot)$, $\Sigma(g) = \Sigma(g')$, $L(g) \sim L(g')$ and
  $\Omega^{-1}(g) = \Omega^{-1}(g')$, delete $g'$ and for all $s \in L^{-1}(g')$
  set $L(s) := g$.

  Now re-run the algorithm from Lemma \ref{lem:bij_labels} on $C$ and output the
  result.
\end{proof}

  \begin{lem}
    Let $C = \langle G, W, \Omega, \Sigma, \Lambda, L \rangle$ be a $(\SB, \MB,
    \tau)-circuit$ on structures of size $n$. There is a deterministic algorithm
    which runs in Poly($\vert C \vert$) and outputs a rigid $(\SB, \MB, \tau)
    circuit$ $C'$ such that $G' = G$ and for any $g \in G$, and any input
    $\tau$-structure $\mathcal{A}$ and any bijection $\gamma$ from $A$ to $[n]$,
    $C[\gamma \mathcal{A}](g) = C'[\gamma \mathcal{A}](g)$ and if $C$ is
    symmetric then so is $C'$.
  \end{lem}

  \begin{proof}
  
  \end{proof}

  \subsection{Computing Supports}
  
 \begin{lem}
   Let $C$ be a rigid $(\SB, MB, \tau)$-circuit on structures of size $n$ and
   $\sigma \in \sym_n$. There is a deterministic algorithm which runs in time
   Poly($\vert C \vert$) and outputs for each gate $g$ its image under the
   automorphism $\pi$ induced by $\sigma$, if it exists.
   \label{lem:computing-supports}
 \end{lem}
 \begin{proof}
   The proof proceeds by recursively going through the circuit and building the
   mapping $\pi$ induced by $\sigma$.

   Suppose $g$ is a constant gate, then $\pi g := g$. Suppose $g$ is a
   relational gate, then there is at most one gate $g'$ such that $\Sigma (g) =
   \Sigma (g')$ and $\sigma\Lambda (g') = \Lambda (g)$. If such a $g'$ exists
   assign $\pi g := g'$, else terminate with failure.

   If $g$ is an symmetric internal gate then (from rigidity) there is at most
   one gate $g'$ such that $\Sigma (g) = \Sigma(g')$ and $W_{g'} = \pi W_g$.
   Assign $\pi g := g'$ if such a gate exists, or else terminate with failure.

   If $g$ is a matrix-symmetric internal gate then consider the set of gates
   $g'$ such that $g'$ has children $\pi W_g$ and $\Sigma(g) = \Sigma(g')$, and
   let $A \times B = \dom (Sigma(g))$. If no such gate $g'$ exists, terminate
   with failure. Define $\sigma_{\pi, g'}:A \times B \rightarrow A \times B$ by
   $\sigma_{\pi, g'} = \omega^{-1}_{g'} \pi \omega_{g}$. Then clearly
   $\omega_{g'} \sigma_{\pi, g'} = \pi \omega_{g}$, and it's easy to show that
   $\pi \omega_g \sim \omega_{g'}$ iff $\sigma_{\pi,g'} \in \sym_A \times
   \sym_B$. But this just involves checking that $\sigma$ acts as a bijection on
   $A$ and $B$ separately and, given that $\vert A \vert$ and $\vert B \vert$
   are both bounded by $\vert C \vert$, the algorithm which just iterates
   through $A$ and $B$ is sufficient. If for every $g'$ it is found that
   $\pi_{\sigma,g'}$ is not in $\sym_A \times \sym_B$ then terminate with
   failure. If there is a $g'$ for which $\pi_{\sigma, g'} \in \sym_A \times
   \sym_B$ then it is unique by rigidity and so set $\pi g := g'$.

   If $g$ is an output gate, then check that for all tuples in $[n]^{q}$ we have
   that $\pi \Omega (x) = \Omega (\sigma (x))$, and terminate with failure if
   the condition is not met.

   If the algorithm has not terminated with failure, output the automorphism.

   The algorithm clearly runs in Poly($\vert C \vert$)
 \end{proof}

 \subsection {Evaluating Circuits}
 In this section let $\mathcal{C} = (C_n)_{n \in \mathbb{N}}$ be a family of
 polynomial-size rigid symmetric matrix-circuits that compute a $q$-ary query
 and let $n_0$ be the constant in the hypothesis of the Support Theorem. We also
 fix a structure $\mathcal{A}$ of size $n$ over the universe $U$ and an internal
 gate $g$ in the circuit $C_n$. In this section we show how to evaluate $g$ in
 $\FPR$ given evaluations of $g$'s children. In this way we will be able to
 recursively evaluate the circuit.

 If $g$ is a symmetric gate the results of Anderson and Dawar \cite{AndersonD17}
 will suffice for evaluating $g$. As such, we assume that $g$ is a
 matrix-symmetric gate, and for simplicity of notation we let $A \times B :=
 \ind(g)$.

 Recall that in order to evaluate the gate $g$ we need to consider a bijection
 $\gamma \in [n]^{\underline{U}}$, with the evaluation of $g$ given by
 $C_n[\gamma \mathcal{A}](g)$. In this subsection we show that the evaluation of
 $g$ depends only what $\gamma$ maps to $\consp(g)$. This result allows us to
 characterise all those bijections for which $g$ evaluates to true using only
 using only constant-size-domain injections in $U^{\consp(g)}$. In the next
 subsection we use this succinct encoding, along with the fixed-point operator,
 to evaluate the entire circuit.
 
 It will often be important that two assignments to a support be
 \emph{compatible} with one another in the sense that there is an injection over
 the union of their domains which agrees with each assignment on their
 respective domains. We formalise this in the following definition.

\begin{definition}
  Let $f \in Y^{\underline{X}}$ and $g : Z^{\underline{W}}$. We say that $f$ is
  \emph{compatible} with $g$, and we write $f \sim g$, if for all $a \in X \cap
  W$, $f(a) = g(a)$ and for all $a \in X \setminus W$ and $b \in W \setminus X$,
  $f(a) \neq g(b)$.
\end{definition}

It is also useful to have some notation for combining two compatible functions.
Let $f : X \rightarrow Y$ and $p: X' \rightarrow Y'$ be compatible injections.
Define the combination $(f | p): X \cup X' \rightarrow Y \cup Y'$ by
\begin{align*}
  (f \vert p) (x) =
  \begin{cases}
    f (x) & x \in X \\
    p (x) & x \in Y.
  \end{cases}
\end{align*}

% \begin{definition}
%   Let $f: A \times B \rightarrow H$ and $p: A' \times B' \rightarrow H$. We
%   say that $f$ and $p$ are \emph{row-column equivalent} if there exist
%   bijections $\alpha: A \rightarrow A'$ and $\beta: B \rightarrow B'$ such
%   that for all $(a, b) \in A \times B$, $f(a,b) = p(\alpha(a), \beta(b))$.
% \end{definition}

Given an assignment $\gamma \in [n]^{\underline{U}}$, we can evaluate the child
gates of $g$, forming the matrix $L^{\gamma} : A \times B \rightarrow \{0,1\}$
defined by $L^{\gamma} (a,b) := C[\gamma \mathcal{A}](L(g)(a,b))$. This function
allows us to evaluate $g$. Moreover, since $g$ is matrix-symmetric the
evaluation of $g$ is constant on any class of functions sort-equivalent to
$L^\gamma$. In the following Lemma we show that for any $\gamma_1, \gamma_2 \in
[n]^{\underline{U}}$ that agree on the support of $g$, $L^{\gamma_1}$ is
sort-equivalent to $L^{\gamma_2}$. From this we can conclude that that the
evaluation of $g$ for $\gamma$ depends only on the assignment to its support
(i.e. on what $\gamma$ maps to $\consp(g)$).

\begin{lem}
  Let $g$ be a matrix-symmetric gate in $C_n$. Let $\eta \in
  U^{\underline{\consp(g)}}$ and $\gamma_1, \gamma_2 \in [n]^{\underline{U}}$
  such that $\gamma^{-1}_1 \sim \eta$ and $\eta \sim \gamma^{-1}_2$. Then
  $L^{\gamma_1}$ and $L^{\gamma_2}$ are sort-equivalent.
  \label{lem:support-determines-evaluation}
\end{lem}

\begin{proof}
  We have that there exists a unique $\pi \in \sym_n$ such that $\pi \cdot
  \gamma_1 = \gamma_2$. Moreover, since $\gamma^{-1}_1$ and $\gamma^{-1}_2$ are
  both consistent with $\eta$, it follows that $\pi$ must fix $\consp(g)$
  pointwise. Thus $L(g)$ is sort-equivalent to $\pi \cdot L(g)$, and so there
  exists $(\sigma, \lambda) \in \sym_A \times \sym_B$ such that $\pi \cdot L(g)
  = L(g) \cdot (\sigma, \lambda)$.

  We then have that,
  \begin{align*}
    L^{\gamma_1} (a,b) &= C_n[\gamma_1 \mathcal{A}](L(g)(a,b))\\
                       & = C_n[\pi \gamma_1 \mathcal{A}][\pi L(g)(a,b)] \\
                       & = C_n[\gamma_2 \mathcal{A}][L(g)((\sigma, \lambda)(a,b))]\\
                       & = L^{\gamma_2} ((\sigma, \lambda) (a,b)),
  \end{align*}
  and it follows that $L^{\gamma_1} \sim L^{\gamma_2}$.
\end{proof}

For each gate $h \in C_n$ we associate with it a set $\Gamma_h$ consisting of
all those bijections which cause $h$ to evaluate to true, i.e. $\Gamma_h:=
\{\gamma \in [n]^{\underline{U}} : C[\gamma \mathcal{A}](h) = 1 \}$. Lemma
\ref{lem:supports-determine-evaluation} gives us that the membership of $\gamma$
in $\Gamma_h$ is entirely determined by what $\gamma$ maps to $\consp(h)$. As
such, we also associate with $h$ a set $\EV_h \subseteq
U^{\underline{\consp(h)}}$ consisting of all assignments to the support of $h$
for which $h$ evaluates to true, i.e. $\EV_h := \{ \eta:
U^{\underline{\consp(h)}} : \exists \gamma \in \Gamma_h \wedge \eta \sim
\gamma^{-1})\}$, and note that $\Gamma_h$ is entirely determined by $\EV_h$. The
important point to note is that each $\eta \in \EV_h$ is defined on a
constant-size domain, and as such $\EV_h$ gives us a succinct way of encoding
$\Gamma_h$.

We aim to show that $\EV_g$ can be recursively constructed for each $g \in C_n$.
In particular, we show that for any $\eta \in U^{\underline{sp(g)}}$, there is
an $\FPR$-definable matrix $M$ such that for any $\gamma \in
[n]^{\underline{U}}$ with $\gamma^{-1} \sim \eta$, $M$ is sort-equivalent to
$L^{\gamma}$. This result allows us to decide the membership of $\eta$ in
$\EV_g$ by first defining $M$ for $\eta$, computing rank the rank of $M$ over
the appropriate prime field, and then comparing this result with the threshold.

% For the remainder of this section we fix an injection $\eta \in
% U^{\underline{sp(g)}}$, and define the matrix $M$.





% \begin{remark}
%   Let $\sigma \in \spstab{g}$, then we know that there exists $(\sigma_r,
%   \sigma_c) \in \sym_A \times \sym_B$ and $\sigma_r (i) = \row (\sigma h)$,
%   for any $h \in H$ such that $\row (h) = i$ and similarly $\sigma_c (j) =
%   \column (\sigma h)$, for any $h \in H$ such that $\column (h) = j$.
% \end{remark}

% We introduce here some useful notation.

% \begin{definition}
%   Let $S^r_h = \{ \sigma \in \stab (\consp(g)) : \sigma \vec{r_h} = \vec{r_h}
%   \}$ and $G^r_h = \{ \sigma \in \stab(\consp(g)) : \row(\sigma h) =
%   \row(h)\}$. Let $S^c_h = \{ \sigma \in \stab (\consp(g)) : \sigma \vec{c_h}
%   = \vec{c_h} \}$ and $G^c_h = \{ \sigma \in \stab(\consp(g)) : \column(\sigma
%   h) = \column(h)\}$.
% \end{definition}

% Clearly, by definition of a row and column support, $S^r_h \subseteq G^r_h$
% and $S^c_h \subseteq G^c_h$.

% \begin{remark}
%   In this section I assume for the moment that:
%   \begin{itemize}
%   \item $\consp (g) = \{\}$,
%   \item $S^r_h = G^r_h$ and $S^c_h = G^c_h$,
%   \item $\forall h,h' \in H$ we have $\vert r_h \vert = \vert r_{h'} \vert$
%     and $\vert c_h \vert = \vert c_{h'} \vert$,
%   \item For all $i,i' \in A$ $\exists \sigma \in \stab(\consp (g))$ such that
%     $\sigma_r i = i'$. Similarly for all $j, j' \in B$ $\sigma \exists \in
%     \spstab{g}$ such that $\sigma_c j = j'$.
%   \item $\forall h \in H$, $\orb (h) = H$
%   \end{itemize}
% \end{remark}

% Let $k_r = \vert r_h \vert$ and $k_c = \vert c_h \vert$. Let $\mathcal{G}_r =
% \{\sigma_r : \sigma \in \spstab{g}\}$ and $\mathcal{G}_c = \{sigma_c : \sigma
% \in \spstab{g}\}$.

% \begin{definition}
%   Let $\mathcal{G} \leq \sym_n$ and $x$ be an element of a set on which an
%   action of $\sym_n$ is defined. Then $\orb_{\mathcal{G}}(x) = \{x^\pi: \pi
%   \in \mathcal{G}\}$.

%   For $i \in [a]$ let $\orb_r(i) = \orb_{\mathcal{G}_r}(i)$ and for $j \in
%   [b]$ let $\orb_c (j) = \orb_{\mathcal{G}_c}(j)$.
% \end{definition}

% \begin{definition}
%   Let $A, B \subseteq [n]$ and let $t = (t_1, t_2, t_3) \in \mathbb{N}^3$. We
%   say that $(A,B)$ has \emph{type} $t$ if $\vert A \vert = t_1$, $\vert B
%   \vert = t_2$ and $\vert A \cap B \vert = t_{3}$. We say that $\type (A,B) =
%   t$.
% \end{definition}

% For the sake of brevity, for sets $Z,X,Y$, and a function $f : Z \rightarrow
% X$ and injection $p :Z \rightarrow Y$, let $f_p = f \cdot p^{-1}$.

% We note that for any $s \subseteq [n]$, $s$ inherits in the linear order on
% $[n]$ and as such may also be thought of as an ordered set. We write $\vec{s}$
% to denote the $\vert s \vert$-tuple, consisting of the elements in $s$ in the
% inherited order. Let $r \subseteq [n]$ and $\vec{x} \in U^{\underline{[\vert r
% \vert]}}$, we can then derive a function $\vec{x}_r : r \rightarrow U$ defined
% by $\vec{x}_r (a) = \vec{x}$

% We say that two functions pairs of elements have the same type

% \begin{definition}
%   Let $\vec{x}, \vec{y} : Z \rightarrow X$ and $\vec{r}, \vec{c}: Z
%   \rightarrow Y$ be injections. If $\vec{x} \cdot \vec{r}^{-1} \sim \vec{y}
%   \cdot \vec{c}^{-1}$ we say that $(\vec{x}, \vec{y})$ and $(\vec{r} \vec{c})$
%   have the same \emph{type}.
% \end{definition}


% \begin{definition}
%   Let $\vec{x}, \vec{y} : Z \rightarrow X$ and $\vec{r}, \vec{c}: Z
%   \rightarrow Y$ be injections. If $\vec{x} \cdot \vec{r}^{-1} \sim \vec{y}
%   \cdot \vec{c}^{-1}$ we say that $(\vec{x}, \vec{y})$ and $(\vec{r} \vec{c})$
%   have the same \emph{type}.
% \end{definition}

% We note that if we have $f : X \rightarrow Y$ and $p: X' \rightarrow Y'$ and
% $f \sim p$ then define $(f \vert p): X \cup X' \rightarrow Y \cup Y'$ by

% \begin{align*}
%   (f \vert p) (x) =
%   \begin{cases}
%     f (x) & x \in X \\
%     p (x) & x \in Y.
%   \end{cases}
% \end{align*}



% \begin{claim}
%   Let $A_1,B_1, A_2, B_2 \subseteq [n]$. Then $(A_1, B_1)$ and $(A_2, B_2)$
%   have the same type iff $\exists \pi \in \sym_n$ such that $A_1 = A^\pi_2$
%   and $B_1 = B^\pi_2$.
% \end{claim}

% \begin{definition}
%   Let $f: A \rightarrow S$ and $g: B \rightarrow S$ be injections, with $A$
%   and $B$ being finite sets. Then $(f,g)$ has \emph{type} $t= (t_1 , t_2, t_3)
%   \in \mathbb{N}^3$ if $\vert A \vert = t_1$ and $\vert B \vert = t_2$ $\vert
%   \{i \in A \cap B : f(i) = g(i)\} \vert = t_3$. We say that $\type (f,g) =
%   t$.
% \end{definition}

% \begin{definition}
%   Let $h \in H$ the \emph{type} of $h$ is the type of $(r_h, c_h)$. We denote
%   the type of $h$ by $\type (h)$.
% \end{definition}

% We define for any set $Y$ with a linear-order $\leq$ on $Y$, a function
% $\ord_\leq: Y \rightarrow \vert Y \vert$ be defined by $\ord_\leq (y) = o_y$,
% where $o_y$ is the position of $y$ in $Y$ in the ordering. We call this
% function the \emph{order map for $Y$}. For a subset $\text{sp} \subseteq [n]$,
% we use $\vec{\text{sp}}$ to denote the inverse of the order map for
% $\text{sp}$.

For a gate $h \in H_g$ define $A_h := \{\vec{x} \in U^{\underline{\consp(s)}} :
\eta \sim \vec{x}\}$. We should also like to consider similar sets of functions
for other objects in the circuit which may be permuted and which are relevant to
$g$. More generally, let $X$ be a set on which the left group action of $\sym_n$
is defined and $s \in X$. We let $A_s = \{\vec{x} \in U^{\underline{\consp(s)}}
: \eta \sim \vec{x} \cdot \vec{\consp}^{-1}(s) \}$. We will be particularly
interested in the case where $X$ is the set of rows or columns (i.e. $A$ or $B$)
indexing the inputs of $g$.

% For $\vec{x} \in A_s$, we use $\vec{x}_s$ from here forward to denote $\vec{x}
% \cdot \vec{\consp}^{-1}(s)$.

Let $s \in X$ and $\vec{x}, \vec{x}' \in A_s$ and we say that $\vec{x}$ and
$\vec{x}'$ are \emph{mutually stable} if there exists $\sigma \in \stab(s) \cap
\spstab{g}$ such that $\vec{x} = \vec{x}' \cdot \sigma$. Note that mutual
stability is an equivalence relation on $A_s$, and we denote the equivalence of
two vectors $\vec{x}, \vec{x}' \in A_s$ by $\vec{x} \equiv_s \vec{x}'$.

\begin{lem}
  Let $X$ be a set on which the left group action of $\sym_n$ is defined, and
  let $\gamma: U \rightarrow [n]$ be a bijection such that $\gamma^{-1} \sim
  \eta$. Let $s \in X$ and let $\sigma, \sigma' \in \stab(\consp(g))$. Then
  $\sigma(s) = \sigma' (s)$ if, and only if, $\sigma \equiv_s \sigma'$.
  \label{lem:functions-well-defined}
\end{lem}

\begin{proof}
  (removed, to be included later)
  % Suppose $\sigma(s) = \sigma'(s)$. Take $x := \sigma(s)$. So then
  % $\gamma^{-1}(\sigma(s))$
\end{proof}


% Let $L(g)(i,j) = h \in H$, $\vec{x} \in A_i$ and $\vec{y} \in A_j$. Let
% $\vec{r} \in ^{\underline{\consp(i)}}$ and $\vec{c}
% \in\consp{j}^{\underline(\consp(j))}$. Suppose $(\vec{r}, \vec{c})$ has the
% type of $(\vec{x}, \vec{y})$. Then we can define $(\vec{x}\vert \vec{y}):
% \consp(i) \cup \consp(j) \rightarrow U$ by
% \begin{align*}
%   (\vec{x}_{\vec{r}} \vert \vec{y}_{\vec{c}}) (z) =
%   \begin{cases}
%     \vec{x} (\vec{r}^{-1}(z)) \text{ if } z \in \consp(i) \\
%     \vec{y} (\vec{r}^{-1}(z)) \text{ if } z \in \consp(j). \\
%   \end{cases}
% \end{align*}



% \begin{claim}
%   Let $f: A \rightarrow S$ and $g B \rightarrow S$ be injections. Then $(f,g)$
%   has the same type as $(A,B)$. It follows that if $h \in H$, and $(i,j) =
%   L^{-1}(h)$,with $f \in A^r_i$ and $ g \in A^c_j$ then $h$ has the same type
%   as $(f,g)$.
% \end{claim}

% For $(i,j) \in [a] \times [b]$ let $H_{i,j} = \{L(p,q): (p,q) \in \orb_r(i)
% \times \orb_c(j)]\}$.

% \begin{claim}
%   For all $(i', j') \in \orb_r(i) \times \orb_c(j)$ and $\sigma \in
%   \spstab{g}$, $(\sigma_r i', \sigma_cj') \in \orb_r(i) \times \orb_c(j)$.
% \end{claim}

% \begin{claim}
%   For all $(i,j) \in [a] \times [b]$, $H_{i,j}$ is a union of orbits.
% \end{claim}

% \begin{lem}
%   Let $(i,j) \in [a] \times [b]$. If $h, h' \in H_{i,j}$ and $h, h'$ are the
%   same type then $h' \in \orb(h)$.
% \end{lem}

We now define a matrix. We begin by defining the index sets for the matrix.
% We by defining a matrix We now define a matrix that we later show to be
% definable in $\FPR$. We then show that this matrix is row-column equivalent to
% $L^{\gamma}$ for any bijection $\gamma: U \rightarrow [n]$ compatible with
% $\eta$. Computing the rank of this matrix in $\FPR$ allows us to then evaluate
% $g$.

Let $R^{\min} = \{\min (\orb(\row(h))) : h \in H_g\}$ and $C^{\min} = \{ \min
(\orb (\column(h))) : h \in H_g\}$ and let
\begin{align*}
  I = \{(i, \vec{x}): i \in R^{\min}, \vec{x} \in A_i\},
\end{align*}
and
\begin{align*}
  J = \{(j, \vec{y}): j \in C^{\min}, \vec{y} \in A_j\}.
\end{align*}


% \begin{align*}
%   M ((i, \vec{x}), (j, \vec{y})) := \bigvee_{t \in \types} ((\vec{x},
%   \vec{y}) \text{ has type } t) \land (\vec{x} | \vec{y}) \in \EV_{\mu_{i,j}(t)}.
% \end{align*}

For $(i, \vec{x}) \in I$ and $(j, \vec{y}) \in J$ indexing an element in the
matrix we should like to define the value at that point in the matrix by somehow
combining $\vec{x}$ and $\vec{y}$, which we think of as assignments to the
canonical support of the row $i$ and column $j$ respectively. In order to do
that we permute $\vec{y}$ so that it is compatible with $\vec{x}$.

% The idea now is to move $\vec{x}$ and $\vec{y}$ such that the moved versions
% are compatible. We can then combine these new vectors and define our matrix.
% In order to do this we first move $\vec{x}$ in a way that keeps

% and let $u_1 , \ldots , u_{2k}$ be the first $2k$ elements of $[n] \setminus
% \consp(g)$. Let $r:= (\consp(g) \cap \consp(i)) \cup \{u_i : i \in [\vert
% \consp(i) \setminus \consp(g) \vert ] \}$ and $\vec{r} \in r^{\underline
% {\consp(i)}}$ be such that

Let $(i, \vec{x}) \in I$ and $(j, \vec{y}) \in J$. Let $u_1, \ldots , u_k$ be
the first $k$ elements of $[n] \setminus (\consp(g) \cup \consp(i))$. Then let
$T = \{a \in \consp(j) \setminus \consp(g) : \vec{y}(a) \in \vec{x}(\consp(i)
\setminus \consp(g))\}$ and $\vec{c} \in \sym_n$ such that
\[
  \vec{c} (a) =
  \begin{cases}
    a & a \in \consp(g) \cap \consp(j)\\
    \vec{x}^{-1}(\vec{y}(a)) & a \in T\\
    u_{i} & \text{$a$ is the $i$th element of $(\consp(j) \setminus (\consp(g)
      \cup T)))$}.
  \end{cases}
\]
\begin{lem}
  For any $(i, \vec{x}) \in I$ and $(j, \vec{y}) \in J$ and $\vec{c}$ be defined
  as above, then $\vec{x} \sim \vec{y}_{\vec{c}}$.
\end{lem}
\begin{proof}
  Let $z \in \consp(i) \cap c$ and $z' = \vec{c}^{-1}(z)$. Suppose $z' \in
  \consp(g)\cap \consp(j) \cap \consp(i)$. Then we have $\vec{x}(z) =
  \vec{x}(z') \eta (z') = \vec{y}(z') = \vec{y}_{\vec{c}}(z)$. By a similar
  argument, if $z' \consp(g) \cap \consp(j) \setminus \consp(i)$ we have
  $\vec{x}(z) \neq \vec{y}_{\vec{c}}(z)$. Suppose $z' \in T$. Then $\vec{c}(z')
  = \vec{x}^{-1}(\vec{y}(z'))$ which gives us that $\vec{y}_{\vec{c}}(z) =
  \vec{y}(z') = \vec{x}(\vec{c}(z')) = \vec{x}(z)$. We finally note that $z'
  \notin (\consp(j) \setminus (\consp(g) \cup T))$ as $\{u_1 , \ldots , u_k\}
  \cap \consp(i) = \emptyset$. This completes the intersection component of
  compatibility.

  Let $z \in \consp(i) \setminus c$ and $w \in c \setminus \consp(i)$. Let $w' =
  \vec{c}^{-1}(w)$. Suppose $w' \in \consp(g) \cap \consp(j)$. Then from the
  fact that $w \notin \consp(i)$ we have that $\vec{y}_{\vec{c}}(w) \neq
  \vec{x}(z)$ (using a similar argument as in the above case). Suppose $w' \in
  T$. Then there exists $b \in \consp(i) \setminus \consp(g)$ such that
  $\vec{y}(w') = \vec{x}(b)$. It follows that $w = \vec{c}(w') =
  \vec{x}^{-1}\vec{y} (w') = b$, which is a contradiction as $w \notin
  \consp(i)$ by assumption, and we conclude $w' \notin T$. Suppose finally that
  $w' \in \consp(j) \setminus (\consp(g) \cup T)$. It follows that for all $b
  \in \consp(i) \setminus \consp(g)$ we have that $\vec{x}(b) \neq
  \vec{y}_{\vec{c}}(w)$. It remains to check the result for $b \in (\consp(i)
  \setminus c) \setminus (\consp(i) \setminus \consp(g)) = (\consp(g) \cap
  \consp(i)) \setminus c$. But then $b \notin \consp(j)$, and so $\vec{x}(b) =
  \eta (b)$. But $w' \notin \consp(g)$, and so $\vec{x}(b) = eta(b) \neq
  \vec{y}(w') = \vec{y}(w)$. The result follows.
\end{proof}

\begin{lem}
  \label{lem:permutation_row-column}
  For any $(i, \vec{x}) \in I$ and $(j, \vec{y}) \in J$ there exists $\sigma_r,
  \sigma_c \in \spstab{g}$ such that if we let $\vec{r} := \sigma_r \cdot
  \vec{\consp}(i)$ and $\vec{c} := \sigma_c \cdot \vec{\consp}(j)$ and
  $\vec{x}_{\vec{r}} \sim \vec{y}_{\vec{c}}$.
\end{lem}

% \[
%   \vec{r} (a) =
%   \begin{cases}
%     a & a \in \consp(g) \cap \consp(i) \\
%     u_{i} & \text{$a$ is the $i$th element of $\consp(i) \setminus \consp(g)$
%     in the induced order}.
%   \end{cases}
% \]
% Let $T = \{a \in \consp(j) \setminus \consp(g) : \vec{y}(a) \in
% \vec{x}(\consp(i) \setminus \consp(g))\}$. Then let $c:= \vec{r} \cdot
% \vec{x}^{-1} \cdot \vec{y} (T) \cup \{u_{k+i} : i \in [\vert \consp(j)
% \setminus (\consp(g) \cup T) \vert ] \}$ and $\vec{c} \in
% c^{\underline{\consp(j)}}$ be such that
% \[
%   \vec{c} (a) =
%   \begin{cases}
%     a & a \in \consp(g) \cap \consp(j)\\
%     \vec{r} (\vec{x}^{-1}\vec{y}(a)) & a \in T\\
%     u_{k+i} & \text{$a$ is the $i$th element of the set $(\consp(j) \setminus
%     (\consp(g) \cup T)))$}.
%   \end{cases}
% \]

% \[
%   \vec{c} (a) =
%   \begin{cases}
%     a & a \in \consp(g) \cap \consp(j)\\
%     \vec{r} (\vec{x^{-1}(\vec{y}(a))}) & \vec{y}(a) \in \vec{x}(\consp(i)
%     \setminus \consp(g))\\
%     u_{k+i} & \text{$a$ is the $i$th element of $\consp(j) \setminus
%     (\consp(g) \cup \consp(i))$ in the induced order}.
%   \end{cases}
% \]


% Let $(i, \vec{x}) \in I$ and $(j, \vec{y}) \in J$ and let $u_1 , \ldots ,
% u_{2k}$ be the first $2k$ elements of $[n] \setminus \consp(g)$. Then let
% \[r = \eta^{-1} (\img(\vec{x}) \cap \eta (\consp(g))) \cup
%   \{u_{\vec{x}^{-1}(a)}: a \in \img(x) \setminus \eta (\consp (g))\} \] and
% \[s = \eta^{-1} (y \cap \eta (\consp(g))) \cup (x \cap y) \cup \{ u_{k +
%   \vec{x}^{-1}(a)} : a \in y \setminus (x \cup \eta (\consp (g))) \}. \]
% Define
% \[
%   \vec{r} (a) =
%   \begin{cases}
%     \eta^{-1} (\vec{x} (a)) & a \in \vec{x}^{-1} (x \cap \eta (\consp(g)))
%     \\
%     u_{a} & a \in \vec{x}^{-1} (x \setminus \eta(\consp(g)),
%   \end{cases}
% \]
% and
% \[
%   \vec{c} (a) =
%   \begin{cases}
%     \eta^{-1} (\vec{y} (a)) & a \in \vec{y}^{-1}(y \cap \eta (\consp (g)))
%     \\
%     \vec{r} (a) & a \in \vec{y}^{-1} (x \cap y \setminus \eta (\consp (g)))
%     \\
%     u_{k+a} & \text{otherwise}.
%   \end{cases}
% \]

% \begin{remark}
%   The above is quite messy and, while I checked it a few times when I first
%   wrote it, I want to double check on it and look for other ways to write this
%   bit up. Moreover, I think of some of this can be simplified using the new
%   definitions I've added.
% \end{remark}
% \begin{lem}
%   For any $(i, \vec{x}) \in I$ and $(j, \vec{y}) \in J$ and with $\vec{r}$ and
%   $\vec{c}$ defined as above, then $\vec{x}_{\vec{r}} \sim \vec{y}_{\vec{c}}$.
% \end{lem}
% \begin{proof}
%   Let $z \in c \cap r$. Then $\exists z_1 \in \consp(i)$ and $z_2 \in
%   \consp(j)$ such that $z = \vec{r}(z_1) = \vec{c}(z_2)$. Suppose $z_1 \in
%   \consp(g)$,y then $z = \vec{r}(z_1) = z_1 = \vec{c}(z_2)$. But we can not
%   have that $\vec{y}(z_2) = \vec{x}(b)$ for some $b \in \consp(i) \setminus
%   \consp(g)$, as then $\vec{r}(b) = \vec{c}(z_2) = z_1$, which gives that $b
%   \in \consp(g)$, a contradiction. It follows $z_2 \in \consp(g) \cap
%   \consp(j)$, and so $z_1 = \vec{c}(z_2) = z_2$, and thus
%   $\vec{x}_{\vec{r}}(z) = \vec{x}(z_1) = \vec{y}(z_2) = \vec{y}_{\vec{c}}(z)$.
%   Suppose $z_1 \in \consp(i) \setminus \consp(g)$, then $c(z_2) = r(z_1)$
%   gives us that there exists $b \in \consp(i) \setminus \consp(g)$ such that
%   $\vec{x}(b) = \vec{y}(z_2)$ and $\vec{c}(z_2) = \vec{r}(b)$. But then
%   $\vec{r}(b) = \vec{r}(z_2)$, and so $b = z_2$ and thus $\vec{x}_{\vec{r}}(z)
%   = \vec{x}(z_1) = \vec{y}(z_2) = \vec{y}_{\vec{c}}(z)$.

%   %   But then $\vec{c}(z_2) = \vec{r}(b)$, where $b \in \consp(i)$ and
%   %   $\vec{x}(b)
%   %   = \vec{y}(z_2)$. It follows that $\vec{r}(b) = \vec{r}(z_1)$, and so $b
%   %   =
%   %   z_1$. Thus $\vec{x}_{\vec{r}}(z) = \vec{x}(\vec{r}^{-1}(z)) =
%   %   \vec{x}(z_1) =
%   %   \vec{y}(z_2) = \vec{y}_{\vec{c}}(z)$.

%   Suppose $z \in r \setminus c$ and $w \in c \setminus r$ and suppose
%   $\vec{x}_{\vec{r}} (z) = \vec{y}_{\vec{c}}(w)$. Let $z' = \vec{r}^{-1}(z)$
%   and $w' = \vec{c}^{-1}(z)$. It suffices to prove that $z' = w'$ in order to
%   derive a contradiction and hence prove the result. Suppose $z' \in \consp(i)
%   \cap \consp(g)$. Then if $w' \in \consp(j) \cap \consp(g)$, it follows that
%   $z' = w'$ as $\eta (z') = \vec{x}(z') = \vec{y}(w') = \eta (w')$ and $\eta$
%   is an injection. Suppose instead $w' \in \consp(j) \setminus \consp(g)$ and
%   there exists $b \in \consp(i) \setminus \consp(g)$ such that $\vec{x}(b) =
%   vec{y}(w')$. Since $\vec{x}$ is injective it follows that $b = z'$, which is
%   a contradiction as $z' \in \consp(g)$ by assumption. Suppose no such $b$
%   exists. Then $w' \in \consp{j} \setminus (\consp(g) \cap \consp(i))$. It
%   follows

%   It is easy to see that $z' \notin \consp(j) \cap \consp(g)$ and $w' \notin
%   \consp(i) \cap \consp(g)$. Suppose $z' \in \consp(g)$, then


% \end{proof}
  

% \begin{lem}
%   \label{lem:permutation_row-column}
%   For any $(i, \vec{x}) \in I$ and $(j, \vec{y}) \in J$ and with $\vec{r}$ and
%   $\vec{c}$ defined as above, there exists $\sigma_1, \sigma_2 \in \spstab{g}$
%   such that $\sigma_1 \cdot \vec{\consp}(i) = \vec{r}$ and $\sigma_2 \cdot
%   \vec{\consp}(j) = \vec{c}$. Moreover, $\vec{x}_{\vec{r}} \sim
%   \vec{y}_{\vec{c}}$.
% \end{lem}
% \begin{proof}
%   Let $a \in r \cap c$, then if $a \in \consp(g)$ we have $\vec{x}_{\vec{r}}
%   (a) = \vec{x}_{\vec{c}}(a)$. Then suppose $a \in (r \cap c) \setminus
%   \consp(g)$, then we must have that $\vec{c}^{-1}(a) \in \consp(i) \cap
%   \consp(j)$, and so $\vec{y}_{\vec{c}}(a) = \vec{y} \cdot \vec{c}^{-1} (a) =
%   \vec{y} \cdot (\vec{r} \cdot \vec{x}^{-1} \cdot \vec{y})^{-1}(a) = \vec{y}
%   \cdot \vec{y}^{-1} \cdot \vec{x} \cdot \vec{r}^{-1} (a) =
%   \vec{x}_{\vec{r}}(a)$.

%   Suppose $a \in r \setminus c$, then if $a \in \consp(g)$, we have that
%   $\vec{x}_{\vec{r}}(a) = \eta (a) \neq \vec{y}_{\vec{c}}(b)$ for all $b \in c
%   \setminus r$ as otherwise $b = \vec{c}^{-1}(b) = a$, a contradiction.
%   Suppose $a \in r \setminus (c cup \consp(g))$ and suppose there exists $b
%   \in c \setminus r$ such that $\vec{y}_{\vec{c}}(b) = \vec{x}_{\vec{r}}(a)$.
%   Clearly $b \notin \consp(g)$ as otherwise $a \in \consp(g)$. It follows that
%   $\vec{c}^{-1}(b) \notin $
  
% \end{proof}

% \begin{lem}
%   \label{lem:permutation_row-column}
%   For any $(i, \vec{x}) \in I$ and $(j, \vec{y}) \in J$ and with $\vec{r}$ and
%   $\vec{c}$ defined as above, there exists $\sigma_1, \sigma_2 \in \spstab{g}$
%   such that $\sigma_1 \cdot \vec{\consp}(i) = \vec{r}$ and $\sigma_2 \cdot
%   \vec{\consp}(j) = \vec{c}$.
% \end{lem}
% \begin{proof}
%   To be added from the book
% \end{proof}

% \begin{lem}
%   \label{lem:permutation_row-column}
%   For any $(i, \vec{x}) \in I$ and $(j, \vec{y}) \in J$ and with $\vec{r}$ and
%   $\vec{c}$ defined as above, there exists $\sigma_1, \sigma_2 \in \spstab{g}$
%   such that $\sigma_1 \cdot \vec{\consp}(i) = \vec{r}$ and $\sigma_2 \cdot
%   \vec{\consp}(j) = \vec{c}$. Moreover, $\vec{x}_{\vec{r}} \sim
%   \vec{y}_{\vec{c}}$.
% \end{lem}

So for any $(i, \vec{x}) \in I$ and $(j, \vec{y}) \in J$ we have $\vec{r}$,
$\vec{c}$, $sigma_r$ and $\sigma_c$ from Lemma \ref{lem:permutation_row-column}.
Let $h = L(g)(\sigma_r(i), \sigma_c (j))$. We define the matrix $M : I \times J
\rightarrow \{0,1\}$ by

\begin{align*}
  M((i , \vec{x}), (j, \vec{y})) := (\vec{x}_{\vec{r}} \vert \vec{y}_{\vec{c}}) \in EV_h.
\end{align*}

Furthermore, we note the following.



Let $I /{\sim} = \{(i, \vec{x}): i \in R^{\min}, \vec{x} \in A_i{\sim_i}\},$ and
$J/{\sim} = \{(j, \vec{y}): j \in C^{\min}, \vec{y} \in A_j/{\sim_j}\}$. Let the
matrix $M_{~} : I /{\sim} \times J / {\sim} rightarrow \{0,1\}$ be defined by
$M_{~} ((i, [\vec{x}]) (j, [\vec{y}])) = M(((i, \vec{x}), (j, \vec{y})))$. Lemma
\ref{lem:matrix-quot-well-defined} gives us that this function is well-defined.

It remains to show that $M_{~} \sim L^{\gamma}$ for some (and so all) bijections
$\gamma: U \rightarrow [n]$.
% \begin{definition}
%   Let $M_1$ and $M_2$ be matrices over some field, with row and column indexes
%   given by $(A_1, B_1)$ and $(A_2, B_2)$, respectively. We say that $M_1$ and
%   $M_2$ are row-column equivalent iff there exists bijections $\alpha: A_1
%   \rightarrow A_2$ and $\beta: B_1 \rightarrow B_2$ such that for all $(a,b)
%   \in A_1 \times B_1$ we have that $M_1(a,b) = M_2 (\alpha (a), \beta (b))$.
%   If $M_1$ and $M_2$ are row-column equivalent we say that $M_1 \sim M_2$.
% \end{definition}

% Fix $\gamma: U \rightarrow [n]$ such that $\gamma^{-1} \sim \eta$. We define
% $L^\gamma: A \times B \rightarrow \{0,1\}$ by $L^\gamma(a,b) = C[\gamma
% \mathcal{A}](L (a,b))$.
% \\~\\
% We note that, in fact, it is the choice of the assignment to the support of
% $g$, i.e. $\eta$, that really matters in the sense that for any two global
% assignments that agree on the support of $g$ will produce row-column
% equivalent matrices. The following lemma formalises this observation.

% \begin{lem}
%   Let $g$ be a matrix-symmetric gate in $C_n$ with children $H$ and matrix
%   labelling $L(g)$. Let $\eta \in U^{\consp(g)}$, and suppose $\gamma_1,
%   \gamma_2: U \rightarrow [n]$ with $\gamma^{-1}_1 \sim \alpha$ and $
%   \gamma^{-1}_2 \sim \alpha$. Let $A \times B = \dom (L(g))$.

%   Then for an input structure $\mathcal{A}$, $L^{\gamma_1} \sim L^{\gamma_2}$.
% \end{lem}
% \begin{proof}
%   We have that there exists a unique $\pi \in \sym_n$ such that $\pi \gamma_1
%   = \gamma_2$. Moreover, since $\gamma^{-1}_1$ and $\gamma^{-1}_2$ are both
%   consistent with $\eta$, it follows that $\pi$ must fix $\consp(g)$. Thus
%   $L(g) \sim \pi L(g)$, and so there exists $(\alpha, \beta)$ such that $\pi
%   L(g) = L(g) \cdot (\alpha, \beta)$.

%   We then have that,
%   \begin{align*}
%     L^{\gamma_1} (a,b) &= C_n[\gamma_1 \mathcal{A}](L(g)(a,b))\\
%                        & = C_n[\pi \gamma_1 \mathcal{A}][\pi L(g)(a,b)] \\
%                        & = C_n[\gamma_2 \mathcal{A}][L(g)((\alpha, \beta)(a,b))]\\
%                        & = L^{\gamma_2} ((\alpha, \beta) (a,b)),
%   \end{align*}
%   and it follows that $L^{\gamma_1} \sim L^{\gamma_2}$.
% \end{proof}

\begin{claim}
  Let $\sigma \in \spstab{g}$, $\eta \in U^{\underline{\consp(g)}}$, $\gamma: U
  \rightarrow [n]$ a bijection such that $\gamma^{-1} \sim \eta$. Then
  $\gamma^{-1} \cdot \sigma \sim \eta$.
\end{claim}
\begin{proof}
  Suppose $a \in \consp(g)$, then $\sigma (a) = a$ and so $\gamma^{-1} (\sigma
  (a)) = \gamma^{-1} (a) = \eta (a)$.
\end{proof}

% \begin{claim}
%   For $h \in H$ and $\sigma \in \stab(\consp (g))$, we have that
%   $\vec{r}_{\sigma h_1} = \sigma \vec{r}_{h_1}$.
% \end{claim}
% \begin{proof}
%   Proof in book
% \end{proof}

The following result shows that the action on the support of an object
determines the action on that object.

\begin{lem}
  \label{lem:support_determine_action}
  Let $X$ be a set on which the left action of $\sym_n$ is defined. Let $\sigma,
  \sigma' \in \spstab{g}$, $a \in X$. If $\sigma (\vec{\consp}(a)) = \sigma'
  (\vec{\consp}(a))$ then $\sigma (a) = \sigma' (a)$.
\end{lem}
\begin{proof}
  From $\sigma (\vec{\consp(a)}) = \sigma' (\vec{\consp(a)})$, it follows that
  $\pi = (\sigma')^{-1} \sigma$ fixes $\vec{\consp}(a)$. Thus $\sigma (a) =
  \sigma' (\pi (a)) = \sigma' (a)$.
\end{proof}

% \begin{lem}
%   \label{lem:map_same_support_same_row}
%   Let $\sigma, \sigma' \in \spstab{g}$ and suppose for some $i \in [a]$ we
%   have that $\sigma (\vec{r}_i) = \sigma (\vec{r}_i)$. It follows that
%   $\sigma_r (i) = \sigma'_r (i)$.
% \end{lem}
% \begin{proof}
%   Let $pi = (\sigma^{-1} \sigma')_r \in G^r_i$. Then $ (\sigma^{-1} \sigma')_r
%   (i) = \sigma^{-1}_r \sigma'_r (i) = i$, and so $\sigma_r (i) = \sigma'_r
%   (i)$.
% \end{proof}

% Let $X$ be a set on which the left group action on which the left group action
% of $\sym_n$ is defined and let $a \in X$. Let $\vec{x} \in A_i$ and $f \in
% U^{\underline{[\vert \consp{a} \vert]}}$. Then $\Pi^{\gamma}_{\vec{x}_f} (a)$
% is the action on $a$ defined by $\Pi^{\gamma}_{\vec{x}_f} (z) =
% \gamma(\vec{x_f}(z))$, for all $z \in \consp (a)$. Lemma
% \ref{lem:support_determine_action} tells us that this action is well defined.


% Let $(i, j) \in A \times B$, let $\vec{x} \in A^r_i$ and $\vec{y} \in A^c_j$.
% Define permutations $\Pi^{\gamma}_{\vec{x}}$ and $\Pi^{{\gamma},c}_{\vec{y}}$
% such that $\Pi^{\gamma,r}_{\vec{x}}(\vec{r}_i) = \gamma (\vec{x})$ and
% $\Pi^{\gamma,c}_{\vec{y}}(\vec{c}_j) = \gamma (\vec{y})$. From Lemma
% \ref{lem:support_determine_action} we have that the choice of $\vec{x}$ and
% $\vec{y}$ uniquely determine the mappings $\Pi^{\gamma,r}_{\vec{x}}(i)$ and
% $\Pi^{\gamma,c}_{\vec{y}}(j)$

Let $X$ be a set on which the left action of $\sym_n$ is defined, and let $x \in
X$. Let $f \in U^{\underline{\consp(x)}}$ and $\gamma\in [n]^{\underline{U}}$,
then we let $\Pi^{\gamma}_{f} \in \spstab{g}$ be such that $\Pi^{\gamma}_f (a) =
\gamma (f(a))$ for all $a \in \consp(x)$. Note that from Lemma
\ref{lem:support_determine_action}, $\Pi^{\gamma}_f(x)$ is well-defined
independently of the choice of $\Pi^{\gamma}_f$.

Let $\alpha^{\gamma}: I \rightarrow A$ and $\beta^{\gamma}: J \rightarrow B$ be
defined by $\alpha^{\gamma} (i, \vec{x}) = \Pi^{\gamma}_{\vec{x}_{i}}(i)$ and
$\beta^{\gamma} (j, \vec{y}) = \Pi^{\gamma}_{\vec{y}_{j}}(j)$, respectively.

Note that both $\alpha^{\gamma}$ and $\beta^{\gamma}$ can be lifted to functions
on $I /{\sim}$ and $J /{\sim}$ respectively. Lemma
\ref{lem:functions-well-defined} gives us that these liftings are well-defined.


We now show that $\alpha^{\gamma}$ and $\beta^{\gamma}$ act as witnesses to the
row-column of equivalence of $M_{~}$ and $L^{\gamma}$. The following lemma
proves surjectivity.

\begin{remark}
  I am still in the process of rewriting this section (and figuring out how to
  restructure it) so as to include this quotienting operation. The remainder of
  this section should still be looked at, but I have yet to integrate the
  quotenting operation. I would also like to talk with you about this step.
\end{remark}

\begin{lem} 
  For any bijection $\gamma : U \rightarrow [n]$ both $\alpha^{\gamma}$ and
  $\beta^{\gamma}$ are surjective.
  \label{lem:alpha-beta-surjective}
\end{lem}
\begin{proof}
  We show that $\alpha$ is surjective, with the same result for $\beta$
  following similarly. Let $q \in A$ and let $i = \min (\orb (q))$. Then there
  exists $\sigma \in \spstab{g}$ such that $\sigma i = q$. Let $\vec{x} =
  \gamma^{-1} \cdot \sigma \cdot \vec{\consp}(i)$. Notice that for $a \in
  \consp(i)$ we have that $\vec{x}_i(a) = \gamma^{-1} (\sigma (a))$, and since
  $\gamma^{-1} \cdot \sigma \sim \eta$, it follows that $\vec{x} \in A_i$.

  For $a \in \consp(i)$ we have $\Pi^{\gamma}_{\vec{x}_i} (a) = \gamma
  (\vec{x}_i(a)) = \gamma \cdot \gamma^{-1} \sigma (a) = \sigma (a)$. From Lemma
  \ref{lem:support_determine_action} it follows that $\alpha(i, \vec{x}) = q$.
\end{proof}

The following lemma allows us to factor through permutations.
\begin{lem}
  \label{lem:alpha_and_gamma}
  Let $(i,\vec{x}) \in I$ and $(j, \vec{y}) \in J$. Let $\gamma: U \rightarrow
  [n]$ be a bijection such that $\gamma^{-1} \sim \eta$ and $\pi \in spstab{g}$.
  Then $\pi \alpha^{\gamma}(i, \vec{x}) = \alpha^{\pi \gamma}(i, \vec{x})$ and
  $\pi \beta^{\gamma}(j, \vec{y}) = \beta^{\pi \gamma}(j, \vec{y})$.
\end{lem}
\begin{proof}
  We have that $\pi \alpha^{\gamma}(i, \vec{x}) = \pi
  \Pi^{\gamma}_{\vec{x}_i}(i)$ and $(\pi
  \Pi^{\gamma}_{\vec{x}_{i}}(\vec{\consp}(i)) = \pi \cdot \gamma (\vec{x}) =
  \Pi^{\pi \gamma}_{\vec{x}_i}(\vec{\consp}(i))$. Since
  $\Pi^{\gamma}_{\vec{x}_i}$ and $\Pi^{\pi \gamma}_{\vec{x}_i}$ are in
  $\spstab{g}$, it follows from Lemma \ref{lem:support_determine_action}, that
  $\pi \alpha^{\gamma}(i, \vec{x}) = \pi \Pi^{\gamma}_{\vec{x}_i} (i) = \Pi^{\pi
    \gamma}_{\vec{x}_i}(i) = \alpha^{\pi \gamma}(i, \vec{x})$. Similarly, $\pi
  \beta^{\gamma}(j, \vec{y}) = \beta^{\pi \gamma} (j, \vec{y})$.
\end{proof}

\begin{lem}
  \label{lem:alpha_ind_gamma}
  Let $(i,\vec{x}) \in I$ and $(j, \vec{y}) \in J$. Let $\gamma_1, \gamma_2: U
  \rightarrow [n]$ be bijections such that $\gamma^{-1}_1 \sim \eta$ and
  $\gamma^{-1}_2 \sim \eta$. Let $\mathcal{A}$ be a structure. Then
  $C_n[\gamma_1 \mathcal{A}] (L(\alpha^{\gamma_1}(i, \vec{x}),
  \beta^{\gamma_1}(j, \vec{y}))) = C_n[\gamma_2 \mathcal{A}]
  (L(\alpha^{\gamma_2}(i, \vec{x}), \beta^{\gamma_2}(j, \vec{y})))$.
\end{lem}
\begin{proof}
  We note that there exists $\pi \in \sym_n$ such that $\gamma_1 = \pi
  \gamma_2$. Moreover, since $\gamma^{-1}_1$ and $\gamma^{-1}_2$ are both
  consistent with $\eta$, it follows that $\pi \in \spstab{g}$. We then have
  that
  \begin{align*}
    C_n[\gamma_1 \mathcal{A}](L(\alpha^{\gamma_1}(i, \vec{x}), \beta^{\gamma_1}(j,
    \vec{y})) &= C_n[\pi \gamma_1 \mathcal{A}](\pi L(\alpha^{\gamma_1}(i, \vec{x}),
                \beta^{\gamma_1}(j, \vec{y})) \\
              &= C_n[\pi \gamma_1 \mathcal{A}](L(\pi
                \alpha^{\gamma_1}(i, \vec{x}), \pi \beta^{\gamma_1}(j, \vec{y}))\\
              &= C_n[\pi
                \gamma_1 \mathcal{A}](L(\alpha^{\pi \gamma_1}(i, \vec{x}), \pi \beta^{\pi
                \gamma_1}(j, \vec{y})\\
              &= C_n[\gamma_2 \mathcal] (L(\alpha^{\gamma_2}(i,
                \vec{x}), \beta^{\gamma_2}(j, \vec{y})))\\
  \end{align*}The third equality follows from Lemma \ref{lem:alpha_and_gamma}.
\end{proof}

\begin{lem}
  \label{lem:defining_h_from_IJ}
  Let $(i, \vec{x}) \in I$ and $j, \vec{y} \in J$. Let $\vec{r}$ and $\vec{c}$
  be described as above. Let $\sigma_1$ and $\sigma_2$ be as from Lemma
  \ref{lem:permutation_row-column}. Let $h = L(g) (\sigma_1 (i), \sigma_2 (j))$.
  Then $\alpha^{\gamma'} (i, \vec{x}) = \row (h)$ and $\beta^{\gamma'}
  (i,\vec{y}) = \column(h)$.
\end{lem}
\begin{proof}
  $\alpha^{\gamma'}(i, \vec{x}) = \Pi^{\gamma'}_{\vec{x}_i} (i)$. It is
  sufficient to show that for all $a \in sp(g)$, $\Pi^{\gamma}_{\vec{x}_i} (a) =
  \sigma_1 (a)$. Note that $\Pi^{\gamma'}_{\vec{x}_i} (a) =
  (\Pi^{\gamma}_{(\vec{x}_{\vec{r}} \vert \vec{y}_{\vec{c}})})^{-1} \gamma
  (\vec{x}_i (a))$, and if $b = \sigma_1 (a)$ we have that $\gamma (\vec{x}_i
  (a)) = \gamma (\vec{x} (\vec{\consp}(i)^{-1} (a))) = \gamma (\vec{x}
  (\vec{\consp}(i)^{-1} (\sigma^{-1}_1 b))) = \gamma (\vec{x} ((\sigma_1 \cdot
  \vec{\consp}(i))^{-1} (b))) = \gamma (\vec{x} (\vec{r}^{-1}(b))) =
  \Pi^{\gamma}_{(\vec{x}_{\vec{r}} \vert \vec{y}_{\vec{c}})}(b)$. So
  $\Pi^{\gamma'}_{\vec{x}} (a) = b = \sigma_1 (a)$. Similarly for
  $\beta^{\gamma'}$.
\end{proof}

\begin{lem}
  Let $\gamma\in [n]^{\underline{U}}$ and $h \in C_n$. Then $\nu \in \EV_h$ iff
  $C_n[\gamma \mathcal{A}](\Pi^{\gamma}_\nu (h)) = 1$.
  \label{lem:translate_EV_circuits}
\end{lem}
\begin{proof}
  We have that $C_n[\gamma \mathcal{A}](\Pi^{\gamma}_\nu(h))$ iff
  $C_n[(\Pi^{\gamma}_{\nu})^{-1}\gamma \mathcal{A}] (h)$. Then, by the
  definition of $\EV_h$, $\nu \in \EV_h$ iff there exists $\gamma' \in
  [n]^{\underline{U}}$ such that $C_n[\gamma' \mathcal{A}](h) = 1$ and $\nu =
  \gamma\restriction{\consp(h)}$.

\end{proof}


\begin{thm}
  Let $\gamma\in [n]^{\underline{U}}$ such that $\eta \sim \gamma^{-1}$ and let
  $(i, \vec{x})\in I$ and $(j, \vec{y})\in J$. It follows that $M((i, \vec{x}),
  (j, \vec{y})) = L^{\gamma}(\alpha^{\gamma}(i, \vec{x}), \beta^{\gamma}(j,
  \vec{y})$.
  \label{lem:ML-equal-elements}
\end{thm}
\begin{proof}
  Let $\gamma' = (\Pi^{\gamma}_{(\vec{x}_{\vec{r}} \vert
    \vec{y}_{\vec{c}})})^{-1} \gamma$.

  \begin{align*}
    M((i, \vec{x}), (j, \vec{y}))
    &= (\vec{x}_{\vec{r}} \vert \vec{y}_{\vec{c}}) \in \EV_h \\
    &= C_n[\gamma \mathcal{A}] (\Pi^{\gamma}_{(\vec{x}_{\vec{r}} \vert \vec{y}_{\vec{c}})} (h)) \\
    &= C_n[\gamma' \mathcal{A}] (h) \\
    &= C_n[\gamma' \mathcal{A}](L(\row(h), \column (h)))\\
    &= C_n[\gamma' \mathcal{A}](L(\alpha^{\gamma'}(i, \vec{x}), \beta^{\gamma'}(j, \vec{y})))\\
    &= C_n[\gamma \mathcal{A}](L(\alpha^{\gamma}(i, \vec{x}), \beta^{\gamma}(j, \vec{y}))y)\\
    &= L^{\gamma}(\alpha^{\gamma}(i, \vec{x}), \beta^{\gamma}(j, \vec{y}))
  \end{align*}
  The second equality follows from Lemma \ref{lem:translate_EV_circuits}. The
  fifth equality follows from Lemma \ref{lem:defining_h_from_IJ}. The sixth
  equality follows from Lemma \ref{lem:alpha_ind_gamma}.
\end{proof}

\begin{lem}
  Let $X$ be a set on which the left group action of $\sym_n$ is defined, and
  let $\sigma, \sigma' \in \stab(\consp(g))$. We have that $\sigma(s) = \sigma'
  (s)$ if, and only if, $\sigma \equiv_s \sigma'$.
  \label{lem:functions-mutual-equivalence}
\end{lem}
\begin{proof}
  Suppose $\sigma(s) = \sigma'(s)$. Then let $\pi = (\sigma')^{-1} \cdot
  \sigma$. Then clearly $\pi \in \stab(s) \cap \spstab(g)$ and $\sigma = \sigma'
  \pi$.1

  Suppose $\sigma \equiv_s \sigma'$. Then let $\pi = (\sigma')^{-1} \cdot
  \sigma$. From mutual stability $\pi \in \stab (s)$ and so $(\sigma')^{-1}\cdot
  \sigma (s) = \pi (s) = s$. The result follows.
\end{proof}

\begin{lem}
  Let $((i, \vec{x}), (j, \vec{y})), ((i, \vec{x}'), (j, \vec{y}')) \in I \times
  J$ such that $\vec{x} \equiv_i \vec{x}'$ and $\vec{y} \equiv_j \vec{y}'$. Then
  for any $\gamma \in [n]^{\underline{U}}$, $\alpha^{\gamma}(i, \vec{x}) =
  \alpha^{\gamma}(i, \vec{x}')$ and $\beta^{\gamma}(j, \vec{y}) =
  \beta^{\gamma}(j, \vec{y}')$.
  \label{lem:alpha-beta-mutal-equivalence}
\end{lem}
\begin{proof}
  From mutual equivalence there exists $\sigma_1 \in \stab(i) \cap \spstab{g}$
  and $\sigma_2 \in \stab{j} \cap \spstab{g}$ such that $\vec{x}' = \vec{x}
  \cdot \sigma_1\restriction{\consp(i)}$ and $\vec{y}' = \vec{y} \cdot
  \sigma_2\restriction{\consp(j)}$. Notice that $\alpha^{\gamma}(i, \vec{x})$
  and $\beta^{\gamma}(j, \vec{y})$ both stabilise $\consp(g)$. Then for $a \in
  \consp(i)$, $\Pi^{\gamma}_{\vec{x}} (\sigma_1 (a)) = \gamma (\vec{x}(\sigma_1
  (a))) = \gamma (\vec{x}'(a)) = \Pi^{\gamma}_{\vec{x}'}(a)$. It follows from
  Lemma \ref{lem:functions-mutual-equivalence} that $\alpha^{\gamma}(i,j) =
  \Pi^{\gamma}_{\vec{x}} (i) = \Pi^{\gamma}_{\vec{x}'}(i)$. The result follows
  similarly for $\beta$.
\end{proof}

\begin{lem}
  Let $((i, \vec{x}), (j, \vec{y})), ((i, \vec{x}'), (j, \vec{y}')) \in I \times
  J$ be such that $\vec{x} \equiv_i \vec{x}'$ and $\vec{y} \equiv_j \vec{y}'$,
  then $M(((i, \vec{x}), (j, \vec{y}))) = M((i, \vec{x}'), (j, \vec{y}'))$.
  \label{lem:matrix-quot-well-defined}
\end{lem}
\begin{proof}
  \begin{align*}
    M((i, \vec{x}),(j, \vec{y})) &= L^{\gamma}(\alpha^{\gamma}(i, \vec{x}), \beta^{\gamma}(j, \vec{y}) \\
                                 &= L^{\gamma}(\alpha^{\gamma}(i, \vec{x}'), \beta^{\gamma}(j, \vec{y}'))\\
                                 &= M((i, \vec{x}'), (j, \vec{y}'))
  \end{align*}
  The second equality follows from Lemma \ref{lem:alpha-beta-mutal-equivalence}.
\end{proof}

Let $I_{\equiv} = \{(i, [\vec{x})]_{\equiv}) : (i, \vec{x}) \in I\}$ and
$J_\equiv = \{(j, [\vec{y}]_{\equiv}) : (j, \vec{y})\}$. Let $M_{\equiv} :
I_{\equiv} \times J_{\equiv} \rightarrow \{0,1\}$ be defined by $M_\equiv ((i,
[\vec{x}]_\equiv), (j, [\vec{y}]_\equiv)) := M((i,\vec{x}), (j, \vec{y}))$.
Lemma \ref{lem:matrix-quot-well-defined} gives us that this function is
well-defined.

\begin{thm}
  Let $\gamma \in [n]^{\underline{U}}$ such that $\gamma^{-1} \sim \eta$. Then
  $L^{\gamma}$ is row-column equivalent to $M_{\equiv}$.
  \label{thm:LM-equivalence}
\end{thm}
\begin{proof}
  Let $(i, [\vec{x}]) \in I_\equiv$ and $(j, [\vec{y}]) \in J_\equiv$. Then,
  from Lemmas \ref{lem:matrix-quot-well-defined} and
  \ref{lem:ML-equal-elements}, we have that $M_\equiv ((i, [\vec{x}]), (j,
  [\vec{y}])) = M ((i, \vec{x}), (j, \vec{y}))= = L^{\gamma}(\alpha^{\gamma}(i,
  \vec{x}), \beta^{\gamma}(j, \vec{y}))$.

  Moreover, from Lemma \ref{lem:alpha-beta-mutal-equivalence} we can lift
  $\alpha^\gamma$ to $I_\equiv$ and $\beta^{\gamma}$ to $J_\equiv$. It remains
  to show that $\alpha^\gamma$ and $\beta^{\gamma}$, thought of as functions to
  $I_\equiv$ and $J_\equiv$, are bijections. We prove the result for
  $\alpha^{\gamma}$, with the proof for $\beta^\gamma$ following similarly.

  We first note that the lifting of $\alpha^{\gamma}$ to $I_\equiv$ is
  surjective as, using Lemma \ref{lem:alpha-beta-surjective}, both the unlifted
  function $\alpha^{\gamma}$ and the lifting function (i.e. the quotient map
  from $I$ to $I_\equiv$) are surjective.

  Suppose $\alpha^{\gamma}((i, [\vec{x}])) = \alpha^{\gamma}((i', [\vec{x}']))$,
  and so $\Pi^{\gamma}_{\vec{x}}(i) = \Pi^{\gamma}_{\vec{x}'}(i')$. But then $i$
  and $i'$ are in the same orbit and thus, from the definition of $I$, $i = i'$.
  Thus $\Pi^{\gamma}_{\vec{x}}(i) = \Pi^{\gamma}_{\vec{x}'}(i)$, and so from
  Lemma \ref{lem:functions-mutual-equivalence} there exists $\sigma \in \stab(i)
  \cap \spstab{g}$ such that for all $a \in \consp(i)$ we have that
  $\Pi^{\gamma}_{\vec{x}}(a) = \Pi^{\gamma}_{\vec{x}'} (\sigma (a))$. But then
  $\Pi^{\gamma}_{\vec{x}}(a) = \gamma (\vec{x}(a)) =
  \Pi^{\gamma}_{\vec{x}'}(\sigma (a)) = \gamma (\vec{x}' (\sigma (a))$ and,
  since $\gamma$ is a bijection, it follows that $\vec{x}(a) = \vec{x}' \sigma
  (a)$. Thus $\vec{x} \equiv_i \vec{x}'$, and the lifting of $\alpha^{\gamma}$
  to $I_{\equiv}$ is an injection. The result follows.
\end{proof}

% \begin{lem}
%   Let $\gamma \in [n]^{\underline{U}}$ such that $\gamma^{-1} \sim \eta$. Then
%   $\rk_p (M) = \rk_p (L^{\gamma})$.
% \end{lem}
% \begin{proof}
%   We show that $\rk(M) = \rk (M_\equiv)$, and the result will follow from
%   Theorem \ref{thm:LM-equivalence}.
% \end{proof}

% Let $((i, \vec{x}), (j, \vec{y})), ((i, \vec{x}'), (j, \vec{y}')) \in I \times
% J$ be such that $\vec{x} \equiv_i \vec{x}'$.
% \begin{lem}

% \end{lem}


% \begin{thm}
%   Let $\gamma\in [n]^{\underline{U}}$, $M$ is row-column equivalent to
%   $L^{\gamma}$. This equivalence is witnessed by $\alpha^{\gamma}$ and
%   $\beta^{\gamma}$.
% \end{thm}
% \begin{proof}
%   We have that $\alpha^{\gamma}$ and $\beta^{\gamma}$ are surjective. Let
%   $\gamma' = (\Pi^{\gamma}_{(\vec{x}_{\vec{r}} \vert \vec{y}_{\vec{c}})})^{-1}
%   \gamma$.

%   \begin{align*}
%     M((i, \vec{x}), (j, \vec{y}))
%     &= (\vec{x}_{\vec{r}} \vert \vec{y}_{\vec{c}}) \in \EV_h \\
%     &= C_n[\gamma \mathcal{A}] (\Pi^{\gamma}_{(\vec{x}_{\vec{r}} \vert \vec{y}_{\vec{c}})} (h)) \\
%     &= C_n[\gamma' \mathcal{A}] (h) \\
%     &= C_n[\gamma' \mathcal{A}](L(\row(h), \column (h)))\\
%     &= C_n[\gamma' \mathcal{A}](L(\alpha^{\gamma'}(i, \vec{x}), \beta^{\gamma'}(j, \vec{y})))\\
%     &= C_n[\gamma \mathcal{A}](L(\alpha^{\gamma}(i, \vec{x}), \beta^{\gamma}(j, \vec{y}))y)\\
%     &= L^{\gamma}(\alpha^{\gamma}(i, \vec{x}), \beta^{\gamma}(j, \vec{y}))
%   \end{align*}
%   The second equality follows from Lemma \ref{lem:translate_EV_circuits}. The
%   fifth equality follows from Lemma \ref{lem:defining_h_from_IJ}. The sixth
%   equality follows from Lemma \ref{lem:alpha_ind_gamma}.
% \end{proof}

% \begin{remark}
%   In fact, the above still requires injectivity. This still needs to be
%   integrated.
% \end{remark}


% \subsection{FPR Formulas}

% \begin{lem}
%   Let $(i, \vec{x}) \in I$ and $(j, \vec{y}) \in J$. Let $h \in H$ such that
%   $\row (h) \in \orb_r (i)$, $\column (h) \in \orb_c(j)$, and $\type(h) =
%   \type(\vec{x}, \vec{y})$. Let $\gamma: U \rightarrow [n]$ be a bijection and
%   $\mathcal{A}$ a structure. Then $C_n[\gamma
%   \mathcal{A}](\Pi^{\gamma}_{\vec{x} \vert \vec{y}} (h)) = C_n[\gamma
%   \mathcal{A}](L(\alpha^{\gamma}(i, \vec{x}), \beta^{\gamma}(j, \vec{y})))$.
% \end{lem}
% \begin{proof}
%   Let $\gamma' = (\Pi^{\gamma}_{\vec{x} \vert \vec{y}})^{-1} \gamma$. First we
%   show that $h = L(\alpha^{\gamma'}(i, \vec{x}), \beta^{\gamma'}(j,
%   \vec{y}))$. Notice that $\Pi^{\gamma'}_{\vec{x}}(\vec{r}_i) =
%   \gamma'(\vec{x}) = (\Pi^{\gamma}_{\vec{x} \vert \vec{y}})^{-1} \gamma
%   (\vec{x}) = \vec{r}_h$. But $\row(h) \in \orb_r(i)$ and so there exists
%   $\vec{x}' \in A^r_i$ such that $\Pi^{\gamma'}_{vec{x}'}(i) = \row{h}$ From
%   Lemma \ref{lem:support_determine_action} it follows that $\row (h) =
%   \Pi^{\gamma'}_{\vec{x}}(i) = \alpha^{\gamma'}(i, \vec{x})$. Similarly, we
%   can show that $\column(h) = \beta^{\gamma'}(j, \vec{y})$. It follows that $h
%   = L(\alpha^{\gamma'}(i, \vec{x}), \beta^{\gamma'}(j, \vec{y}))$, and so
%   \begin{align*}
%     C_n[\gamma \mathcal{A}](\Pi^{\gamma}_{\vec{x}
%     \vert \vec{y}} (h))
%     &= C_n[\gamma' \mathcal{A}](h)\\
%     &= C_n[\gamma' \mathcal{A}](L(\alpha^{\gamma'}(i, \vec{x}), \beta^{\gamma'}(j, \vec{y})))\\
%     &= C_n[\gamma \mathcal{A}](L(\alpha^{\gamma}(i, \vec{x}), \beta^{\gamma}(j, \vec{y}))).
%   \end{align*}
%   The final equality follows from Lemma \ref{lem:alpha_ind_gamma}.
% \end{proof}


% \chapter{New Stuff}
% Let $x,y \subset U$ such that $\vert x \vert = \vert y \vert = k \in
% \mathbb{N}$. Let $\vec{x}: [k] \rightarrow x$ and $\vec{y}: [k] \rightarrow y$
% be bijections.

% We need to define $r, c \subset [n]$ such that $\vert r \vert = \vert c \vert
% = k$ and there exists bijections $\vec {r}: [k] \rightarrow r$ and $\vec{c}:
% [k] \rightarrow c$.

% Let $u_1 , \ldots , u_{2k}$ be the first $2k$ elements of $[n] \setminus
% \SP(g)$ in order. Then let
% \[r = \eta^{-1} (x \cap \eta (\SP(g))) \cup \{u_{\vec{x}^{-1}(a)}: a \in x
%   \setminus \alpha (\SP (g))\} \] and
% \[s = \eta^{-1} (y \cap \eta (\SP(g))) \cup (x \cap y) \cup \{ u_{k +
%   \vec{x}^{-1}(a)} : a \in y \setminus (x \cup \alpha (\SP (g))) \}). \]
% Define
% \[
%   \vec{r} (a) =
%   \begin{cases}
%     \eta^{-1} (\vec{x} (a)) & a \in \vec{x}^{-1} (x \cap \eta (\SP(g))) \\
%     u_{a} & a \in \vec{x}^{-1} (x \setminus \eta(\SP(g)),
%   \end{cases}
% \]
% and

% \[
%   \vec{c} (a) =
%   \begin{cases}
%     \eta^{-1} (\vec{y} (a)) & a \in \vec{y}^{-1}(y \cap \eta (\SP (g))) \\
%     \vec{r} (a) & a \in \vec{y}^{-1} (x \cap y \setminus \eta (\SP (g))) \\
%     u_{k+a} & \text{otherwise}.
%   \end{cases}
% \]

% \begin{lem}
%   $x_r \sim \eta$ and $x_c \sim \eta$
% \end{lem}

% \begin{lem}
%   $\SP(g) \cap \SP(i) = \SP(g) \cap r$ and $\SP (g) \cap SP (j) = \SP (g) \cap
%   c$.
% \end{lem}

% Let $(\vec{x}, \vec{y})_{\vec{r}, \vec{c}}: r \cup c \rightarrow U$ be defined
% by
% \[
%   (\vec{x}, \vec{y})_{\vec{r}, \vec{c}}(a) =
%   \begin{cases}
%     \vec{x}(\vec{r}^{-1}(a)) & a \in r \\
%     \vec{y}(\vec{c}^{-1}(a)) & a \in c
%   \end{cases}
% \]

% This function is well defined.

% % \begin{lem}
% %   Let $r, c \subset U$ and let $r_1, r_2 : [k_1] \rightarrow r$ and $c_1, c_2 :
% %   [k_2] \rightarrow c$ then $\type(\vec{r}_1, \vec{c}_1) = \type (\vec{r}_2 ,
% %   \vec{c}_2)$.
% % \end{lem}

% \begin{lem}
%   $(\vec{x}_{\vec{r}} \vert \vec{y}_{\vec{y}}) \sim \eta$
% \end{lem}

% \begin{lem}
%   There exists $\sigma_1, \sigma_2 \in \spstab{g}$ such that $\sigma_1 \cdot
%   \vec{\consp(i)} = \vec{r}$ and $\sigma_2 \cdot \vec{\consp(j)} = \vec{c}$.
% \end{lem}

% \begin{lem}
%   Let $(i, \vec{x}) \in I$ and $j, \vec{y} \in J$. Let $\vec{r}$ and $\vec{c}$
%   be described as above. Let $\sigma_1$ and $\sigma_2$ be as from Lemma
%   \ref{}. Let $h = L(g) (\sigma_1 (i), \sigma_2 (j))$. Then $\alpha^{\gamma'}
%   (i, \vec{x}) = \row (h)$ and $\beta^{\gamma'} (i,\vec{y}) = \column(h)$.
% \end{lem}
% \begin{proof}
%   $\alpha^{\gamma'}(i, \vec{x}) = \Pi^{\gamma'}_{\vec{x}} (i)$. It is
%   sufficient to show that for all $a \in sp(g)$, $\Pi^{\gamma}_{\vec{x}} (a) =
%   \sigma_1 (a)$. Note that $\Pi^{\gamma'}_{\vec{x}_i} (a) =
%   (\Pi^{\gamma}_{(\vec{x}, \vec{y})_{\vec{r}, \vec{c}}})^{-1} \gamma
%   (\vec{x}_i (a))$, and if $b = \sigma_1 (a)$ we have that $\gamma (\vec{x}_i
%   (a)) = \gamma (\vec{x} (\vec{\consp}(i)^{-1} (a))) = \gamma (\vec{x}
%   (\vec{\consp}(i)^{-1} (\sigma^{-1}_1 b))) = \gamma (\vec{x} ((\sigma_1 \cdot
%   \vec{\consp}(i))^{-1} (b))) = \gamma (\vec{x} (\vec{r}^{-1}(b))) =
%   \Pi^{\gamma}_{(\vec{x}, \vec{y})_{\vec{r}, \vec{c}}}(b)$. So
%   $\Pi^{\gamma'}_{\vec{x}} (a) = b = \sigma_1 (a)$. Similarly for
%   $\beta^{\gamma'}$.
% \end{proof}

% \begin{lem}
%   Let $(i, \vec{x}) \in I$ and $(j, \vec{y}) \in J$. There exists $h \in H$
%   such that $h$ has type $(\vec{x}, \vec{y})$ and for any bijection $\gamma: U
%   \rightarrow [n]$ and structure $\mathcal{A}$ then $C_n[\gamma \mathcal{A}]
%   (\Pi^{\gamma}_{(\vec{x} \vert \vec{y})_{h}}) = C_n [\gamma
%   \mathcal{A}](L(\alpha^{\gamma}(i, \vec{x}), \beta^{\gamma}(j, \vec{y})))$.
% \end{lem}

% \begin{lem}
%   Let $h \in H$ and $\vec{z} \in A_h$ and $\Pi^{\delta}_h$ be a permutation
%   such that $\Pi^{\delta}_{\vec{z}}(a) = \delta(\vec{z}(a))$ for all $a \in
%   \sp(h)$. Then $C_n[\gamma \mathcal{A}](\Pi^{delta}_{\vec{z}} (h))$ iff
%   $\vec{z} \in \EV_h$.
% \end{lem}

% \begin{thm}
%   The matrix $M$ is equivalent to $L$.
% \end{thm}
\subsection{Translating to Formulas of FPR}
Let $\mathcal{C}:= (C_n)_{n \in \mathbb{N}}$ be a $P$-uniform family of
symmetric rank circuits. In this section we define a formula $Q$ in $\FPR$ such
that for any $\tau$-structure $\mathcal{A}$ over the universe $U$ with $\vert U
\vert = n$, the $q$-ary query defined by $C_n$ on input $\mathcal{A}$ is defined
by $Q$ when interpreted in $\mathcal{A}$.

From the Immerman-Vardi theorem and Lemma \ref{}, there is an $FP$
interpretation defining a circuit with bijective 
\end{document}
